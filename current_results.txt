============================= test session starts =============================
platform win32 -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0
rootdir: C:\Users\issak\CodeDocSync
configfile: pyproject.toml
plugins: anyio-4.9.0, asyncio-1.1.0, mock-3.14.1
asyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 702 items

test_style_detector.py .                                                 [  0%]
tests\analyzer\test_llm_analyzer.py ........F.......                     [  2%]
tests\analyzer\test_rule_engine.py ...............                       [  4%]
tests\matcher\test_contextual_matcher.py ...........                     [  6%]
tests\matcher\test_direct_matcher.py ..........F                         [  7%]
tests\matcher\test_semantic_matcher.py ............                      [  9%]
tests\parser\test_ast_parser_comprehensive.py .......................... [ 13%]
....                                                                     [ 13%]
tests\parser\test_ast_parser_decorators.py .......                       [ 14%]
tests\parser\test_ast_parser_error_recovery.py .............             [ 16%]
tests\parser\test_ast_parser_function_types.py ......                    [ 17%]
tests\parser\test_ast_parser_performance.py .F....                       [ 18%]
tests\parser\test_docstring_parser_integration.py ...............        [ 20%]
tests\suggestions\formatters\test_json_formatter.py .................... [ 23%]
...........                                                              [ 24%]
tests\suggestions\formatters\test_terminal_formatter.py ................ [ 27%]
.................                                                        [ 29%]
tests\suggestions\templates\test_google_template.py F............FF.F..F [ 32%]
F                                                                        [ 32%]
tests\suggestions\templates\test_numpy_template.py .............F....F.. [ 35%]
F.F.....                                                                 [ 36%]
tests\suggestions\templates\test_sphinx_template.py .................... [ 39%]
F.........FF                                                             [ 41%]
tests\suggestions\test_base.py ......................................... [ 47%]
......                                                                   [ 47%]
tests\suggestions\test_config.py ....................................... [ 53%]
F.                                                                       [ 53%]
tests\suggestions\test_converter.py ........................F..          [ 57%]
tests\suggestions\test_e2e_integration.py FF.FF.F..F...                  [ 59%]
tests\suggestions\test_generators.py FFFFFFF.FFFF.FFFF...                [ 62%]
tests\suggestions\test_integration.py ......................             [ 65%]
tests\suggestions\test_merging.py ....F.F...F.......                     [ 67%]
tests\suggestions\test_models.py ....................................... [ 73%]
.                                                                        [ 73%]
tests\suggestions\test_performance.py FFFFFFF                            [ 74%]
tests\suggestions\test_ranking.py ......F...................F........    [ 79%]
tests\suggestions\test_specific_issues.py FFFFFFF                        [ 80%]
tests\suggestions\test_style_detector.py ............................... [ 85%]
..........                                                               [ 86%]
tests\suggestions\test_suggestion_generator.py FFFFFFFFFFF               [ 88%]
tests\suggestions\test_type_formatter.py .......F.F...........F.F....... [ 92%]
.......                                                                  [ 93%]
tests\suggestions\test_validation.py ...FFFFF                            [ 94%]
tests\test_cli.py .FFFF.FF.FF..FFF.FF...FF.                              [ 98%]
tests\test_integration.py .............                                  [100%]

================================== FAILURES ===================================
________________ TestLLMAnalyzer.test_cache_identical_analyses ________________

self = <test_llm_analyzer.TestLLMAnalyzer object at 0x000001E7C0A34C50>
llm_analyzer = <codedocsync.analyzer.llm_analyzer.LLMAnalyzer object at 0x000001E7C0F5A950>
basic_function = ParsedFunction(signature=FunctionSignature(name='calculate_discount', parameters=[FunctionParameter(name='price', type..._method=False, decorators=[]), docstring=None, file_path='test.py', line_number=10, end_line_number=15, source_code='')
basic_docstring = ParsedDocstring(format=<DocstringFormat.GOOGLE: 'google'>, summary='Calculate the discounted price', description=None,...efault: 10.0)\n\n            Returns:\n                Discounted price\n            ', is_valid=True, parse_errors=[])

    @pytest.mark.asyncio
    async def test_cache_identical_analyses(
        self,
        llm_analyzer: LLMAnalyzer,
        basic_function: ParsedFunction,
        basic_docstring: ParsedDocstring,
    ) -> None:
        """Test caching of identical analysis requests."""
        request = LLMAnalysisRequest(
            function=basic_function,
            docstring=basic_docstring,
            analysis_types=["behavior"],
            rule_results=[],
            related_functions=[],
        )

        # Mock OpenAI response
        mock_response = {
            "issues": [
                {
                    "type": "behavior_mismatch",
                    "description": "Test issue",
                    "suggestion": "Test suggestion",
                    "confidence": 0.85,
                    "line_number": 10,
                    "details": {},
                }
            ],
            "confidence": 0.90,
        }

        call_count = 0

        async def mock_call(*args: Any, **kwargs: Any) -> tuple[str, dict[str, int]]:
            nonlocal call_count
            call_count += 1
            return (
                json.dumps(mock_response),
                {"prompt_tokens": 150, "completion_tokens": 50},
            )

        # Clear any existing cache
        if hasattr(llm_analyzer, "_cache_manager"):
            try:
                # Try different cache clearing methods
                if hasattr(llm_analyzer._cache_manager, "clear"):
                    await llm_analyzer._cache_manager.clear()
                elif hasattr(llm_analyzer._cache_manager, "clear_cache"):
                    llm_analyzer._cache_manager.clear_cache()
            except Exception:
                pass  # If cache clearing fails, continue anyway

        with patch.object(llm_analyzer, "_call_openai", side_effect=mock_call):
            # First call
            response1 = await llm_analyzer.analyze_function(request)

            # Second identical call
            response2 = await llm_analyzer.analyze_function(request)

            # The test logic depends on how caching is implemented
            # If cache_hit is always True due to how the mock works, adjust expectations

            # At minimum, verify that both calls return the same result
            assert len(response1.issues) == len(response2.issues)
            if len(response1.issues) > 0 and len(response2.issues) > 0:
                assert (
                    response1.issues[0].description == response2.issues[0].description
                )

            # Verify the mock was called at least once
>           assert call_count >= 1
E           assert 0 >= 1

tests\analyzer\test_llm_analyzer.py:874: AssertionError
_________________ TestEdgeCases.test_performance_consistency __________________

self = <tests.matcher.test_direct_matcher.TestEdgeCases object at 0x000001E7C0A02C40>

    def test_performance_consistency(self) -> None:
        """Test that performance remains consistent across multiple runs."""
        matcher = DirectMatcher()

        # Create test data
        functions = []
        for i in range(100):
            functions.append(
                ParsedFunction(
                    signature=FunctionSignature(
                        name=f"func_{i}",
                        parameters=[],
                        return_type="None",
                        is_async=False,
                        is_method=False,
                        decorators=[],
                    ),
                    file_path=f"/project/file_{i // 10}.py",
                    line_number=10 + (i % 10) * 5,
                    end_line_number=15 + (i % 10) * 5,
                    docstring=(
                        RawDocstring(
                            raw_text=f"Function {i}",
                            line_number=10 + (i % 10) * 5,
                        )
                        if i % 2 == 0
                        else None
                    ),
                )
            )

        # Run multiple times
        durations = []
        for _ in range(10):
            start = time.perf_counter()
            result = matcher.match_functions(functions)
            duration = time.perf_counter() - start
            durations.append(duration)

            # Results should be consistent
            assert result.total_functions == 100
            assert result.match_rate == 0.5

        # Check performance consistency
        avg_duration = sum(durations) / len(durations)
        max_deviation = max(abs(d - avg_duration) for d in durations)
        relative_deviation = max_deviation / avg_duration

>       assert (
            relative_deviation < 0.5
        ), f"Performance varies too much: {relative_deviation:.1%}"
E       AssertionError: Performance varies too much: 59.0%
E       assert 0.589894572495393 < 0.5

tests\matcher\test_direct_matcher.py:676: AssertionError
_________ TestASTParserPerformance.test_parse_large_file_performance __________

self = <tests.parser.test_ast_parser_performance.TestASTParserPerformance object at 0x000001E7C0BA0050>

    def test_parse_large_file_performance(self) -> None:
        """Test parsing a large file (5000+ lines) completes under 200ms."""
        # Generate a file with 500 functions (10 lines each = 5000 lines)
        content = generate_test_file(num_functions=500, lines_per_function=10)

        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write(content)
            temp_path = f.name

        try:
            # Warm up
            parse_python_file(temp_path)

            # Actual timing
            start_time = time.perf_counter()
            functions = parse_python_file(temp_path)
            end_time = time.perf_counter()

            parse_time_ms = (end_time - start_time) * 1000

            assert len(functions) == 500
>           assert (
                parse_time_ms < 400
            ), f"Parse time {parse_time_ms:.2f}ms exceeds 400ms limit"
E           AssertionError: Parse time 581.26ms exceeds 400ms limit
E           assert 581.2573000002885 < 400

tests\parser\test_ast_parser_performance.py:110: AssertionError
____________ TestGoogleStyleTemplate.test_render_parameters_simple ____________

self = <test_google_template.TestGoogleStyleTemplate object at 0x000001E7C0C2C910>
template = <codedocsync.suggestions.templates.google_template.GoogleStyleTemplate object at 0x000001E784AC9160>

    def test_render_parameters_simple(self, template: Any) -> None:
        """Test rendering simple parameters."""
        parameters = [
            DocstringParameter(
                name="param1", type_str="str", description="First parameter"
            ),
            DocstringParameter(
                name="param2",
                type_str="int",
                description="Second parameter",
                is_optional=True,
            ),
        ]

        result = template.render_parameters(parameters)

        assert result[0] == "Args:"
        assert "    param1 (str): First parameter" in result
>       assert "    param2 (int, optional): Second parameter" in result
E       AssertionError: assert '    param2 (int, optional): Second parameter' in ['Args:', '    param1 (str): First parameter', '    param2 (int): Second parameter']

tests\suggestions\templates\test_google_template.py:41: AssertionError
______________ TestGoogleStyleTemplate.test_match_parameter_line ______________

self = <test_google_template.TestGoogleStyleTemplate object at 0x000001E7C0BC6820>
template = <codedocsync.suggestions.templates.google_template.GoogleStyleTemplate object at 0x000001E780AE59B0>

    def test_match_parameter_line(self, template: Any) -> None:
        """Test matching parameter lines to extract names."""
        test_cases = [
            ("    param_name (str): Description", "param_name"),
            ("    param: Description", "param"),
            ("    *args: Variable arguments", "*args"),
            ("    **kwargs: Keyword arguments", "**kwargs"),
            ("    Regular line without parameter", None),
        ]

        for line, expected in test_cases:
            result = template._match_parameter_line(line)
>           assert result == expected
E           AssertionError: assert None == '**kwargs'

tests\suggestions\templates\test_google_template.py:189: AssertionError
___________ TestGoogleStyleTemplate.test_extract_section_boundaries ___________

self = <test_google_template.TestGoogleStyleTemplate object at 0x000001E7C0C3C4D0>
template = <codedocsync.suggestions.templates.google_template.GoogleStyleTemplate object at 0x000001E7C0BC5BF0>

    def test_extract_section_boundaries(self, template: Any) -> None:
        """Test extracting section boundaries from docstring."""
        docstring_lines = [
            '"""Function docstring.',
            "",
            "Args:",
            "    param1: First parameter",
            "    param2: Second parameter",
            "",
            "Returns:",
            "    Success status",
            "",
            "Raises:",
            "    ValueError: Invalid input",
            '"""',
        ]

        boundaries = template.extract_section_boundaries(docstring_lines)

        assert "parameters" in boundaries
        assert "returns" in boundaries
        assert "raises" in boundaries

        # Check parameter section boundaries
        params_start, params_end = boundaries["parameters"]
        assert params_start == 2  # "Args:" line
>       assert params_end == 4  # Last parameter line
        ^^^^^^^^^^^^^^^^^^^^^^
E       assert 5 == 4

tests\suggestions\templates\test_google_template.py:217: AssertionError
_________ TestGoogleStyleTemplate.test_template_with_max_line_length __________

self = <test_google_template.TestGoogleStyleTemplate object at 0x000001E7C0BD2620>

    def test_template_with_max_line_length(self) -> None:
        """Test template respects max line length setting."""
        template = GoogleStyleTemplate(max_line_length=50)

        parameters = [
            DocstringParameter(
                name="param",
                type_str="str",
                description="This is a very long description that should be wrapped",
            )
        ]

        result = template.render_parameters(parameters)

        # Check that lines don't exceed max length (accounting for indentation)
        for line in result:
>           assert len(line) <= 50 or line.strip() == ""
E           AssertionError: assert (71 <= 50 or 'param (str):...ld be wrapped' == ''
E            +  where 71 = len('    param (str): This is a very long description that should be wrapped')
E
E             + param (str): This is a very long description that should be wrapped)

tests\suggestions\templates\test_google_template.py:266: AssertionError
____________ TestTemplateRegistry.test_invalid_style_raises_error _____________

self = <test_google_template.TestTemplateRegistry object at 0x000001E7C0BEDBA0>

    def test_invalid_style_raises_error(self) -> None:
        """Test that invalid style raises error."""
        from codedocsync.suggestions.templates import DocstringStyle, template_registry

>       with pytest.raises(ValueError):
             ^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'ValueError'>

tests\suggestions\templates\test_google_template.py:291: Failed
__________ TestTemplateIntegration.test_realistic_function_docstring __________

self = <test_google_template.TestTemplateIntegration object at 0x000001E7C0C2CE10>

    def test_realistic_function_docstring(self) -> None:
        """Test generating realistic function docstring."""
        template = GoogleStyleTemplate()

        parameters = [
            DocstringParameter(
                name="data",
                type_str="List[Dict[str, Any]]",
                description="Input data to process",
            ),
            DocstringParameter(
                name="config",
                type_str="Optional[Config]",
                description="Configuration object",
                is_optional=True,
                default_value="None",
            ),
            DocstringParameter(
                name="verbose",
                type_str="bool",
                description="Enable verbose output",
                is_optional=True,
                default_value="False",
            ),
        ]

        returns = DocstringReturns(
            type_str="ProcessedData",
            description="Processed data object with validation results",
        )

        raises = [
            DocstringRaises(
                exception_type="ValidationError",
                description="When input data fails validation",
            ),
            DocstringRaises(
                exception_type="ConfigurationError",
                description="When configuration is invalid",
            ),
        ]

        result = template.render_complete_docstring(
            summary="Process input data with optional configuration.",
            description="This function validates and processes input data according to the provided configuration. It supports various input formats and provides detailed error reporting.",
            parameters=parameters,
            returns=returns,
            raises=raises,
        )

        # Verify structure and content
        assert '"""' in result
        assert "Process input data with optional configuration." in result
        assert "Args:" in result
        assert "data (List[Dict[str, Any]]): Input data to process" in result
>       assert "config (Optional[Config], optional): Configuration object" in result
E       assert 'config (Optional[Config], optional): Configuration object' in '"""\nProcess input data with optional configuration.\n\nThis function validates and processes input data according to...es:\n    ValidationError: When input data fails validation\n    ConfigurationError: When configuration is invalid\n"""'

tests\suggestions\templates\test_google_template.py:353: AssertionError
___________ TestNumpyStyleTemplate.test_render_raises_without_type ____________

self = <test_numpy_template.TestNumpyStyleTemplate object at 0x000001E7C0BC6B60>
template = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000001E785270050>

    def test_render_raises_without_type(self, template: Any) -> None:
        """Test rendering raises without exception type."""
        raises = [
            DocstringRaises(
                exception_type="Exception",
                description="If something goes wrong",
            )
        ]

        result = template.render_raises(raises)

        # Should use generic "Exception"
        assert "Exception" in result
>       assert "If something goes wrong" in result
E       AssertionError: assert 'If something goes wrong' in ['Raises', '------', 'Exception', '    If something goes wrong']

tests\suggestions\templates\test_numpy_template.py:259: AssertionError
______________ TestNumpyStyleTemplate.test_match_parameter_line _______________

self = <test_numpy_template.TestNumpyStyleTemplate object at 0x000001E7C0C43A70>
template = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000001E784D0D270>

    def test_match_parameter_line(self, template: Any) -> None:
        """Test parameter line matching."""
        # Valid parameter lines
        assert template._match_parameter_line("param_name : str") == "param_name"
        assert template._match_parameter_line("param") == "param"
        assert template._match_parameter_line("param_name : List[str]") == "param_name"

        # Invalid lines
>       assert template._match_parameter_line("    description") is None
E       AssertionError: assert 'description' is None
E        +  where 'description' = _match_parameter_line('    description')
E        +    where _match_parameter_line = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000001E784D0D270>._match_parameter_line

tests\suggestions\templates\test_numpy_template.py:315: AssertionError
_______ TestNumpyStyleTemplate.test_format_type_annotation_array_types ________

self = <test_numpy_template.TestNumpyStyleTemplate object at 0x000001E7C0C68850>
template = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000001E7C0C4A750>

    def test_format_type_annotation_array_types(self, template: Any) -> None:
        """Test formatting array types for NumPy style."""
        # NumPy arrays should become array_like
        assert template._format_type_annotation("np.ndarray") == "array_like"
        assert template._format_type_annotation("ndarray") == "array_like"

        # Lists should become list of type
        assert template._format_type_annotation("List[str]") == "list of str"
        assert template._format_type_annotation("List[int]") == "list of int"

        # Dicts should become dict of type
>       assert template._format_type_annotation("Dict[str, Any]") == "dict of Any"
E       AssertionError: assert 'dict of str, Any' == 'dict of Any'
E
E         - dict of Any
E         + dict of str, Any
E         ?        +++++

tests\suggestions\templates\test_numpy_template.py:366: AssertionError
_______________ TestNumpyStyleTemplate.test_long_line_wrapping ________________

self = <test_numpy_template.TestNumpyStyleTemplate object at 0x000001E7C0C618D0>
template = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000001E7C0C60AD0>

    def test_long_line_wrapping(self, template: Any) -> None:
        """Test that long lines are properly wrapped."""
        template.max_line_length = 50  # Short line for testing

        params = [
            DocstringParameter(
                name="very_long_parameter_name_that_exceeds_limit",
                type_str="Dict[str, List[Tuple[int, str]]]",
                description="This is an extremely long description that definitely exceeds the maximum line length and should be wrapped properly across multiple lines",
                is_optional=False,
            )
        ]

        result = template.render_parameters(params)

        # Check that no line exceeds the limit (accounting for indentation)
        for line in result:
>           assert len(line) <= template.max_line_length or line.strip() == ""
E           AssertionError: assert (81 <= 50 or 'very_long_pa...uple[int, str' == ''
E            +  where 81 = len('very_long_parameter_name_that_exceeds_limit : dict of str, list of Tuple[int, str')
E            +  and   50 = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000001E7C0C60AD0>.max_line_length
E
E             + very_long_parameter_name_that_exceeds_limit : dict of str, list of Tuple[int, str)

tests\suggestions\templates\test_numpy_template.py:413: AssertionError
________________ TestSphinxStyleTemplate.test_render_examples _________________

self = <test_sphinx_template.TestSphinxStyleTemplate object at 0x000001E7C0C23530>
template = <codedocsync.suggestions.templates.sphinx_template.SphinxStyleTemplate object at 0x000001E784D0EB70>

    def test_render_examples(self, template: Any) -> None:
        """Test rendering examples."""
        examples = [
            "from mymodule import process\nresult = process(data)",
            "with open('file.txt') as f:\n    content = process(f.read())",
        ]

        result = template._render_examples(examples)

        # Should use Sphinx rubric and code-block directives
        assert ".. rubric:: Examples" in result
        assert ".. code-block:: python" in result
>       assert "from mymodule import process" in result
E       AssertionError: assert 'from mymodule import process' in ['.. rubric:: Examples', '', '.. code-block:: python', '', '   from mymodule import process', '   result = process(data)', ...]

tests\suggestions\templates\test_sphinx_template.py:339: AssertionError
__________ TestSphinxTemplateEdgeCases.test_unicode_in_sphinx_fields __________

self = <test_sphinx_template.TestSphinxTemplateEdgeCases object at 0x000001E7C0C88EF0>
template = <codedocsync.suggestions.templates.sphinx_template.SphinxStyleTemplate object at 0x000001E7F06BD910>

    def test_unicode_in_sphinx_fields(self, template: Any) -> None:
        """Test handling of Unicode characters in Sphinx fields."""
        params = [
>           DocstringParameter(
                name="\u03b1lpha",  # Unicode parameter name
                type_str="str",
                description="Parameter with \xe9mojis \U0001f680 and symbols \u03b1 \u03b2 \u03b3",
                is_optional=False,
            )
        ]

tests\suggestions\templates\test_sphinx_template.py:510:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:8: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = DocstringParameter(name='\u03b1lpha', type_str='str', description='Parameter with \xe9mojis \U0001f680 and symbols \u03b1 \u03b2 \u03b3', is_optional=False, default_value=None)

    def __post_init__(self) -> None:
        """Validate parameter name."""
        # Validate parameter name
        if not re.match(r"^[a-zA-Z_][a-zA-Z0-9_]*$", self.name):
            # Allow *args and **kwargs
            if not re.match(r"^(\*{1,2})?[a-zA-Z_][a-zA-Z0-9_]*$", self.name):
>               raise ValueError(f"Invalid parameter name: {self.name}")
E               ValueError: Invalid parameter name: \u03b1lpha

codedocsync\parser\docstring_models.py:38: ValueError
___________ TestSphinxTemplateEdgeCases.test_very_long_field_names ____________

self = <test_sphinx_template.TestSphinxTemplateEdgeCases object at 0x000001E7C0B4F790>
template = <codedocsync.suggestions.templates.sphinx_template.SphinxStyleTemplate object at 0x000001E780098EF0>

    def test_very_long_field_names(self, template: Any) -> None:
        """Test field names that might cause formatting issues."""
        template.max_line_length = 60

        params = [
            DocstringParameter(
                name="parameter_with_extremely_long_name_that_exceeds_normal_limits",
                type_str="str",
                description="Short desc",
                is_optional=False,
            )
        ]

>       result = template.render_parameters(params)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\templates\test_sphinx_template.py:539:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\templates\sphinx_template.py:49: in render_parameters
    wrapped_lines = self._wrap_sphinx_field(param_line, ":param")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.templates.sphinx_template.SphinxStyleTemplate object at 0x000001E780098EF0>
field_line = ':param parameter_with_extremely_long_name_that_exceeds_normal_limits: Short desc'
field_prefix = ':param'

    def _wrap_sphinx_field(self, field_line: str, field_prefix: str) -> list[str]:
        """Wrap Sphinx field line with proper continuation indentation."""
        if len(field_line) <= self.max_line_length:
            return [field_line]

        # Find the description part after the field prefix
        colon_pos = field_line.find(": ", len(field_prefix))
        if colon_pos == -1:
            return [field_line]

        field_part = field_line[: colon_pos + 2]
        description_part = field_line[colon_pos + 2 :]

        # Calculate continuation indent (align with description start)
        continuation_indent = " " * len(field_part)

        # Wrap the description part
        available_width = self.max_line_length - len(field_part)

        if len(description_part) <= available_width:
            return [field_line]

        # Split description and wrap
        lines = [field_part + description_part[:available_width]]
        remaining = description_part[available_width:]

        while remaining:
            chunk_size = self.max_line_length - len(continuation_indent)
            if len(remaining) <= chunk_size:
                lines.append(continuation_indent + remaining)
                break
            else:
                # Find a good break point
                chunk = remaining[:chunk_size]
                last_space = chunk.rfind(" ")
                if last_space > chunk_size * 0.7:  # If space is reasonably close to end
>                   lines.append(continuation_indent + remaining[:last_space])
E                   MemoryError

codedocsync\suggestions\templates\sphinx_template.py:153: MemoryError
_______ TestConfigIntegration.test_config_with_yaml_file_and_overrides ________

self = <tests.suggestions.test_config.TestConfigIntegration object at 0x000001E7C0C2FB10>

    def test_config_with_yaml_file_and_overrides(self) -> None:
        """Test loading config from YAML with user overrides."""
        yaml_content = """
        suggestions:
          default_style: numpy
          max_line_length: 100
          confidence_threshold: 0.8
        """

        with tempfile.NamedTemporaryFile(mode="w", suffix=".yml", delete=False) as f:
            f.write(yaml_content)
            temp_path = Path(f.name)

        try:
            manager = ConfigManager()

            user_overrides = {
                "confidence_threshold": 0.9,  # Override YAML value
                "include_examples": True,  # New value
            }

            config = manager.load_config(
                config_path=temp_path,
                user_config=user_overrides,
            )

            # Should have YAML values
>           assert config.default_style == "numpy"
E           AssertionError: assert 'google' == 'numpy'
E
E             - numpy
E             + google

tests\suggestions\test_config.py:576: AssertionError
_____________ TestSpecialCases.test_convert_with_unicode_content ______________

self = <tests.suggestions.test_converter.TestSpecialCases object at 0x000001E7C0D18910>
converter = <codedocsync.suggestions.converter.DocstringStyleConverter object at 0x000001E785341F40>

    def test_convert_with_unicode_content(self, converter: Any) -> None:
        """Test conversion with Unicode content."""
        unicode_docstring = ParsedDocstring(
            summary="Funci\xf3n con caracteres especiales \U0001f680.",
            description="Procesa datos con s\xedmbolos \u03b1, \u03b2, \u03b3.",
            parameters=[
>               DocstringParameter(
                    name="données",  # French
                    type_str="str",
                    description="Donn\xe9es d'entr\xe9e avec \xe9mojis \U0001f4ca",
                    is_optional=False,
                )
            ],
            returns=None,
            raises=[],
            raw_text="",
            format=DocstringFormat.GOOGLE,
        )

tests\suggestions\test_converter.py:574:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:8: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = DocstringParameter(name='donn\xe9es', type_str='str', description="Donn\xe9es d'entr\xe9e avec \xe9mojis \U0001f4ca", is_optional=False, default_value=None)

    def __post_init__(self) -> None:
        """Validate parameter name."""
        # Validate parameter name
        if not re.match(r"^[a-zA-Z_][a-zA-Z0-9_]*$", self.name):
            # Allow *args and **kwargs
            if not re.match(r"^(\*{1,2})?[a-zA-Z_][a-zA-Z0-9_]*$", self.name):
>               raise ValueError(f"Invalid parameter name: {self.name}")
E               ValueError: Invalid parameter name: données

codedocsync\parser\docstring_models.py:38: ValueError
____________ TestFullPipeline.test_parse_analyze_suggest_workflow _____________

self = <tests.suggestions.test_e2e_integration.TestFullPipeline object at 0x000001E7C0E796D0>

    def test_parse_analyze_suggest_workflow(self) -> None:
        """Test full workflow from parsing to suggestion generation."""
        # Step 1: Create test function
        function = create_test_function(
            name="calculate_total",
            params=["items", "tax_rate"],
            return_type="float",
            docstring="""Calculate total with tax.

            Args:
                items: List of items
                rate: Tax rate

            Returns:
                Total amount
            """,
        )

        # Step 2: Create matched pair
        pair = MatchedPair(
            function=function,
            docstring=create_parsed_docstring(
                summary="Calculate total with tax.",
                params={
                    "items": "List of items",
                    "rate": "Tax rate",
                },
                returns="Total amount",
            ),
            confidence=MatchConfidence(
                overall=0.9,
                name_similarity=1.0,
                location_score=1.0,
                signature_similarity=0.7,
            ),
            match_type=MatchType.EXACT,
            match_reason="Same file documentation",
        )

        # Step 3: Create analysis result with issues
        issues = [
            create_test_issue(
                issue_type="parameter_name_mismatch",
                description="Parameter 'rate' doesn't match 'tax_rate' in code",
            ),
            create_test_issue(
                issue_type="return_type_mismatch",
                description="Return type not documented",
                severity="medium",
            ),
        ]

        analysis_result = AnalysisResult(
            matched_pair=pair,
            issues=issues,
            used_llm=False,
            analysis_time_ms=15.3,
        )

        # Step 4: Generate suggestions
        config = SuggestionConfig(default_style="google")
        enhanced_result = enhance_with_suggestions(analysis_result, config)

        # Verify complete pipeline
        assert enhanced_result is not None
        assert len(enhanced_result.issues) == 2

        # Check parameter mismatch suggestion
        param_issue = enhanced_result.issues[0]
>       assert param_issue.rich_suggestion is not None
E       assert None is not None
E        +  where None = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description="Parameter 'rate' doesn't match '...ismatch', line_number=10, confidence=0.95, details={}, rich_suggestion=None, formatted_output=None, ranking_score=None).rich_suggestion

tests\suggestions\test_e2e_integration.py:113: AssertionError
------------------------------ Captured log call ------------------------------
WARNING  codedocsync.suggestions.integration:integration.py:227 Generator failed for parameter_name_mismatch: 'DocstringParameter' object has no attribute 'type_annotation'
___________________ TestFullPipeline.test_batch_processing ____________________

self = <tests.suggestions.test_e2e_integration.TestFullPipeline object at 0x000001E7C0E79590>

    def test_batch_processing(self) -> None:
        """Test processing multiple functions in batch."""
        # Create multiple test scenarios
        test_cases: list[dict[str, Any]] = [
            {
                "name": "func1",
                "params": ["x", "y"],
                "issue": "parameter_missing",
                "missing": "y",
            },
            {
                "name": "func2",
                "params": ["data"],
                "issue": "missing_returns",
                "return_type": "Dict[str, Any]",
            },
            {
                "name": "func3",
                "params": ["value"],
                "issue": "missing_raises",
                "exceptions": ["ValueError"],
            },
        ]

        results = []
        for case in test_cases:
            function = create_test_function(
                name=case["name"],
                params=case["params"],
                return_type=case.get("return_type"),
            )

            issue = create_test_issue(
                issue_type=case["issue"],
            )

            pair = MatchedPair(
                function=function,
                docstring=None,
                confidence=MatchConfidence(
                    overall=0.9,
                    name_similarity=1.0,
                    location_score=1.0,
                    signature_similarity=0.9,
                ),
                match_type=MatchType.EXACT,
                match_reason="Test",
            )

            result = AnalysisResult(
                matched_pair=pair,
                issues=[issue],
                used_llm=False,
                analysis_time_ms=10.0,
            )

            results.append(result)

        # Process batch
        config = SuggestionConfig()

        enhanced_results = enhance_multiple_with_suggestions(results, config)

        # Verify batch results
        assert len(enhanced_results) == 3
        enhanced_result: EnhancedAnalysisResult
        for enhanced_result in enhanced_results:
            assert len(enhanced_result.issues) > 0
>           assert enhanced_result.issues[0].rich_suggestion is not None
E           AssertionError: assert None is not None
E            +  where None = EnhancedIssue(issue_type='parameter_missing', severity='critical', description='Test issue of type parameter_missing',...missing', line_number=10, confidence=0.95, details={}, rich_suggestion=None, formatted_output=None, ranking_score=None).rich_suggestion

tests\suggestions\test_e2e_integration.py:190: AssertionError
------------------------------ Captured log call ------------------------------
WARNING  codedocsync.suggestions.integration:integration.py:227 Generator failed for parameter_missing: original_text cannot be empty
WARNING  codedocsync.suggestions.integration:integration.py:227 Generator failed for missing_returns: original_text cannot be empty
WARNING  codedocsync.suggestions.integration:integration.py:227 Generator failed for missing_raises: original_text cannot be empty
______________ TestCLIIntegration.test_suggest_command_with_file ______________

self = <tests.suggestions.test_e2e_integration.TestCLIIntegration object at 0x000001E7C0E79950>
tmp_path = WindowsPath('C:/Users/issak/AppData/Local/Temp/pytest-of-issak/pytest-64/test_suggest_command_with_file0')

        def test_suggest_command_with_file(self, tmp_path: Path) -> None:
            """Test suggest command with a Python file."""
            # Create test file
            test_file = tmp_path / "test.py"
            test_file.write_text(
                '''
    def process_data(items, threshold=0.5):
        """Process data items.

        Args:
            items: List of items
            limit: Threshold value

        Returns:
            Processed items
        """
        return [item for item in items if item > threshold]
    '''
            )

            # Mock the analysis pipeline
>           with patch("codedocsync.main.UnifiedMatchingFacade") as mock_facade:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_e2e_integration.py:226:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python313\Lib\unittest\mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001E784D20AD0>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'codedocsync.main' from 'C:\\Users\\issak\\CodeDocSync\\codedocsync\\main.py'> does not have the attribute 'UnifiedMatchingFacade'

C:\Python313\Lib\unittest\mock.py:1467: AttributeError
_______________ TestCLIIntegration.test_suggest_command_dry_run _______________

self = <tests.suggestions.test_e2e_integration.TestCLIIntegration object at 0x000001E7C0E44FC0>
tmp_path = WindowsPath('C:/Users/issak/AppData/Local/Temp/pytest-of-issak/pytest-64/test_suggest_command_dry_run0')

    def test_suggest_command_dry_run(self, tmp_path: Path) -> None:
        """Test suggest command with dry-run option."""
        test_file = tmp_path / "test.py"
        test_file.write_text("def test(): pass")

>       with patch("codedocsync.main.UnifiedMatchingFacade"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_e2e_integration.py:280:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python313\Lib\unittest\mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001E784D22430>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'codedocsync.main' from 'C:\\Users\\issak\\CodeDocSync\\codedocsync\\main.py'> does not have the attribute 'UnifiedMatchingFacade'

C:\Python313\Lib\unittest\mock.py:1467: AttributeError
_________ TestPerformanceMonitoring.test_performance_recommendations __________

self = <tests.suggestions.test_e2e_integration.TestPerformanceMonitoring object at 0x000001E7C0E79BD0>

    def test_performance_recommendations(self) -> None:
        """Test performance optimization recommendations."""
        monitor = get_performance_monitor()
        monitor.reset()

        # Simulate slow operations
        import time

        for _i in range(5):
            with monitor.measure("slow_operation"):
                time.sleep(0.1)  # Simulate slow operation

        recommendations = monitor.get_recommendations()
>       assert len(recommendations) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests\suggestions\test_e2e_integration.py:331: AssertionError
___________ TestProductionScenarios.test_large_codebase_simulation ____________

self = <tests.suggestions.test_e2e_integration.TestProductionScenarios object at 0x000001E7C0E79F90>

    def test_large_codebase_simulation(self) -> None:
        """Test handling of large codebase with many functions."""
        # Simulate 100 functions with various issues
        num_functions = 100
        results = []

        issue_types = [
            "parameter_name_mismatch",
            "parameter_missing",
            "return_type_mismatch",
            "missing_raises",
            "description_vague",
        ]

        for i in range(num_functions):
            function = create_test_function(
                name=f"function_{i}",
                params=[f"param_{j}" for j in range(i % 5 + 1)],
            )

>           issue = create_test_issue(
                issue_type=issue_types[i % len(issue_types)],
                severity=["critical", "high", "medium", "low"][i % 4],
            )

tests\suggestions\test_e2e_integration.py:419:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='critical', description='Test issue of type description_vague', suggestion='Fix description_vague', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
____ TestParameterSuggestionGenerator.test_parameter_name_mismatch_simple _____

self = <tests.suggestions.test_generators.TestParameterSuggestionGenerator object at 0x000001E7C0E7A350>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000001E7C1142390>

    def test_parameter_name_mismatch_simple(self, generator: Any) -> None:
        """Test fixing simple parameter name mismatch."""
        # Create function with mismatched parameter
        function = create_test_function(
            name="authenticate_user",
            params=["username", "password"],
            docstring=DOCSTRING_EXAMPLES["google_simple"],
        )

        # Create issue
        issue = create_test_issue(
            issue_type="parameter_name_mismatch",
            description="Parameter 'email' doesn't match 'username' in code",
            details={"expected": "username", "found": "email"},
        )

        # Create context
        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                summary="Simple function description.",
                params={"email": "First parameter", "password": "Second parameter"},
            ),
            project_style="google",
        )

        # Generate suggestion
        suggestion = generator.generate(context)

        # Verify suggestion
        assert suggestion.suggestion_type == SuggestionType.PARAMETER_UPDATE
>       assert "username" in suggestion.suggested_text
E       AssertionError: assert 'username' in 'Simple function description.\n\nArgs:\n    email: First parameter\n    password: Second parameter'
E        +  where 'Simple function description.\n\nArgs:\n    email: First parameter\n    password: Second parameter' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='Simple function descr..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:72: AssertionError
___________ TestParameterSuggestionGenerator.test_parameter_missing ___________

self = <tests.suggestions.test_generators.TestParameterSuggestionGenerator object at 0x000001E7C0E7A490>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000001E7F06C3590>

    def test_parameter_missing(self, generator: Any) -> None:
        """Test adding missing parameter documentation."""
        function = create_test_function(params=["username", "password", "remember_me"])

        issue = create_test_issue(
            issue_type="parameter_missing",
            description="Parameter 'remember_me' is not documented",
            details={"missing_param": "remember_me", "type_annotation": "bool"},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                params={"username": "User's username", "password": "User's password"}
            ),
            project_style="google",
        )

        suggestion = generator.generate(context)

        assert "remember_me" in suggestion.suggested_text
>       assert "bool" in suggestion.suggested_text
E       assert 'bool' in '"""\nTest function.\n\nArgs:\n    username (str): User\'s username\n    password (str): User\'s password\n    remember_me (int): Description for remember_me (int)\n"""'
E        +  where '"""\nTest function.\n\nArgs:\n    username (str): User\'s username\n    password (str): User\'s password\n    remember_me (int): Description for remember_me (int)\n"""' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text="Test function.\n\nArg..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:99: AssertionError
________ TestParameterSuggestionGenerator.test_parameter_type_mismatch ________

self = <tests.suggestions.test_generators.TestParameterSuggestionGenerator object at 0x000001E7C0E45350>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000001E7F06C0770>

    def test_parameter_type_mismatch(self, generator: Any) -> None:
        """Test fixing parameter type mismatch."""
        function = create_test_function(params=["count", "name"])

        issue = create_test_issue(
            issue_type="parameter_type_mismatch",
            description="Parameter 'count' type mismatch",
            details={
                "param_name": "count",
                "expected_type": "int",
                "documented_type": "str",
            },
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                params={"count": "Number of items", "name": "Item name"}
            ),
            project_style="google",
        )

        suggestion = generator.generate(context)

>       assert "count (int)" in suggestion.suggested_text
E       assert 'count (int)' in '"""\nTest function.\n\nArgs:\n    count (str): Number of items\n    name (int): Item name\n"""'
E        +  where '"""\nTest function.\n\nArgs:\n    count (str): Number of items\n    name (int): Item name\n"""' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='Test function.\n\nArg..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:127: AssertionError
________ TestParameterSuggestionGenerator.test_preserves_descriptions _________

self = <tests.suggestions.test_generators.TestParameterSuggestionGenerator object at 0x000001E7C0E45480>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000001E7F06C0230>

    def test_preserves_descriptions(self, generator: Any) -> None:
        """Test that existing descriptions are preserved."""
        function = create_test_function(params=["data", "config"])

        issue = create_test_issue(
            issue_type="parameter_name_mismatch",
            details={"expected": "config", "found": "settings"},
        )

        detailed_desc = (
            "Configuration object with multiple settings\n"
            "        that control the behavior of the function.\n"
            "        Can be None for default settings."
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                params={"data": "Input data to process", "settings": detailed_desc}
            ),
            project_style="google",
        )

        suggestion = generator.generate(context)

        # Should preserve the detailed description
        assert (
            "Configuration object with multiple settings" in suggestion.suggested_text
        )
>       assert "config" in suggestion.suggested_text
E       AssertionError: assert 'config' in 'Test function.\n\nArgs:\n    data: Input data to process\n    settings: Configuration object with multiple settings\n        that control the behavior of the function.\n        Can be None for default settings.'
E        +  where 'Test function.\n\nArgs:\n    data: Input data to process\n    settings: Configuration object with multiple settings\n        that control the behavior of the function.\n        Can be None for default settings.' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='Test function.\n\nArg..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:160: AssertionError
___________ TestReturnSuggestionGenerator.test_return_type_mismatch ___________

self = <tests.suggestions.test_generators.TestReturnSuggestionGenerator object at 0x000001E7C0E7A5D0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000001E7F05FBBD0>

    def test_return_type_mismatch(self, generator: Any) -> None:
        """Test fixing return type mismatch."""
        function = create_test_function(
            name="calculate_total",
            return_type="float",
            docstring="Calculate total.\n\nReturns:\n    int: The total",
        )

        issue = create_test_issue(
            issue_type="return_type_mismatch",
            description="Return type mismatch",
            details={"expected_type": "float", "documented_type": "int"},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(returns="The total"),
            project_style="google",
        )

        suggestion = generator.generate(context)

>       assert "float" in suggestion.suggested_text
E       assert 'float' in '"""\nTest function.\n\nReturns:\n    None: None\n"""'
E        +  where '"""\nTest function.\n\nReturns:\n    None: None\n"""' = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Test function.\n\nReturns:\..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:196: AssertionError
_______ TestReturnSuggestionGenerator.test_missing_return_documentation _______

self = <tests.suggestions.test_generators.TestReturnSuggestionGenerator object at 0x000001E7C0E7A710>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000001E7F05FA140>

    def test_missing_return_documentation(self, generator: Any) -> None:
        """Test adding missing return documentation."""
        function = create_test_function(
            name="process_data", return_type="Dict[str, Any]"
        )

        issue = create_test_issue(
            issue_type="missing_returns",
            description="Missing return documentation",
            details={"return_type": "Dict[str, Any]"},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(summary="Process data."),
            project_style="google",
        )

        suggestion = generator.generate(context)

>       assert "Returns:" in suggestion.suggested_text
E       AssertionError: assert 'Returns:' in 'Process data.'
E        +  where 'Process data.' = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Process data.', suggested_t..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:220: AssertionError
________ TestReturnSuggestionGenerator.test_generator_function_return _________

self = <tests.suggestions.test_generators.TestReturnSuggestionGenerator object at 0x000001E7C0E456E0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000001E7F0612550>

    def test_generator_function_return(self, generator: Any) -> None:
        """Test documenting generator functions."""
        function = create_test_function(
            name="iterate_items", return_type="Generator[int, None, None]"
        )

        issue = create_test_issue(
            issue_type="return_type_mismatch",
            details={"is_generator": True, "yield_type": "int"},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(returns="Items"),
            project_style="google",
        )

        suggestion = generator.generate(context)

>       assert (
            "Yields:" in suggestion.suggested_text
            or "Generator" in suggestion.suggested_text
        )
E       assert ('Yields:' in '"""\nTest function.\n\nReturns:\n    None: None\n"""' or 'Generator' in '"""\nTest function.\n\nReturns:\n    None: None\n"""')
E        +  where '"""\nTest function.\n\nReturns:\n    None: None\n"""' = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Test function.\n\nReturns:\..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text
E        +  and   '"""\nTest function.\n\nReturns:\n    None: None\n"""' = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Test function.\n\nReturns:\..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:243: AssertionError
_____ TestRaisesSuggestionGenerator.test_updates_existing_raises_section ______

self = <tests.suggestions.test_generators.TestRaisesSuggestionGenerator object at 0x000001E7C0E7A990>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000001E7F04FE8B0>

    def test_updates_existing_raises_section(self, generator: Any) -> None:
        """Test updating existing raises section."""
        function = create_test_function(name="process")

        issue = create_test_issue(
            issue_type="missing_raises",
            details={"missing_exceptions": [{"type": "RuntimeError"}]},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                raises={"ValueError": "If value is invalid"}
            ),
            project_style="google",
        )

        suggestion = generator.generate(context)

        # Should preserve existing and add new
        assert "ValueError: If value is invalid" in suggestion.suggested_text
>       assert "RuntimeError" in suggestion.suggested_text
E       AssertionError: assert 'RuntimeError' in 'Test function.\n\nRaises:\n    ValueError: If value is invalid'
E        +  where 'Test function.\n\nRaises:\n    ValueError: If value is invalid' = Suggestion(suggestion_type=<SuggestionType.RAISES_UPDATE: 'raises_update'>, original_text='Test function.\n\nRaises:\n..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:316: AssertionError
_______ TestBehaviorSuggestionGenerator.test_enhance_vague_description ________

self = <tests.suggestions.test_generators.TestBehaviorSuggestionGenerator object at 0x000001E7C0E7AAD0>
generator = <codedocsync.suggestions.generators.behavior_generator.BehaviorSuggestionGenerator object at 0x000001E79FB690F0>

        def test_enhance_vague_description(self, generator: Any) -> None:
            """Test enhancing vague descriptions."""
            function = create_test_function(
                name="process_data",
                source_code="""def process_data(items):
        result = []
        for item in items:
            if item > 0:
                result.append(item * 2)
        return result
    """,
            )

>           issue = create_test_issue(
                issue_type="description_vague",
                description="Description is too vague",
                severity="medium",
            )

tests\suggestions\test_generators.py:341:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Fix description_vague', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
_________ TestBehaviorSuggestionGenerator.test_identify_side_effects __________

self = <tests.suggestions.test_generators.TestBehaviorSuggestionGenerator object at 0x000001E7C0E7AC10>
generator = <codedocsync.suggestions.generators.behavior_generator.BehaviorSuggestionGenerator object at 0x000001E7F065AC40>

        def test_identify_side_effects(self, generator: Any) -> None:
            """Test identifying and documenting side effects."""
            function = create_test_function(
                name="save_to_file",
                source_code="""def save_to_file(data, filename):
        with open(filename, 'w') as f:
            json.dump(data, f)
        logging.info(f"Saved data to {filename}")
    """,
            )

>           issue = create_test_issue(
                issue_type="description_incomplete", severity="medium"
            )

tests\suggestions\test_generators.py:371:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_incomplete', severity='medium', description='Test issue of type description_incomplete', suggestion='Fix description_incomplete', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_incomplete'

codedocsync\analyzer\models.py:63: ValueError
_________ TestExampleSuggestionGenerator.test_generate_basic_example __________

self = <tests.suggestions.test_generators.TestExampleSuggestionGenerator object at 0x000001E7C0E7AD50>
generator = <codedocsync.suggestions.generators.example_generator.ExampleSuggestionGenerator object at 0x000001E79DBDDBA0>

    def test_generate_basic_example(self, generator: Any) -> None:
        """Test generating basic usage example."""
        function = create_test_function(
            name="add_numbers", params=["a", "b"], return_type="int"
        )

>       issue = create_test_issue(
            issue_type="missing_examples",
            description="No usage examples provided",
            severity="low",
        )

tests\suggestions\test_generators.py:403:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='No usage examples provided', suggestion='Fix missing_examples', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
_____ TestEdgeCaseSuggestionGenerator.test_property_method_documentation ______

self = <tests.suggestions.test_generators.TestEdgeCaseSuggestionGenerator object at 0x000001E7C0E7AFD0>
generator = <codedocsync.suggestions.generators.edge_case_handlers.EdgeCaseSuggestionGenerator object at 0x000001E7F04FE8B0>

    def test_property_method_documentation(self, generator: Any) -> None:
        """Test documenting property methods."""
        function = create_test_function(name="temperature")
        function.signature.decorators = ["property"]

>       issue = create_test_issue(
            issue_type="property_documentation",
            description="Property lacks proper documentation",
        )

tests\suggestions\test_generators.py:465:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='property_documentation', severity='critical', description='Property lacks proper documentation', suggestion='Fix property_documentation', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'property_documentation'

codedocsync\analyzer\models.py:63: ValueError
_______ TestEdgeCaseSuggestionGenerator.test_classmethod_documentation ________

self = <tests.suggestions.test_generators.TestEdgeCaseSuggestionGenerator object at 0x000001E7C0E7B110>
generator = <codedocsync.suggestions.generators.edge_case_handlers.EdgeCaseSuggestionGenerator object at 0x000001E7F04FFA80>

    def test_classmethod_documentation(self, generator: Any) -> None:
        """Test documenting class methods."""
        function = create_test_function(
            name="from_dict", params=["cls", "data"], return_type="MyClass"
        )
        function.signature.decorators = ["classmethod"]

>       issue = create_test_issue(
            issue_type="classmethod_documentation",
            description="Class method documentation includes 'cls' parameter",
        )

tests\suggestions\test_generators.py:492:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='classmethod_documentation', severity='critical', description="Class method documentation includes 'cls' parameter", suggestion='Fix classmethod_documentation', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'classmethod_documentation'

codedocsync\analyzer\models.py:63: ValueError
_______ TestEdgeCaseSuggestionGenerator.test_magic_method_documentation _______

self = <tests.suggestions.test_generators.TestEdgeCaseSuggestionGenerator object at 0x000001E7C0E45810>
generator = <codedocsync.suggestions.generators.edge_case_handlers.EdgeCaseSuggestionGenerator object at 0x000001E7EE22F1D0>

    def test_magic_method_documentation(self, generator: Any) -> None:
        """Test documenting magic methods."""
        function = create_test_function(
            name="__init__", params=["self", "name", "value"]
        )

>       issue = create_test_issue(
            issue_type="magic_method_documentation",
            description="Magic method needs appropriate documentation",
        )

tests\suggestions\test_generators.py:518:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='magic_method_documentation', severity='critical', description='Magic method needs appropriate documentation', suggestion='Fix magic_method_documentation', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'magic_method_documentation'

codedocsync\analyzer\models.py:63: ValueError
_________ TestGeneratorIntegration.test_multiple_issues_same_function _________

self = <tests.suggestions.test_generators.TestGeneratorIntegration object at 0x000001E7C0E7B250>

    def test_multiple_issues_same_function(self) -> None:
        """Test handling multiple issues for the same function."""
        config = SuggestionConfig(default_style="google")

        # Create function with multiple issues
        function = create_test_function(
            name="process_data",
            params=["data", "options"],
            return_type="Dict[str, Any]",
        )

        # Issue 1: Missing parameter
        param_gen = ParameterSuggestionGenerator(config)
        param_issue = create_test_issue(
            issue_type="parameter_missing", details={"missing_param": "options"}
        )

        # Issue 2: Missing return
        return_gen = ReturnSuggestionGenerator(config)
        return_issue = create_test_issue(
            issue_type="missing_returns", details={"return_type": "Dict[str, Any]"}
        )

        # Generate suggestions
        docstring = create_parsed_docstring(params={"data": "Input data"})

        param_suggestion = param_gen.generate(
            SuggestionContext(param_issue, function, docstring, "google")
        )
        return_suggestion = return_gen.generate(
            SuggestionContext(return_issue, function, docstring, "google")
        )

        # Both should be valid
        assert param_suggestion.confidence >= 0.8
>       assert return_suggestion.confidence >= 0.8
E       AssertionError: assert 0.1 >= 0.8
E        +  where 0.1 = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Test function.\n\nArgs:\n  ..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).confidence

tests\suggestions\test_generators.py:577: AssertionError
____ TestDocstringMerger.test_smart_parameter_merge_preserve_descriptions _____

self = <tests.suggestions.test_merging.TestDocstringMerger object at 0x000001E7C0EC7530>
merger = <codedocsync.suggestions.merging.DocstringMerger object at 0x000001E7A1D88E90>

    def test_smart_parameter_merge_preserve_descriptions(self, merger: Any) -> None:
        """Test intelligent parameter merging with description preservation."""
        original_params = [
            DocstringParameter(
                name="param1",
                type_str="str",
                description="Detailed description that should be preserved",
            ),
            DocstringParameter(
                name="param2",
                type_str="int",
                description="Another detailed description",
            ),
        ]

        new_params = [
            DocstringParameter(
                name="param1",
                type_str="Optional[str]",  # Type updated
                description="Generic description",  # Generic description
            ),
            DocstringParameter(
                name="param3",  # New parameter
                type_str="bool",
                description="New parameter description",
            ),
        ]

        merged = merger.smart_parameter_merge(
            original_params, new_params, preserve_descriptions=True
        )

        assert len(merged) == 2

        # First parameter should have new type but preserved description
        param1 = next(p for p in merged if p.name == "param1")
        assert param1.type_str == "Optional[str]"
>       assert param1.description == "Detailed description that should be preserved"
E       AssertionError: assert 'Generic description' == 'Detailed des... be preserved'
E
E         - Detailed description that should be preserved
E         + Generic description

tests\suggestions\test_merging.py:174: AssertionError
_______ TestDocstringMerger.test_parse_section_boundaries_google_style ________

self = <tests.suggestions.test_merging.TestDocstringMerger object at 0x000001E7C0DEFDF0>
merger = <codedocsync.suggestions.merging.DocstringMerger object at 0x000001E7F05F9480>

    def test_parse_section_boundaries_google_style(self, merger: Any) -> None:
        """Test parsing section boundaries for Google style."""
        lines = [
            '"""Function summary.',
            "",
            "Detailed description.",
            "",
            "Args:",
            "    param1: First parameter",
            "    param2: Second parameter",
            "",
            "Returns:",
            "    Return value",
            "",
            "Raises:",
            "    ValueError: When something is wrong",
            "",
            "Examples:",
            "    >>> example()",
            "    True",
            '"""',
        ]

        boundaries = merger._parse_section_boundaries(lines)

>       assert SectionType.SUMMARY in boundaries
E       AssertionError: assert <SectionType.SUMMARY: 'summary'> in {<SectionType.PARAMETERS: 'parameters'>: SectionBoundary(section_type=<SectionType.PARAMETERS: 'parameters'>, start_li...type=<SectionType.EXAMPLES: 'examples'>, start_line=14, end_line=17, header_line=None, content_lines=[14, 15, 16, 17])}
E        +  where <SectionType.SUMMARY: 'summary'> = SectionType.SUMMARY

tests\suggestions\test_merging.py:220: AssertionError
_______________ TestDocstringMerger.test_validate_merge_result ________________

self = <tests.suggestions.test_merging.TestDocstringMerger object at 0x000001E7C0E06990>
merger = <codedocsync.suggestions.merging.DocstringMerger object at 0x000001E7F071A5D0>

    def test_validate_merge_result(self, merger: Any) -> None:
        """Test validation of merge results."""
        # Valid docstring
        valid_docstring = '''"""
        Valid docstring.

        Args:
            param: Parameter description

        Returns:
            Return value
        """'''

        is_valid, errors = merger.validate_merge_result(valid_docstring)
        assert is_valid
        assert len(errors) == 0

        # Invalid docstring - unbalanced quotes
        invalid_docstring = '''"""
        Invalid docstring.

        Args:
            param: Parameter description
        """'''

        is_valid, errors = merger.validate_merge_result(invalid_docstring)
>       assert not is_valid
E       assert not True

tests\suggestions\test_merging.py:316: AssertionError
________ TestSuggestionPerformance.test_single_suggestion_performance _________

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000001E7C0EEAD50>

    def test_single_suggestion_performance(self) -> None:
        """Test that single suggestion generation is under 100ms."""
>       func = self.create_test_function(num_params=10)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:55:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_________ TestSuggestionPerformance.test_batch_suggestion_performance _________

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000001E7C0EEAE90>

    def test_batch_suggestion_performance(self) -> None:
        """Test performance with multiple analysis results."""
        results = []
        # Create 20 analysis results
        for _ in range(20):
>           func = self.create_test_function(num_params=5)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:111:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_________ TestSuggestionPerformance.test_generator_direct_performance _________

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000001E7C0E47950>

    def test_generator_direct_performance(self) -> None:
        """Test direct generator performance without integration layer."""
>       func = self.create_test_function(num_params=15)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:159:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_________ TestSuggestionPerformance.test_complex_function_performance _________

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000001E7C0E47A80>

    def test_complex_function_performance(self) -> None:
        """Test performance with complex function signatures."""
        # Create complex function with many parameters and complex types
        params = [
            FunctionParameter(
                name="data",
                type_annotation="Dict[str, List[Tuple[int, str]]]",
                is_required=True,
            ),
            FunctionParameter(
                name="processor",
                type_annotation="Callable[[Any], Tuple[bool, Dict[str, Any]]]",
                is_required=True,
            ),
            FunctionParameter(
                name="options",
                type_annotation="Dict[str, Union[str, int, float, List[str]]]",
                default_value="None",
                is_required=False,
            ),
            FunctionParameter(name="*args", type_annotation="Any", is_required=False),
            FunctionParameter(
                name="**kwargs", type_annotation="Any", is_required=False
            ),
        ]
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="complex_processor",
                parameters=params,
                return_type="Generator[Dict[str, Any], None, None]",
                is_async=True,
            ),
            docstring=RawDocstring(raw_text='""""""'),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_performance.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='complex_processor', parameters=[FunctionParameter(name='data', type_a...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestSuggestionPerformance.test_style_generation_performance[google] _____

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000001E7C0F3E7B0>
style = 'google'

    @pytest.mark.parametrize("style", ["google", "numpy", "sphinx"])
    def test_style_generation_performance(self, style: Any) -> None:
        """Test performance across different docstring styles."""
>       func = self.create_test_function(num_params=8)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:284:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestSuggestionPerformance.test_style_generation_performance[numpy] ______

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000001E7C0F18C00>
style = 'numpy'

    @pytest.mark.parametrize("style", ["google", "numpy", "sphinx"])
    def test_style_generation_performance(self, style: Any) -> None:
        """Test performance across different docstring styles."""
>       func = self.create_test_function(num_params=8)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:284:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestSuggestionPerformance.test_style_generation_performance[sphinx] _____

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000001E7C0F18D10>
style = 'sphinx'

    @pytest.mark.parametrize("style", ["google", "numpy", "sphinx"])
    def test_style_generation_performance(self, style: Any) -> None:
        """Test performance across different docstring styles."""
>       func = self.create_test_function(num_params=8)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:284:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
________________ TestSuggestionRanker.test_rank_by_confidence _________________

self = <tests.suggestions.test_ranking.TestSuggestionRanker object at 0x000001E7C0E47CE0>
critical_issue = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description='Critical parameter mismatch', su...rameter', line_number=10, confidence=0.95, details={}, rich_suggestion=None, formatted_output=None, ranking_score=29.5)
low_confidence_issue = EnhancedIssue(issue_type='description_outdated', severity='medium', description='Outdated description', suggestion='Up...cription', line_number=50, confidence=0.3, details={}, rich_suggestion=None, formatted_output=None, ranking_score=None)

    def test_rank_by_confidence(
        self, critical_issue: Any, low_confidence_issue: Any
    ) -> None:
        """Test ranking considers confidence."""
        config = RankingConfig(strategy=RankingStrategy.CONFIDENCE_FIRST)
        ranker = SuggestionRanker(config)

        issues = [low_confidence_issue, critical_issue]
        ranked = ranker.rank_suggestions(issues)

        # Higher confidence should rank higher
>       assert ranked[0].confidence > ranked[1].confidence
                                      ^^^^^^^^^
E       IndexError: list index out of range

tests\suggestions\test_ranking.py:226: IndexError
____________ TestRankingStrategies.test_confidence_first_strategy _____________

self = <tests.suggestions.test_ranking.TestRankingStrategies object at 0x000001E7C0F7C410>
critical_issue = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description='Critical parameter mismatch', su...arameter', line_number=10, confidence=0.6, details={}, rich_suggestion=None, formatted_output=None, ranking_score=26.0)
medium_issue = EnhancedIssue(issue_type='missing_raises', severity='medium', description='Missing exception documentation', suggestio...ion docs', line_number=30, confidence=0.9, details={}, rich_suggestion=None, formatted_output=None, ranking_score=19.0)

    def test_confidence_first_strategy(
        self, critical_issue: Any, medium_issue: Any
    ) -> None:
        """Test confidence-first ranking strategy."""
        config = RankingConfig(strategy=RankingStrategy.CONFIDENCE_FIRST)
        ranker = SuggestionRanker(config)

        # Set different confidences
        critical_issue.confidence = 0.6
        medium_issue.confidence = 0.9

        issues = [critical_issue, medium_issue]
        ranked = ranker.rank_suggestions(issues)

        # Medium issue should rank higher due to confidence boost
>       assert ranked[0].confidence > ranked[1].confidence
E       AssertionError: assert 0.6 > 0.9
E        +  where 0.6 = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description='Critical parameter mismatch', su...arameter', line_number=10, confidence=0.6, details={}, rich_suggestion=None, formatted_output=None, ranking_score=26.0).confidence
E        +  and   0.9 = EnhancedIssue(issue_type='missing_raises', severity='medium', description='Missing exception documentation', suggestio...ion docs', line_number=30, confidence=0.9, details={}, rich_suggestion=None, formatted_output=None, ranking_score=19.0).confidence

tests\suggestions\test_ranking.py:506: AssertionError
___________ TestSpecificIssueFixes.test_fix_parameter_name_mismatch ___________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000001E7C0F7CCD0>

    def test_fix_parameter_name_mismatch(self) -> None:
        """Test fixing parameter name mismatches."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="calculate_area",
                parameters=[
                    FunctionParameter(
                        name="width", type_annotation="float", is_required=True
                    ),
                    FunctionParameter(
                        name="height", type_annotation="float", is_required=True
                    ),
                ],
                return_type="float",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Calculate area of rectangle.
                    Args:
                        w (float): Width of rectangle.
                        h (float): Height of rectangle.
                    Returns:
                        float: Area value.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:39:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='calculate_area', parameters=[FunctionParameter(name='width', type_ann...:\n    float: Area value.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestSpecificIssueFixes.test_fix_return_type_mismatch _____________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000001E7C0F7CE10>

    def test_fix_return_type_mismatch(self) -> None:
        """Test fixing return type documentation mismatches."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="get_config",
                return_type="Optional[Dict[str, Any]]",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Get configuration settings.
                    Returns:
                        dict: Configuration dictionary.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:94:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='get_config', parameters=[], return_type='Optional[Dict[str, Any]]', i...Configuration dictionary.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
___________ TestSpecificIssueFixes.test_fix_missing_raises_complex ____________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000001E7C0F70770>

    def test_fix_missing_raises_complex(self) -> None:
        """Test fixing missing exception documentation with multiple exceptions."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="parse_json_file",
                parameters=[
                    FunctionParameter(
                        name="filepath", type_annotation="str", is_required=True
                    ),
                ],
                return_type="Dict[str, Any]",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Parse JSON file and return contents.
                    Args:
                        filepath (str): Path to JSON file.
                    Returns:
                        Dict[str, Any]: Parsed JSON data.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:138:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='parse_json_file', parameters=[FunctionParameter(name='filepath', type..., Any]: Parsed JSON data.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
__________ TestSpecificIssueFixes.test_fix_parameter_order_different __________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000001E7C0F708A0>

    def test_fix_parameter_order_different(self) -> None:
        """Test fixing when parameter order in docs doesn't match code."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="create_connection",
                parameters=[
                    FunctionParameter(
                        name="host", type_annotation="str", is_required=True
                    ),
                    FunctionParameter(
                        name="port", type_annotation="int", is_required=True
                    ),
                    FunctionParameter(
                        name="timeout",
                        type_annotation="float",
                        default_value="30.0",
                        is_required=False,
                    ),
                ],
                return_type="Connection",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Create network connection.
                    Args:
                        port (int): Port number.
                        timeout (float): Timeout in seconds.
                        host (str): Host address.
                    Returns:
                        Connection: Active connection object.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:193:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='create_connection', parameters=[FunctionParameter(name='host', type_a...Active connection object.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
______ TestSpecificIssueFixes.test_fix_missing_params_with_complex_types ______

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000001E7C0F7AC30>

    def test_fix_missing_params_with_complex_types(self) -> None:
        """Test fixing missing parameters with complex type annotations."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="process_data",
                parameters=[
                    FunctionParameter(
                        name="data", type_annotation="pd.DataFrame", is_required=True
                    ),
                    FunctionParameter(
                        name="columns",
                        type_annotation="Optional[List[str]]",
                        default_value="None",
                        is_required=False,
                    ),
                    FunctionParameter(
                        name="callback",
                        type_annotation="Callable[[int], None]",
                        default_value="None",
                        is_required=False,
                    ),
                ],
                return_type="pd.DataFrame",
            ),
            docstring=RawDocstring(raw_text='""""""'),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:254:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='process_data', parameters=[FunctionParameter(name='data', type_annota...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_______________ TestSpecificIssueFixes.test_fix_example_invalid _______________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000001E7C0F19150>

    def test_fix_example_invalid(self) -> None:
        """Test fixing invalid examples in docstring."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="square",
                parameters=[
                    FunctionParameter(
                        name="x", type_annotation="float", is_required=True
                    ),
                ],
                return_type="float",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Calculate square of a number.
                    Args:
                        x (float): Number to square.
                    Returns:
                        float: Square of x.
                    Examples:
                        >>> square(2)
                        5
                        >>> square(-3)
                        -9
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:302:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='square', parameters=[FunctionParameter(name='x', type_annotation='flo...   >>> square(-3)\n    -9\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestSpecificIssueFixes.test_fix_description_outdated _____________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000001E7C0F196A0>

    def test_fix_description_outdated(self) -> None:
        """Test fixing outdated function descriptions."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="save_data",
                parameters=[
                    FunctionParameter(
                        name="data", type_annotation="Dict[str, Any]", is_required=True
                    ),
                    FunctionParameter(
                        name="filepath", type_annotation="Path", is_required=True
                    ),
                    FunctionParameter(
                        name="compress",
                        type_annotation="bool",
                        default_value="False",
                        is_required=False,
                    ),
                ],
                return_type="None",
                is_async=True,
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Save data to CSV file.
                    Args:
                        data (dict): Data to save.
                        filepath (str): Output file path.
                    Returns:
                        bool: True if successful.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:360:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='save_data', parameters=[FunctionParameter(name='data', type_annotatio...bool: True if successful.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
______ TestDocstringStyleGeneration.test_generate_google_style_docstring ______

self = <tests.suggestions.test_suggestion_generator.TestDocstringStyleGeneration object at 0x000001E7C0F7DE50>

    def test_generate_google_style_docstring(self) -> None:
        """Test Google style docstring generation."""
        template = GoogleStyleTemplate()

        # Create proper docstring components
        parameters = [
            DocstringParameter(
                name="numbers",
                type_str="List[float]",
                description="List of numbers to average",
                is_optional=False,
            ),
            DocstringParameter(
                name="weights",
                type_str="Optional[List[float]]",
                description="Optional weights for each number",
                is_optional=True,
            ),
        ]

        returns = DocstringReturns(
            type_str="float",
            description="The weighted average",
        )

        raises = [
            DocstringRaises(
                exception_type="ValueError",
                description="If lists have different lengths",
            )
        ]

        # Generate full docstring
        docstring = template.render_complete_docstring(
            summary="Calculate weighted average of numbers.",
            parameters=parameters,
            returns=returns,
            raises=raises,
        )

        # Verify structure
        assert "Calculate weighted average of numbers." in docstring
        assert "Args:" in docstring
        assert "numbers (List[float]): List of numbers to average" in docstring
>       assert (
            "weights (Optional[List[float]]): Optional weights for each number"
            in docstring
        )
E       assert 'weights (Optional[List[float]]): Optional weights for each number' in '"""\nCalculate weighted average of numbers.\n\nArgs:\n    numbers (List[float]): List of numbers to average\n    weig...h number\n\nReturns:\n    float: The weighted average\n\nRaises:\n    ValueError: If lists have different lengths\n"""'

tests\suggestions\test_suggestion_generator.py:121: AssertionError
______ TestDocstringStyleGeneration.test_generate_numpy_style_docstring _______

self = <tests.suggestions.test_suggestion_generator.TestDocstringStyleGeneration object at 0x000001E7C0F7DF90>

    def test_generate_numpy_style_docstring(self) -> None:
        """Test NumPy style docstring generation."""
        template = NumpyStyleTemplate()

        # Create proper docstring components
        parameters = [
            DocstringParameter(
                name="numbers",
                type_str="List[float]",
                description="List of numbers to average",
                is_optional=False,
            ),
            DocstringParameter(
                name="weights",
                type_str="Optional[List[float]]",
                description="Optional weights for each number",
                is_optional=True,
            ),
        ]

        returns = DocstringReturns(
            type_str="float",
            description="The weighted average",
        )

        raises = [
            DocstringRaises(
                exception_type="ValueError",
                description="If lists have different lengths",
            )
        ]

        # Generate full docstring
        docstring = template.render_complete_docstring(
            summary="Calculate weighted average of numbers.",
            parameters=parameters,
            returns=returns,
            raises=raises,
        )

        # Verify structure
        assert "Calculate weighted average of numbers." in docstring
        assert "Parameters" in docstring
        assert "----------" in docstring
>       assert "numbers : List[float]" in docstring
E       assert 'numbers : List[float]' in '"""\nCalculate weighted average of numbers.\n\nParameters\n----------\nnumbers : list of float\n    List of numbers t...----\nresult : float\n    The weighted average\n\nRaises\n------\nValueError\n    If lists have different lengths\n"""'

tests\suggestions\test_suggestion_generator.py:181: AssertionError
______ TestDocstringStyleGeneration.test_generate_sphinx_style_docstring ______

self = <tests.suggestions.test_suggestion_generator.TestDocstringStyleGeneration object at 0x000001E7C0F716E0>

    def test_generate_sphinx_style_docstring(self) -> None:
        """Test Sphinx style docstring generation."""
        template = SphinxStyleTemplate()

        # Create proper docstring components
        parameters = [
            DocstringParameter(
                name="numbers",
                type_str="List[float]",
                description="List of numbers to average",
                is_optional=False,
            ),
            DocstringParameter(
                name="weights",
                type_str="Optional[List[float]]",
                description="Optional weights for each number",
                is_optional=True,
            ),
        ]

        returns = DocstringReturns(
            type_str="float",
            description="The weighted average",
        )

        raises = [
            DocstringRaises(
                exception_type="ValueError",
                description="If lists have different lengths",
            )
        ]

        # Generate full docstring
        docstring = template.render_complete_docstring(
            summary="Calculate weighted average of numbers.",
            parameters=parameters,
            returns=returns,
            raises=raises,
        )

        # Verify structure
        assert "Calculate weighted average of numbers." in docstring
        assert ":param numbers:" in docstring
        assert "List of numbers to average" in docstring
>       assert ":type numbers: List[float]" in docstring
E       assert ':type numbers: List[float]' in '"""\nCalculate weighted average of numbers.\n\n:param numbers: List of numbers to average\n:type numbers: list of flo...list of float\n:returns: The weighted average\n:rtype: float\n:raises ValueError: If lists have different lengths\n"""'

tests\suggestions\test_suggestion_generator.py:242: AssertionError
_______________ TestSmartUpdates.test_preserve_existing_content _______________

self = <tests.suggestions.test_suggestion_generator.TestSmartUpdates object at 0x000001E7C0F7E0D0>

    def test_preserve_existing_content(self) -> None:
        """Test that existing docstring content is preserved during updates."""
>       function = ParsedFunction(
            signature=FunctionSignature(
                name="process_data",
                parameters=[
                    FunctionParameter(
                        name="data",
                        type_annotation="Dict[str, Any]",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="Dict[str, Any]",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=20,
        )

tests\suggestions\test_suggestion_generator.py:263:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='process_data', parameters=[FunctionParameter(name='data', type_annota...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=20, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (20)

codedocsync\parser\ast_parser.py:159: ValidationError
_________________ TestSmartUpdates.test_merge_partial_updates _________________

self = <tests.suggestions.test_suggestion_generator.TestSmartUpdates object at 0x000001E7C0F7E210>

    def test_merge_partial_updates(self) -> None:
        """Test merging partial docstring updates."""
>       function = ParsedFunction(
            signature=FunctionSignature(
                name="validate_input",
                parameters=[
                    FunctionParameter(
                        name="value",
                        type_annotation="str",
                        default_value=None,
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="strict",
                        type_annotation="bool",
                        default_value="False",
                        is_required=False,
                    ),
                ],
                return_type="bool",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=30,
        )

tests\suggestions\test_suggestion_generator.py:351:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='validate_input', parameters=[FunctionParameter(name='value', type_ann...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=30, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (30)

codedocsync\parser\ast_parser.py:159: ValidationError
__________________ TestSmartUpdates.test_fix_specific_issues __________________

self = <tests.suggestions.test_suggestion_generator.TestSmartUpdates object at 0x000001E7C0F71940>

    def test_fix_specific_issues(self) -> None:
        """Test fixing specific issues: parameter, return, and raises."""
>       function = ParsedFunction(
            signature=FunctionSignature(
                name="divide",
                parameters=[
                    FunctionParameter(
                        name="a",
                        type_annotation="float",
                        default_value=None,
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="b",
                        type_annotation="float",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="float",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=40,
        )

tests\suggestions\test_suggestion_generator.py:468:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='divide', parameters=[FunctionParameter(name='a', type_annotation='flo...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=40, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (40)

codedocsync\parser\ast_parser.py:159: ValidationError
______ TestPerformanceBenchmarks.test_suggestion_generation_performance _______

self = <tests.suggestions.test_suggestion_generator.TestPerformanceBenchmarks object at 0x000001E7C0F7E350>

    def test_suggestion_generation_performance(self) -> None:
        """Test that suggestion generation is < 100ms."""
>       function = ParsedFunction(
            signature=FunctionSignature(
                name="test_func",
                parameters=[
                    FunctionParameter(
                        name="param1",
                        type_annotation="str",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="str",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=50,
        )

tests\suggestions\test_suggestion_generator.py:574:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_func', parameters=[FunctionParameter(name='param1', type_annotat...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=50, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (50)

codedocsync\parser\ast_parser.py:159: ValidationError
______________ TestPerformanceBenchmarks.test_template_accuracy _______________

self = <tests.suggestions.test_suggestion_generator.TestPerformanceBenchmarks object at 0x000001E7C0F7E490>

    def test_template_accuracy(self) -> None:
        """Test that all templates produce 100% valid syntax."""
        templates = [
            GoogleStyleTemplate(),
            NumpyStyleTemplate(),
            SphinxStyleTemplate(),
        ]

        parsers = {
            "google": GoogleParser(),
            "numpy": NumpydocParser(),
            "sphinx": parse,  # Sphinx uses general parser
        }

>       ParsedFunction(
            signature=FunctionSignature(
                name="complex_function",
                parameters=[
                    FunctionParameter(
                        name="required_param",
                        type_annotation="str",
                        default_value=None,
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="optional_param",
                        type_annotation="int",
                        default_value="0",
                        is_required=False,
                    ),
                ],
                return_type="Tuple[str, int]",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=60,
        )

tests\suggestions\test_suggestion_generator.py:635:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='complex_function', parameters=[FunctionParameter(name='required_param...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=60, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (60)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestEdgeCasesAndRobustness.test_empty_function_docstring_generation _____

self = <tests.suggestions.test_suggestion_generator.TestEdgeCasesAndRobustness object at 0x000001E7C0F7E5D0>

    def test_empty_function_docstring_generation(self) -> None:
        """Test generating docstring for function with no parameters or return."""
>       ParsedFunction(
            signature=FunctionSignature(
                name="do_nothing",
                parameters=[],
                return_type="None",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=70,
        )

tests\suggestions\test_suggestion_generator.py:741:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='do_nothing', parameters=[], return_type='None', is_async=False, is_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=70, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (70)

codedocsync\parser\ast_parser.py:159: ValidationError
__________ TestEdgeCasesAndRobustness.test_complex_type_annotations ___________

self = <tests.suggestions.test_suggestion_generator.TestEdgeCasesAndRobustness object at 0x000001E7C0F7E710>

    def test_complex_type_annotations(self) -> None:
        """Test handling of complex type annotations."""
>       ParsedFunction(
            signature=FunctionSignature(
                name="process_complex_types",
                parameters=[
                    FunctionParameter(
                        name="data",
                        type_annotation="Dict[str, List[Tuple[int, str]]]",
                        default_value=None,
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="callback",
                        type_annotation="Callable[[str], Awaitable[None]]",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="AsyncIterator[Dict[str, Any]]",
                decorators=[],
                is_async=True,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=80,
        )

tests\suggestions\test_suggestion_generator.py:771:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='process_complex_types', parameters=[FunctionParameter(name='data', ty...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=80, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (80)

codedocsync\parser\ast_parser.py:159: ValidationError
___________ TestEdgeCasesAndRobustness.test_multiline_descriptions ____________

self = <tests.suggestions.test_suggestion_generator.TestEdgeCasesAndRobustness object at 0x000001E7C0F71A70>

    def test_multiline_descriptions(self) -> None:
        """Test handling of multiline descriptions."""
>       ParsedFunction(
            signature=FunctionSignature(
                name="complex_algorithm",
                parameters=[
                    FunctionParameter(
                        name="input_data",
                        type_annotation="np.ndarray",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="np.ndarray",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=90,
        )

tests\suggestions\test_suggestion_generator.py:833:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='complex_algorithm', parameters=[FunctionParameter(name='input_data', ...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=90, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (90)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestTypeAnnotationFormatter.test_format_complex_types ____________

self = <tests.suggestions.test_type_formatter.TestTypeAnnotationFormatter object at 0x000001E7C0F59350>
google_formatter = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x000001E7F06892B0>

    def test_format_complex_types(self, google_formatter: Any) -> None:
        """Test formatting of complex types."""
        # Callable should be simplified
>       assert (
            google_formatter.format_for_docstring("Callable[[int, str], bool]")
            == "callable"
        )
E       AssertionError: assert 'Callable[[int, str], bool]' == 'callable'
E
E         - callable
E         + Callable[[int, str], bool]

tests\suggestions\test_type_formatter.py:102: AssertionError
_____________ TestTypeAnnotationFormatter.test_assess_complexity ______________

self = <tests.suggestions.test_type_formatter.TestTypeAnnotationFormatter object at 0x000001E7C0FA05F0>
google_formatter = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x000001F18480A330>

    def test_assess_complexity(self, google_formatter: Any) -> None:
        """Test complexity assessment."""
        # Simple types
        assert google_formatter._assess_complexity("str") == TypeComplexity.SIMPLE
        assert google_formatter._assess_complexity("int") == TypeComplexity.SIMPLE

        # Generic types
        assert (
            google_formatter._assess_complexity("List[str]") == TypeComplexity.GENERIC
        )
        assert (
            google_formatter._assess_complexity("Dict[str, Any]")
            == TypeComplexity.GENERIC
        )

        # Union types
        assert (
            google_formatter._assess_complexity("Union[str, int]")
            == TypeComplexity.UNION
        )
        assert (
            google_formatter._assess_complexity("Optional[str]") == TypeComplexity.UNION
        )

        # Complex types
>       assert (
            google_formatter._assess_complexity("Callable[[int], str]")
            == TypeComplexity.COMPLEX
        )
E       AssertionError: assert <TypeComplexity.GENERIC: 'generic'> == <TypeComplexity.COMPLEX: 'complex'>
E        +  where <TypeComplexity.GENERIC: 'generic'> = _assess_complexity('Callable[[int], str]')
E        +    where _assess_complexity = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x000001F18480A330>._assess_complexity
E        +  and   <TypeComplexity.COMPLEX: 'complex'> = TypeComplexity.COMPLEX

tests\suggestions\test_type_formatter.py:152: AssertionError
___________ TestTypeAnnotationFormatter.test_new_style_union_syntax ___________

self = <tests.suggestions.test_type_formatter.TestTypeAnnotationFormatter object at 0x000001E7C0FF34D0>
google_formatter = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x000001F1848F22D0>

    def test_new_style_union_syntax(self, google_formatter: Any) -> None:
        """Test Python 3.10+ union syntax (Union[A, B])."""
        result = google_formatter.format_for_docstring("Union[str, int]")
        assert result == "str or int"

        result = google_formatter.format_for_docstring("Union[str, int] | float")
>       assert result == "str or int or float"
E       AssertionError: assert 'str or int' == 'str or int or float'
E
E         - str or int or float
E         + str or int

tests\suggestions\test_type_formatter.py:265: AssertionError
__________ TestComplexTypeScenarios.test_very_long_type_annotations ___________

self = <tests.suggestions.test_type_formatter.TestComplexTypeScenarios object at 0x000001E7C0F7ED50>
formatter = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x000001F1848F1DF0>

    def test_very_long_type_annotations(self, formatter: Any) -> None:
        """Test very long type annotations."""
        long_type = "Callable[[Dict[str, List[Tuple[int, str]]], Union[List[Dict[str, Any]], None]]"
        result = formatter.format_for_docstring(long_type)
        # Should be simplified to "callable"
>       assert result == "callable"
E       AssertionError: assert 'Callable[[Di...Any]], None]]' == 'callable'
E
E         - callable
E         + Callable[[Dict[str, List[Tuple[int, str]]], Union[List[Dict[str, Any]], None]]

tests\suggestions\test_type_formatter.py:289: AssertionError
_______ TestTemplateSyntaxValidation.test_return_documentation_validity _______

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000001E7C0F728B0>

    def test_return_documentation_validity(self) -> None:
        """Test return documentation produces valid syntax."""
        generator = ReturnSuggestionGenerator()
        test_returns = [
            {"type": "int", "description": "Count of items"},
            {"type": "List[str]", "description": "List of names"},
            {"type": "Optional[Dict[str, Any]]", "description": "Data or None"},
            {"type": "Generator[int, None, None]", "description": "Number generator"},
        ]
        for style in ["google", "numpy", "sphinx"]:
            for ret in test_returns:
>               func = ParsedFunction(
                    signature=FunctionSignature(
                        name="test_func", return_type=ret["type"]
                    ),
                    docstring=RawDocstring(raw_text='""""""'),
                    file_path="test.py",
                    line_number=1,
                )

tests\suggestions\test_validation.py:213:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_func', parameters=[], return_type='int', is_async=False, is_meth...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_______ TestTemplateSyntaxValidation.test_raises_documentation_validity _______

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000001E7C0F7AD50>

    def test_raises_documentation_validity(self) -> None:
        """Test exception documentation produces valid syntax."""
        generator = RaisesSuggestionGenerator()
        exceptions = [
            ["ValueError", "TypeError"],
            ["FileNotFoundError", "PermissionError", "OSError"],
            ["CustomError"],
        ]
        for style in ["google", "numpy", "sphinx"]:
            for exc_list in exceptions:
>               func = ParsedFunction(
                    signature=FunctionSignature(name="test_func"),
                    docstring=RawDocstring(raw_text='""""""'),
                    file_path="test.py",
                    line_number=1,
                )

tests\suggestions\test_validation.py:246:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_func', parameters=[], return_type=None, is_async=False, is_metho...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
________ TestTemplateSyntaxValidation.test_complete_docstring_validity ________

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000001E7C0F1AAD0>

    def test_complete_docstring_validity(self) -> None:
        """Test complete docstrings with all sections are valid."""
        # Create a complex function
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="process_data",
                parameters=[
                    FunctionParameter(
                        name="data",
                        type_annotation="List[Dict[str, Any]]",
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="validate",
                        type_annotation="bool",
                        default_value="True",
                        is_required=False,
                    ),
                ],
                return_type="ProcessedResult",
            ),
            docstring=RawDocstring(raw_text='""""""'),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_validation.py:270:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='process_data', parameters=[FunctionParameter(name='data', type_annota...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestTemplateSyntaxValidation.test_edge_case_validity _____________

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000001E7C0F1ABE0>

    def test_edge_case_validity(self) -> None:
        """Test edge cases produce valid syntax."""
        edge_cases: list[dict[str, Any]] = [
            # Empty parameter list
            {
                "params": [],
                "returns": None,
                "raises": [],
            },
            # Very long type annotations
            {
                "params": [
                    {
                        "name": "complex_param",
                        "type": "Dict[str, List[Tuple[int, str, Dict[str, Any]]]]",
                        "description": "Very complex nested type",
                    }
                ],
                "returns": "Tuple[bool, Dict[str, List[int]], Optional[str]]",
                "raises": ["Exception"],
            },
            # Special characters in descriptions
            {
                "params": [
                    {
                        "name": "pattern",
                        "type": "str",
                        "description": "Pattern with special chars: \"quotes\", 'single', \\backslash",
                    }
                ],
                "returns": "bool",
                "raises": [],
            },
        ]
        for style in ["google", "numpy", "sphinx"]:
            for case in edge_cases:
                # Build a complete docstring
                if style == "google":
                    docstring = '"""Test function.\n\n'
                    if case["params"]:
                        docstring += "Args:\n"
                        for p in case["params"]:
                            docstring += (
                                f"    {p['name']} ({p['type']}): {p['description']}\n"
                            )
                    if case["returns"]:
                        docstring += f"\nReturns:\n    {case['returns']}: Result.\n"
                    if case["raises"]:
                        docstring += "\nRaises:\n"
                        for exc in case["raises"]:
                            docstring += f"    {exc}: Error.\n"
                    docstring += '"""'
>                   assert self.validate_python_syntax(docstring)
E                   assert False
E                    +  where False = validate_python_syntax('"""Test function.\n\n"""')
E                    +    where validate_python_syntax = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000001E7C0F1ABE0>.validate_python_syntax

tests\suggestions\test_validation.py:390: AssertionError
______ TestTemplateSyntaxValidation.test_multiline_descriptions_validity ______

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000001E7C0F59550>

    def test_multiline_descriptions_validity(self) -> None:
        """Test multiline descriptions produce valid syntax."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="complex_function",
                parameters=[
                    FunctionParameter(
                        name="config",
                        type_annotation="Dict[str, Any]",
                        is_required=True,
                    ),
                ],
            ),
            docstring=RawDocstring(raw_text='""""""'),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_validation.py:394:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='complex_function', parameters=[FunctionParameter(name='config', type_...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_____________________ TestCLIBasics.test_version_command ______________________

self = <tests.test_cli.TestCLIBasics object at 0x000001E7C0F7F9D0>

    def test_version_command(self) -> None:
        """Test version display."""
        result = runner.invoke(app, ["--version"])
        assert result.exit_code == 0
>       assert "0.2.0" in result.stdout or "version" in result.stdout.lower()
E       AssertionError: assert ('0.2.0' in 'CodeDocSync v0.1.0\n' or 'version' in 'codedocsync v0.1.0\n')
E        +  where 'CodeDocSync v0.1.0\n' = <Result okay>.stdout
E        +  and   'codedocsync v0.1.0\n' = <built-in method lower of str object at 0x000001F1848CCFF0>()
E        +    where <built-in method lower of str object at 0x000001F1848CCFF0> = 'CodeDocSync v0.1.0\n'.lower
E        +      where 'CodeDocSync v0.1.0\n' = <Result okay>.stdout

tests\test_cli.py:35: AssertionError
___________________ TestParseCommand.test_parse_single_file ___________________

self = <tests.test_cli.TestParseCommand object at 0x000001E7C0F7FB10>

        def test_parse_single_file(self) -> None:
            """Test parsing a single Python file."""
            test_code = '''
    def test_function(x: int, y: int) -> int:
        """Add two numbers.

        Args:
            x: First number
            y: Second number

        Returns:
            The sum
        """
        return x + y
    '''

            with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
                f.write(test_code)
                temp_path = Path(f.name)

            try:
                result = runner.invoke(app, ["parse", str(temp_path)])
                assert result.exit_code == 0
>               assert "test_function" in result.stdout
E               AssertionError: assert 'test_function' in '         Functions in C:\\\\Users\\\\issak\\\\AppData\\\\Local\\\\Temp\\\\tmpoexukk0q.py         \\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500....   \u2502        \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\\nFound 1 functions\\n'
E                +  where '         Functions in C:\\\\Users\\\\issak\\\\AppData\\\\Local\\\\Temp\\\\tmpoexukk0q.py         \\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500....   \u2502        \u2502\\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\\n\\nFound 1 functions\\n' = <Result okay>.stdout

tests\test_cli.py:64: AssertionError
____________________ TestParseCommand.test_parse_directory ____________________

self = <tests.test_cli.TestParseCommand object at 0x000001E7C0F7FC50>

        def test_parse_directory(self) -> None:
            """Test parsing a directory."""
            with tempfile.TemporaryDirectory() as tmpdir:
                # Create test files
                for i in range(3):
                    test_file = Path(tmpdir) / f"test_{i}.py"
                    test_file.write_text(
                        f'''
    def function_{i}():
        """Function {i}"""
        pass
    '''
                    )

                result = runner.invoke(app, ["parse", tmpdir])
>               assert result.exit_code == 0
E               assert 1 == 0
E                +  where 1 = <Result SystemExit(1)>.exit_code

tests\test_cli.py:87: AssertionError
------------------------------ Captured log call ------------------------------
ERROR    codedocsync.parser.ast_parser:ast_parser.py:210 Permission denied: C:\Users\issak\AppData\Local\Temp\tmpl8mjl7ms
___________________ TestParseCommand.test_parse_json_output ___________________

self = <tests.test_cli.TestParseCommand object at 0x000001E7C0F72B10>

        def test_parse_json_output(self) -> None:
            """Test JSON output format."""
            test_code = '''
    def example():
        """Example function"""
        pass
    '''

            with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
                f.write(test_code)
                temp_path = Path(f.name)

            try:
                result = runner.invoke(app, ["parse", str(temp_path), "--json"])
                assert result.exit_code == 0

                # Should be valid JSON
                data = json.loads(result.stdout)
>               assert "functions" in data or "results" in data
E               AssertionError: assert ('functions' in [{'decorators': [], 'docstring': {'description': None, 'examples': [], 'format': 'google', 'is_valid': True, ...}, 'end_line_number': 4, 'is_async': False, ...}] or 'results' in [{'decorators': [], 'docstring': {'description': None, 'examples': [], 'format': 'google', 'is_valid': True, ...}, 'end_line_number': 4, 'is_async': False, ...}])

tests\test_cli.py:108: AssertionError
______________________ TestMatchCommand.test_match_basic ______________________

args = (<tests.test_cli.TestMatchCommand object at 0x000001E7C0F7FD90>,)
keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

C:\Python313\Lib\unittest\mock.py:1423:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
C:\Python313\Lib\unittest\mock.py:1405: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
C:\Python313\Lib\unittest\mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001E7C0FBA510>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'codedocsync.cli.match' from 'C:\\Users\\issak\\CodeDocSync\\codedocsync\\cli\\match.py'> does not have the attribute 'match_functions_in_path'

C:\Python313\Lib\unittest\mock.py:1467: AttributeError
_________________ TestMatchCommand.test_match_with_threshold __________________

self = <tests.test_cli.TestMatchCommand object at 0x000001E7C0F7FED0>

    def test_match_with_threshold(self) -> None:
        """Test match command with confidence threshold."""
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write("def test(): pass")
            temp_path = Path(f.name)

        try:
            result = runner.invoke(app, ["match", str(temp_path), "--threshold", "0.9"])
>           assert result.exit_code == 0
E           assert 2 == 0
E            +  where 2 = <Result SystemExit(2)>.exit_code

tests\test_cli.py:144: AssertionError
_________________ TestAnalyzeCommand.test_analyze_with_style __________________

self = <tests.test_cli.TestAnalyzeCommand object at 0x000001E7C1028190>

    def test_analyze_with_style(self) -> None:
        """Test analyze with specific docstring style."""
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write("def test(): pass")
            temp_path = Path(f.name)

        try:
            result = runner.invoke(app, ["analyze", str(temp_path), "--style", "numpy"])
>           assert result.exit_code == 0
E           assert 2 == 0
E            +  where 2 = <Result SystemExit(2)>.exit_code

tests\test_cli.py:187: AssertionError
_________________ TestAnalyzeCommand.test_analyze_json_output _________________

self = <tests.test_cli.TestAnalyzeCommand object at 0x000001E7C0F72D70>

    def test_analyze_json_output(self) -> None:
        """Test analyze with JSON output."""
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write('def test(): """Test""" \n pass')
            temp_path = Path(f.name)

        try:
            result = runner.invoke(app, ["analyze", str(temp_path), "--json"])
>           assert result.exit_code == 0
E           assert 2 == 0
E            +  where 2 = <Result SystemExit(2)>.exit_code

tests\test_cli.py:199: AssertionError
__________________ TestSuggestCommand.test_suggest_auto_fix ___________________

self = <tests.test_cli.TestSuggestCommand object at 0x000001E7C1028410>

        def test_suggest_auto_fix(self) -> None:
            """Test suggest with auto-fix option."""
            test_code = """
    def test():
        return 42
    """

            with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
                f.write(test_code)
                temp_path = Path(f.name)

            try:
                # Note: Auto-fix should create backup
                result = runner.invoke(app, ["suggest", str(temp_path), "--fix"])
>               assert result.exit_code == 0
E               assert 2 == 0
E                +  where 2 = <Result SystemExit(2)>.exit_code

tests\test_cli.py:275: AssertionError
________________ TestClearCacheCommand.test_clear_cache_basic _________________

args = (<tests.test_cli.TestClearCacheCommand object at 0x000001E7C1028550>,)
keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

C:\Python313\Lib\unittest\mock.py:1423:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
C:\Python313\Lib\unittest\mock.py:1405: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
C:\Python313\Lib\unittest\mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001E7C0FBA890>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'codedocsync.cli.cache' from 'C:\\Users\\issak\\CodeDocSync\\codedocsync\\cli\\cache.py'> does not have the attribute 'clear_all_caches'

C:\Python313\Lib\unittest\mock.py:1467: AttributeError
________________ TestClearCacheCommand.test_clear_cache_force _________________

args = (<tests.test_cli.TestClearCacheCommand object at 0x000001E7C1028690>,)
keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

C:\Python313\Lib\unittest\mock.py:1423:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
C:\Python313\Lib\unittest\mock.py:1405: in decoration_helper
    arg = exit_stack.enter_context(patching)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
             ^^^^^^^^^^
C:\Python313\Lib\unittest\mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001E7C0FBAC10>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'codedocsync.cli.cache' from 'C:\\Users\\issak\\CodeDocSync\\codedocsync\\cli\\cache.py'> does not have the attribute 'clear_all_caches'

C:\Python313\Lib\unittest\mock.py:1467: AttributeError
__________________ TestCLIConfiguration.test_verbose_output ___________________

self = <tests.test_cli.TestCLIConfiguration object at 0x000001E7C1028910>

    def test_verbose_output(self) -> None:
        """Test verbose output mode."""
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write("def test(): pass")
            temp_path = Path(f.name)

        try:
            result = runner.invoke(app, ["--verbose", "parse", str(temp_path)])
>           assert result.exit_code == 0
E           assert 2 == 0
E            +  where 2 = <Result SystemExit(2)>.exit_code

tests\test_cli.py:339: AssertionError
____________________ TestCLIConfiguration.test_quiet_mode _____________________

self = <tests.test_cli.TestCLIConfiguration object at 0x000001E7C0F72FD0>

    def test_quiet_mode(self) -> None:
        """Test quiet output mode."""
        with tempfile.NamedTemporaryFile(mode="w", suffix=".py", delete=False) as f:
            f.write("def test(): pass")
            temp_path = Path(f.name)

        try:
            result = runner.invoke(app, ["--quiet", "parse", str(temp_path)])
>           assert result.exit_code == 0
E           assert 2 == 0
E            +  where 2 = <Result SystemExit(2)>.exit_code

tests\test_cli.py:352: AssertionError
_____________ TestErrorHandling.test_keyboard_interrupt_handling ______________

self = <tests.test_cli.TestErrorHandling object at 0x000001E7C0F73230>

    def test_keyboard_interrupt_handling(self) -> None:
        """Test handling of keyboard interrupts."""
>       with patch("codedocsync.cli.parse.parse_files") as mock_parse:
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\test_cli.py:380:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python313\Lib\unittest\mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000001E7853EDB70>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'codedocsync.cli.parse' from 'C:\\Users\\issak\\CodeDocSync\\codedocsync\\cli\\parse.py'> does not have the attribute 'parse_files'

C:\Python313\Lib\unittest\mock.py:1467: AttributeError
_________________ TestPerformance.test_large_project_handling _________________

self = <tests.test_cli.TestPerformance object at 0x000001E7C1028CD0>

        def test_large_project_handling(self) -> None:
            """Test handling of large projects."""
            with tempfile.TemporaryDirectory() as tmpdir:
                # Create 100 small Python files
                for i in range(100):
                    test_file = Path(tmpdir) / f"module_{i}.py"
                    test_file.write_text(
                        f'''
    def function_{i}(x: int) -> int:
        """Function {i} in module."""
        return x + {i}
    '''
                    )

                import time

                start = time.perf_counter()
                result = runner.invoke(app, ["parse", tmpdir])
                duration = time.perf_counter() - start

>               assert result.exit_code == 0
E               assert 1 == 0
E                +  where 1 = <Result SystemExit(1)>.exit_code

tests\test_cli.py:412: AssertionError
------------------------------ Captured log call ------------------------------
ERROR    codedocsync.parser.ast_parser:ast_parser.py:210 Permission denied: C:\Users\issak\AppData\Local\Temp\tmpbo182t0a
=========================== short test summary info ===========================
FAILED tests/analyzer/test_llm_analyzer.py::TestLLMAnalyzer::test_cache_identical_analyses
FAILED tests/matcher/test_direct_matcher.py::TestEdgeCases::test_performance_consistency
FAILED tests/parser/test_ast_parser_performance.py::TestASTParserPerformance::test_parse_large_file_performance
FAILED tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_parameters_simple
FAILED tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_match_parameter_line
FAILED tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_extract_section_boundaries
FAILED tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_template_with_max_line_length
FAILED tests/suggestions/templates/test_google_template.py::TestTemplateRegistry::test_invalid_style_raises_error
FAILED tests/suggestions/templates/test_google_template.py::TestTemplateIntegration::test_realistic_function_docstring
FAILED tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_raises_without_type
FAILED tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_match_parameter_line
FAILED tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_format_type_annotation_array_types
FAILED tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_long_line_wrapping
FAILED tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_examples
FAILED tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_unicode_in_sphinx_fields
FAILED tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_very_long_field_names
FAILED tests/suggestions/test_config.py::TestConfigIntegration::test_config_with_yaml_file_and_overrides
FAILED tests/suggestions/test_converter.py::TestSpecialCases::test_convert_with_unicode_content
FAILED tests/suggestions/test_e2e_integration.py::TestFullPipeline::test_parse_analyze_suggest_workflow
FAILED tests/suggestions/test_e2e_integration.py::TestFullPipeline::test_batch_processing
FAILED tests/suggestions/test_e2e_integration.py::TestCLIIntegration::test_suggest_command_with_file
FAILED tests/suggestions/test_e2e_integration.py::TestCLIIntegration::test_suggest_command_dry_run
FAILED tests/suggestions/test_e2e_integration.py::TestPerformanceMonitoring::test_performance_recommendations
FAILED tests/suggestions/test_e2e_integration.py::TestProductionScenarios::test_large_codebase_simulation
FAILED tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_name_mismatch_simple
FAILED tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_missing
FAILED tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_type_mismatch
FAILED tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_preserves_descriptions
FAILED tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_return_type_mismatch
FAILED tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_missing_return_documentation
FAILED tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_generator_function_return
FAILED tests/suggestions/test_generators.py::TestRaisesSuggestionGenerator::test_updates_existing_raises_section
FAILED tests/suggestions/test_generators.py::TestBehaviorSuggestionGenerator::test_enhance_vague_description
FAILED tests/suggestions/test_generators.py::TestBehaviorSuggestionGenerator::test_identify_side_effects
FAILED tests/suggestions/test_generators.py::TestExampleSuggestionGenerator::test_generate_basic_example
FAILED tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_property_method_documentation
FAILED tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_classmethod_documentation
FAILED tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_magic_method_documentation
FAILED tests/suggestions/test_generators.py::TestGeneratorIntegration::test_multiple_issues_same_function
FAILED tests/suggestions/test_merging.py::TestDocstringMerger::test_smart_parameter_merge_preserve_descriptions
FAILED tests/suggestions/test_merging.py::TestDocstringMerger::test_parse_section_boundaries_google_style
FAILED tests/suggestions/test_merging.py::TestDocstringMerger::test_validate_merge_result
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_single_suggestion_performance
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_batch_suggestion_performance
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_generator_direct_performance
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_complex_function_performance
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[google]
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[numpy]
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[sphinx]
FAILED tests/suggestions/test_ranking.py::TestSuggestionRanker::test_rank_by_confidence
FAILED tests/suggestions/test_ranking.py::TestRankingStrategies::test_confidence_first_strategy
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_parameter_name_mismatch
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_return_type_mismatch
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_missing_raises_complex
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_parameter_order_different
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_missing_params_with_complex_types
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_example_invalid
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_description_outdated
FAILED tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_google_style_docstring
FAILED tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_numpy_style_docstring
FAILED tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_sphinx_style_docstring
FAILED tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_preserve_existing_content
FAILED tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_merge_partial_updates
FAILED tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_fix_specific_issues
FAILED tests/suggestions/test_suggestion_generator.py::TestPerformanceBenchmarks::test_suggestion_generation_performance
FAILED tests/suggestions/test_suggestion_generator.py::TestPerformanceBenchmarks::test_template_accuracy
FAILED tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_empty_function_docstring_generation
FAILED tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_complex_type_annotations
FAILED tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_multiline_descriptions
FAILED tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_complex_types
FAILED tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_assess_complexity
FAILED tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_new_style_union_syntax
FAILED tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_very_long_type_annotations
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_return_documentation_validity
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_raises_documentation_validity
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_complete_docstring_validity
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_edge_case_validity
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_multiline_descriptions_validity
FAILED tests/test_cli.py::TestCLIBasics::test_version_command - AssertionErro...
FAILED tests/test_cli.py::TestParseCommand::test_parse_single_file - Assertio...
FAILED tests/test_cli.py::TestParseCommand::test_parse_directory - assert 1 == 0
FAILED tests/test_cli.py::TestParseCommand::test_parse_json_output - Assertio...
FAILED tests/test_cli.py::TestMatchCommand::test_match_basic - AttributeError...
FAILED tests/test_cli.py::TestMatchCommand::test_match_with_threshold - asser...
FAILED tests/test_cli.py::TestAnalyzeCommand::test_analyze_with_style - asser...
FAILED tests/test_cli.py::TestAnalyzeCommand::test_analyze_json_output - asse...
FAILED tests/test_cli.py::TestSuggestCommand::test_suggest_auto_fix - assert ...
FAILED tests/test_cli.py::TestClearCacheCommand::test_clear_cache_basic - Att...
FAILED tests/test_cli.py::TestClearCacheCommand::test_clear_cache_force - Att...
FAILED tests/test_cli.py::TestCLIConfiguration::test_verbose_output - assert ...
FAILED tests/test_cli.py::TestCLIConfiguration::test_quiet_mode - assert 2 == 0
FAILED tests/test_cli.py::TestErrorHandling::test_keyboard_interrupt_handling
FAILED tests/test_cli.py::TestPerformance::test_large_project_handling - asse...
================= 93 failed, 609 passed in 996.01s (0:16:36) ==================
