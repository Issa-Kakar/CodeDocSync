name: Claude Bug Scanner

on:
  pull_request:
    types: [opened, synchronize]
    paths:
      - '**.py'
      - '.github/workflows/claude.yml'
  workflow_dispatch:  # Allow manual bug scanning

jobs:
  comprehensive-bug-scan:
    name: Comprehensive Bug & Security Scanning
    runs-on: ubuntu-latest
    permissions:
      contents: read
      security-events: write
      pull-requests: write
      id-token: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install Poetry and dependencies
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true
          # Install the export plugin for Poetry 1.2+
          poetry self add poetry-plugin-export || true
          poetry install --no-interaction || echo "‚ö†Ô∏è Poetry install encountered issues"

      - name: Install bug scanning tools
        run: |
          echo "Installing bug scanning tools..."
          pip install bandit[toml] safety semgrep pylint vulture radon pyflakes || {
            echo "‚ö†Ô∏è Failed to install some tools, continuing with available tools"
            exit 0
          }

      - name: Run Bandit security scan
        id: bandit
        run: |
          echo "## üîí Bandit Security Scan" > bug_report.md
          echo "Scanning for security vulnerabilities..." >> bug_report.md
          # Run bandit and capture exit code
          bandit -r codedocsync -f json -o bandit_results.json || BANDIT_EXIT=$?
          # Ensure JSON file exists even if bandit fails
          [ -f bandit_results.json ] || echo '{"errors": [], "results": []}' > bandit_results.json
          # Run human-readable output
          bandit -r codedocsync -ll -i >> bug_report.md 2>&1 || echo "‚ö†Ô∏è Bandit scan encountered issues" >> bug_report.md
          echo -e "\n---\n" >> bug_report.md
        continue-on-error: true

      - name: Check dependencies for vulnerabilities
        id: safety
        run: |
          echo "## üõ°Ô∏è Dependency Vulnerability Scan" >> bug_report.md
          # Ensure JSON output file is created even on failure
          poetry export -f requirements.txt --without-hashes | safety check --stdin --json > safety_results.json || echo '{}' > safety_results.json
          poetry export -f requirements.txt --without-hashes | safety check --stdin --full-report >> bug_report.md || echo "‚ö†Ô∏è Safety check encountered issues" >> bug_report.md
          echo -e "\n---\n" >> bug_report.md
        continue-on-error: true

      - name: Run Semgrep for bug patterns
        id: semgrep
        run: |
          echo "## üêõ Semgrep Bug Pattern Detection" >> bug_report.md
          semgrep --config=auto --config=p/python --config=p/security-audit \
                 --json -o semgrep_results.json codedocsync || true
          semgrep --config=auto --config=p/python --config=p/security-audit \
                 --severity ERROR codedocsync >> bug_report.md || true
          echo -e "\n---\n" >> bug_report.md
        continue-on-error: true

      - name: Analyze cyclomatic complexity
        id: radon
        run: |
          echo "## üìä Code Complexity Analysis" >> bug_report.md
          echo "### Functions with dangerous complexity (>15):" >> bug_report.md
          # Ensure JSON output file is created even on failure
          radon cc codedocsync -s -n D --json > radon_cc_results.json || echo '{}' > radon_cc_results.json
          radon cc codedocsync -s -n D >> bug_report.md || echo "No high complexity functions found" >> bug_report.md
          echo -e "\n### Maintainability Issues (Grade C or worse):" >> bug_report.md
          radon mi codedocsync -s -n C >> bug_report.md || echo "No maintainability issues found" >> bug_report.md
          echo -e "\n---\n" >> bug_report.md
        continue-on-error: true

      - name: Detect dead code
        id: vulture
        run: |
          echo "## ü¶Ö Dead Code Detection" >> bug_report.md
          echo "Unused code that may indicate bugs:" >> bug_report.md
          vulture codedocsync --min-confidence 90 >> bug_report.md || true
          echo -e "\n---\n" >> bug_report.md
        continue-on-error: true

      - name: Run Pylint for bugs and code smells
        id: pylint
        run: |
          echo "## üîç Pylint Bug Detection" >> bug_report.md
          echo "Focus on: errors, warnings, and potential bugs" >> bug_report.md
          pylint codedocsync --errors-only --output-format=json > pylint_results.json || true
          pylint codedocsync --errors-only >> bug_report.md || true
          echo -e "\n### Critical Warnings:" >> bug_report.md
          pylint codedocsync --disable=all --enable=W --output-format=parseable | head -20 >> bug_report.md || true
          echo -e "\n---\n" >> bug_report.md
        continue-on-error: true

      - name: Run Pyflakes for additional checks
        id: pyflakes
        run: |
          echo "## üî• Pyflakes Analysis" >> bug_report.md
          pyflakes codedocsync >> bug_report.md || true
          echo -e "\n---\n" >> bug_report.md
        continue-on-error: true

      - name: Search for common bug patterns
        run: |
          echo "## üéØ Common Bug Pattern Search" >> bug_report.md
          echo "### Dangerous Patterns Found:" >> bug_report.md

          echo -e "\n#### Bare except clauses (catches all exceptions):" >> bug_report.md
          find codedocsync -name "*.py" -type f -exec grep -Hn -B1 -A1 "except:" {} \; >> bug_report.md || echo "‚úÖ None found" >> bug_report.md

          echo -e "\n#### Use of eval/exec (code injection risk):" >> bug_report.md
          find codedocsync -name "*.py" -type f -exec grep -Hn -E "eval\(|exec\(" {} \; >> bug_report.md || echo "‚úÖ None found" >> bug_report.md

          echo -e "\n#### Mutable default arguments:" >> bug_report.md
          find codedocsync -name "*.py" -type f -exec grep -Hn -E "def .+\(.*=\[\]|def .+\(.*=\{\}" {} \; >> bug_report.md || echo "‚úÖ None found" >> bug_report.md

          echo -e "\n#### Potential type confusion (isinstance with unions):" >> bug_report.md
          find codedocsync -name "*.py" -type f -exec grep -Hn -E "isinstance\(.+\\\|" {} \; >> bug_report.md || echo "‚úÖ None found" >> bug_report.md

          echo -e "\n#### Assert statements (removed in optimized code):" >> bug_report.md
          find codedocsync -name "*.py" -type f -exec grep -Hn "assert " {} \; | head -10 >> bug_report.md || echo "‚úÖ None found" >> bug_report.md

          echo -e "\n---\n" >> bug_report.md

      - name: Memory and resource leak detection
        run: |
          echo "## üíæ Resource Management Issues" >> bug_report.md
          echo "### Potential resource leaks:" >> bug_report.md

          echo -e "\n#### Files opened without context managers:" >> bug_report.md
          FOUND_OPEN=false
          find codedocsync -name "*.py" -type f 2>/dev/null | while IFS= read -r file; do
            grep -n "open(" "$file" 2>/dev/null | while IFS=: read -r linenum content; do
              # Skip comments
              echo "$content" | grep -q "^[[:space:]]*#" && continue

              # Safe line range calculation
              start_line=1
              [ "$linenum" -gt 2 ] && start_line=$((linenum - 2))
              end_line=$((linenum + 2))

              # Check for context manager
              if ! sed -n "${start_line},${end_line}p" "$file" 2>/dev/null | grep -q "with.*open("; then
                echo "${file}:${linenum}: ${content}" >> bug_report.md
                FOUND_OPEN=true
              fi
            done
          done
          [ "$FOUND_OPEN" = "false" ] && echo "‚úÖ None found" >> bug_report.md

          echo -e "\n#### Potential circular imports:" >> bug_report.md

          # Use a file to track whether we found any circular imports
          circular_found_file=$(mktemp)
          echo "false" > "$circular_found_file"

          # Create a temporary file for tracking imports
          import_map=$(mktemp)
          trap "rm -f $import_map $circular_found_file" EXIT

          # First pass: collect all imports (using process substitution to avoid subshell)
          while IFS= read -r file; do
            # Skip test files and __pycache__
            case "$file" in
              */test_*|*/__pycache__/*) continue ;;
            esac

            # Get module name from file path
            module=$(echo "$file" | sed 's|^\./||; s|\.py$||; s|/|.|g')

            # Extract imports from this module
            grep -E "^[[:space:]]*(from|import)[[:space:]]+" "$file" 2>/dev/null | while IFS= read -r import_line; do
              # Extract imported module names
              if echo "$import_line" | grep -q "^[[:space:]]*from"; then
                # Handle 'from X import Y' format
                imported=$(echo "$import_line" | sed 's/^[[:space:]]*from[[:space:]]\+\([^[:space:]]\+\)[[:space:]]\+import.*/\1/')
              else
                # Handle 'import X' format
                imported=$(echo "$import_line" | sed 's/^[[:space:]]*import[[:space:]]\+\([^[:space:],]\+\).*/\1/')
              fi

              # Only track imports within codedocsync
              if echo "$imported" | grep -q "^codedocsync"; then
                echo "$module imports $imported" >> "$import_map"
              fi
            done
          done < <(find codedocsync -name "*.py" -type f 2>/dev/null)

          # Second pass: check for circular dependencies (avoiding subshell)
          if [ -s "$import_map" ]; then
            # Create a sorted unique list
            sort -u "$import_map" > "${import_map}.sorted"
            mv "${import_map}.sorted" "$import_map"

            # Check each import relationship
            while IFS= read -r relation; do
              module1=$(echo "$relation" | cut -d' ' -f1)
              module2=$(echo "$relation" | cut -d' ' -f3)

              # Skip self-imports
              [ "$module1" = "$module2" ] && continue

              # Check for reverse relationship
              if grep -q "^${module2} imports.*${module1}" "$import_map" 2>/dev/null; then
                # Avoid duplicate reports
                if ! grep -q "Circular import: ${module2} ‚Üî ${module1}" bug_report.md 2>/dev/null; then
                  echo "Circular import detected: ${module1} ‚Üî ${module2}" >> bug_report.md
                  echo "true" > "$circular_found_file"
                fi
              fi
            done < "$import_map"
          fi

          # Check if we found any circular imports
          if [ "$(cat $circular_found_file)" = "false" ]; then
            echo "‚úÖ None found" >> bug_report.md
          fi

          # Cleanup handled by trap

          echo -e "\n---\n" >> bug_report.md

      - name: Generate bug statistics
        id: bug-stats
        run: |
          echo "## üìà Bug Scan Statistics" >> bug_report.md
          echo "| Scan Type | Issues Found |" >> bug_report.md
          echo "|-----------|--------------|" >> bug_report.md

          # Ensure all counts are valid numbers
          BANDIT_COUNT=$(grep -c "Issue:" bug_report.md 2>/dev/null || echo "0")
          [ -z "$BANDIT_COUNT" ] && BANDIT_COUNT=0

          COMPLEXITY_COUNT=$(grep -c "is too complex" bug_report.md 2>/dev/null || echo "0")
          [ -z "$COMPLEXITY_COUNT" ] && COMPLEXITY_COUNT=0

          DEAD_CODE_COUNT=$(grep -c "unused" bug_report.md 2>/dev/null || echo "0")
          [ -z "$DEAD_CODE_COUNT" ] && DEAD_CODE_COUNT=0

          PYLINT_COUNT=$(grep -c "^[CE][0-9]" bug_report.md 2>/dev/null || echo "0")
          [ -z "$PYLINT_COUNT" ] && PYLINT_COUNT=0

          echo "| Security Issues | $BANDIT_COUNT |" >> bug_report.md
          echo "| High Complexity | $COMPLEXITY_COUNT |" >> bug_report.md
          echo "| Dead Code | $DEAD_CODE_COUNT |" >> bug_report.md
          echo "| Lint Errors | $PYLINT_COUNT |" >> bug_report.md

          TOTAL=$((BANDIT_COUNT + COMPLEXITY_COUNT + DEAD_CODE_COUNT + PYLINT_COUNT))
          echo "| **TOTAL** | **$TOTAL** |" >> bug_report.md

          echo "total_issues=$TOTAL" >> $GITHUB_OUTPUT

      - name: Ensure bug report exists
        run: |
          if [ ! -f bug_report.md ]; then
            echo "# Bug Scan Report" > bug_report.md
            echo "Automated scan completed. Awaiting deep analysis..." >> bug_report.md
          fi
          # Add timestamp
          echo "" >> bug_report.md
          echo "---" >> bug_report.md
          echo "Report generated at: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> bug_report.md

      - name: Upload initial scan results
        uses: actions/upload-artifact@v4
        with:
          name: initial-scan-results
          path: |
            bug_report.md
            *_results.json

      - name: Run Claude deep bug analysis
        uses: anthropics/claude-code-action@beta
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          model: "claude-opus-4-20250514"
          mode: "agent"
          timeout_minutes: "30"
          allowed_tools: |
            Read
            Grep
            Glob
            LS
            Task
          prompt: |
            You are a specialized bug hunter analyzing CodeDocSync. Your ONLY job is to find bugs.

            The automated scanners have run. Now perform DEEP ANALYSIS to find:

            1. **MEMORY BUGS**:
               - Memory leaks from unclosed resources
               - Circular references preventing garbage collection
               - Unbounded data structure growth
               - Large object creation in loops

            2. **CONCURRENCY BUGS**:
               - Race conditions
               - Deadlocks
               - Thread safety violations
               - Missing locks/synchronization

            3. **LOGIC BUGS**:
               - Off-by-one errors
               - Integer overflow/underflow
               - Incorrect boolean logic
               - State inconsistencies
               - Unreachable code paths

            4. **EXCEPTION BUGS**:
               - Unhandled exceptions
               - Exception during exception handling
               - Resource cleanup failures
               - Silent exception swallowing

            5. **TYPE BUGS**:
               - Type confusion
               - None dereference
               - Wrong types passed to functions
               - Incompatible type operations

            6. **PERFORMANCE BUGS**:
               - O(n¬≤) or worse algorithms
               - Repeated expensive operations
               - Missing caching
               - Inefficient data structures

            7. **SECURITY BUGS**:
               - Path traversal
               - Command injection
               - SQL injection
               - XSS vulnerabilities
               - Insecure randomness
               - Hardcoded secrets

            **OUTPUT FORMAT**:
            For each bug found, provide EXACTLY this format:

            Bug type: [CATEGORY]
            Severity: [CRITICAL] or [HIGH] or [MEDIUM] or [LOW]
            File: path/to/file.py
            Line: specific line number
            Description: what the bug is
            Impact: what could go wrong
            Fix: specific code to fix it

            IMPORTANT: Use square brackets for severity levels (e.g., "Severity: [CRITICAL]")

            Focus on REAL BUGS only. No style issues or minor warnings.
            Report findings directly in the bug_report.md file.

      - name: Upload final bug scan results with Claude analysis
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: final-bug-scan-results
          path: |
            bug_report.md
            *_results.json

  create-bug-report:
    name: Create Final Bug Report
    needs: comprehensive-bug-scan
    if: always()
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
      issues: write

    steps:
      - name: Download all bug scan results
        uses: actions/download-artifact@v4
        with:
          path: artifacts

      - name: Merge bug reports
        run: |
          mkdir -p results
          # Try to get the final report with Claude analysis first
          if [ -f artifacts/final-bug-scan-results/bug_report.md ]; then
            cp artifacts/final-bug-scan-results/bug_report.md results/
            cp artifacts/final-bug-scan-results/*_results.json results/ 2>/dev/null || true
          elif [ -f artifacts/initial-scan-results/bug_report.md ]; then
            cp artifacts/initial-scan-results/bug_report.md results/
            cp artifacts/initial-scan-results/*_results.json results/ 2>/dev/null || true
          else
            echo "# Bug Scan Report" > results/bug_report.md
            echo "‚ùå No bug scan results found" >> results/bug_report.md
          fi

      - name: Post bug report as PR comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const reportPath = 'results/bug_report.md';
            const MAX_COMMENT_LENGTH = 60000; // Leave buffer for GitHub's 65536 limit

            let comment = '# üêõ Comprehensive Bug Scan Report\n\n';

            if (fs.existsSync(reportPath)) {
              const report = fs.readFileSync(reportPath, 'utf8');
              const lines = report.split('\n');

              // Extract summary statistics
              let inStatsTable = false;
              let statsTable = [];
              let totalIssues = 0;

              for (const line of lines) {
                if (line.includes('Bug Scan Statistics')) {
                  inStatsTable = true;
                  statsTable.push(line);
                } else if (inStatsTable) {
                  statsTable.push(line);
                  if (line.includes('**TOTAL**')) {
                    const match = line.match(/\*\*(\d+)\*\*/);
                    if (match) totalIssues = parseInt(match[1]);
                    break;
                  }
                }
              }

              // Build initial comment
              if (totalIssues > 0) {
                comment += `## ‚ö†Ô∏è Found ${totalIssues} potential issues\n\n`;
                comment += '**Action Required**: Please review the critical findings below.\n\n';
              } else {
                comment += '## ‚úÖ No critical bugs detected\n\n';
              }

              // Add summary table
              if (statsTable.length > 0) {
                comment += '### Summary\n\n';
                comment += statsTable.join('\n') + '\n\n';
              }

              // Extract HIGH and CRITICAL severity findings
              const criticalFindings = [];
              const highFindings = [];
              let currentFinding = [];
              let currentSeverity = null;

              for (let i = 0; i < lines.length; i++) {
                const line = lines[i];

                // Check if this is the start of a new finding
                if (line.startsWith('Bug type:')) {
                  // Save previous finding if exists
                  if (currentFinding.length > 0 && currentSeverity) {
                    const finding = currentFinding.join('\n');
                    if (currentSeverity === 'CRITICAL') {
                      criticalFindings.push(finding);
                    } else if (currentSeverity === 'HIGH') {
                      highFindings.push(finding);
                    }
                  }

                  // Start new finding
                  currentFinding = [line];
                  currentSeverity = null;
                } else if (line.includes('Severity:')) {
                  currentFinding.push(line);
                  if (line.includes('[CRITICAL]')) {
                    currentSeverity = 'CRITICAL';
                  } else if (line.includes('[HIGH]')) {
                    currentSeverity = 'HIGH';
                  } else if (line.includes('Severity: High')) { // Bandit format
                    currentSeverity = 'HIGH';
                  }
                } else if (currentFinding.length > 0 && line.trim() !== '' && !line.startsWith('#')) {
                  currentFinding.push(line);
                  // Check if this is the end of a finding (empty line or new section)
                  if (i + 1 < lines.length && (lines[i + 1].trim() === '' || lines[i + 1].startsWith('#'))) {
                    if (currentSeverity) {
                      const finding = currentFinding.join('\n');
                      if (currentSeverity === 'CRITICAL') {
                        criticalFindings.push(finding);
                      } else if (currentSeverity === 'HIGH') {
                        highFindings.push(finding);
                      }
                    }
                    currentFinding = [];
                    currentSeverity = null;
                  }
                }
              }

              // Add last finding if exists
              if (currentFinding.length > 0 && currentSeverity) {
                const finding = currentFinding.join('\n');
                if (currentSeverity === 'CRITICAL') {
                  criticalFindings.push(finding);
                } else if (currentSeverity === 'HIGH') {
                  highFindings.push(finding);
                }
              }

              // Add findings to comment with truncation if needed
              if (criticalFindings.length > 0 || highFindings.length > 0) {
                comment += '### Critical & High Severity Findings\n\n';

                let findingsAdded = 0;
                const maxFindings = 10;
                let truncated = false;

                // Add critical findings first
                for (const finding of criticalFindings) {
                  if (findingsAdded >= maxFindings || comment.length + finding.length + 500 > MAX_COMMENT_LENGTH) {
                    truncated = true;
                    break;
                  }
                  comment += finding + '\n\n---\n\n';
                  findingsAdded++;
                }

                // Add high findings if space allows
                for (const finding of highFindings) {
                  if (findingsAdded >= maxFindings || comment.length + finding.length + 500 > MAX_COMMENT_LENGTH) {
                    truncated = true;
                    break;
                  }
                  comment += finding + '\n\n---\n\n';
                  findingsAdded++;
                }

                if (truncated) {
                  const remainingCritical = Math.max(0, criticalFindings.length - findingsAdded);
                  const remainingHigh = Math.max(0, highFindings.length - (findingsAdded - criticalFindings.length));
                  const remaining = remainingCritical + remainingHigh;
                  comment += `\n... and ${remaining} more issues. See full report in artifacts.\n\n`;
                }
              }

              // Add footer
              comment += '\n---\n\n';
              comment += 'üìÑ **Full Report**: Download the complete bug scan results from the [workflow artifacts](../actions/runs/' + context.runId + ')\n\n';
              comment += 'ü§ñ This automated bug scan checks for security vulnerabilities, code complexity, dead code, and common bug patterns.';

              // Final safety check
              if (comment.length > MAX_COMMENT_LENGTH) {
                // Truncate the comment to fit
                const truncateMessage = '\n\n... Content truncated to fit GitHub comment limit. See full report in artifacts.';
                comment = comment.substring(0, MAX_COMMENT_LENGTH - truncateMessage.length) + truncateMessage;
              }
            } else {
              comment += '‚ùå Bug scan failed to generate report. Please check the workflow logs.';
            }

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

      - name: Fail if critical bugs found
        run: |
          if [ -f results/bug_report.md ]; then
            echo "üìã Checking for critical issues..."

            # Simply check if any critical patterns exist
            if grep -q "Severity: \[CRITICAL\]" results/bug_report.md 2>/dev/null || \
               grep -q "Severity: \[HIGH\]" results/bug_report.md 2>/dev/null || \
               grep -q "Severity: High" results/bug_report.md 2>/dev/null; then

              echo "‚ùå Critical or high severity issues found!"
              echo ""
              echo "Found the following issues:"
              grep "Severity: \[CRITICAL\]" results/bug_report.md 2>/dev/null || true
              grep "Severity: \[HIGH\]" results/bug_report.md 2>/dev/null || true
              grep "Severity: High" results/bug_report.md 2>/dev/null || true
              echo ""
              echo "Please fix these issues before merging."
              exit 1
            else
              echo "‚úÖ No critical security issues detected."
              exit 0
            fi
          else
            echo "‚ö†Ô∏è  No bug report file found"
            exit 1
          fi
