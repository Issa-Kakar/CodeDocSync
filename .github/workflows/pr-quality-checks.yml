name: PR Quality Checks

on:
  pull_request:
    branches: [ main, develop ]
    paths:
      - '**.py'
      - 'pyproject.toml'
      - '.github/workflows/pr-quality-checks.yml'
  push:
    branches: [ main ]
    paths:
      - '**.py'
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  quality-checks:
    name: Code Quality (${{ matrix.os }}, Python ${{ matrix.python-version }})
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        python-version: ['3.10', '3.13']
        include:
          - os: windows-latest
            python-version: '3.13'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better analysis

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache dependencies
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pypoetry
            .venv
          key: ${{ runner.os }}-poetry-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-poetry-${{ matrix.python-version }}-
            ${{ runner.os }}-poetry-

      - name: Install Poetry (Unix)
        if: runner.os != 'Windows'
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Install Poetry (Windows)
        if: runner.os == 'Windows'
        run: |
          (Invoke-WebRequest -Uri https://install.python-poetry.org -UseBasicParsing).Content | python -
          # Poetry on Windows installs to %APPDATA%\pypoetry\venv\Scripts
          Add-Content -Path $env:GITHUB_PATH -Value "$env:APPDATA\pypoetry\venv\Scripts"

      - name: Configure Poetry
        run: |
          poetry config virtualenvs.in-project true
          poetry config virtualenvs.create true

      - name: Install dependencies
        run: |
          poetry install --no-interaction --no-ansi
          poetry show

      - name: Run Black formatting check
        id: black
        run: |
          poetry run black --check --diff .
          echo "black_passed=true" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Run Ruff linting
        id: ruff
        run: |
          poetry run ruff check . --output-format=github
          echo "ruff_passed=true" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Run Mypy type checking
        id: mypy
        run: |
          poetry run mypy codedocsync --show-error-codes --pretty
          echo "mypy_passed=true" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Run pytest with coverage
        id: pytest
        run: |
          poetry run pytest -v --tb=short --cov=codedocsync --cov-report=xml --cov-report=term-missing
          echo "pytest_passed=true" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Upload coverage reports
        # Note: CODECOV_TOKEN must be added to repository secrets for this to work
        if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.13'
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Generate summary
        if: always()
        run: |
          echo "## Quality Check Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Check | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Black | ${{ steps.black.outputs.black_passed == 'true' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Ruff | ${{ steps.ruff.outputs.ruff_passed == 'true' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Mypy | ${{ steps.mypy.outputs.mypy_passed == 'true' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Pytest | ${{ steps.pytest.outputs.pytest_passed == 'true' && '‚úÖ Passed' || '‚ùå Failed' }} |" >> $GITHUB_STEP_SUMMARY

      - name: Fail if any check failed
        if: |
          steps.black.outputs.black_passed != 'true' ||
          steps.ruff.outputs.ruff_passed != 'true' ||
          steps.mypy.outputs.mypy_passed != 'true' ||
          steps.pytest.outputs.pytest_passed != 'true'
        run: |
          echo "One or more quality checks failed. Please fix the issues before merging."
          exit 1

  self-dogfood:
    name: CodeDocSync Self-Check
    runs-on: ubuntu-latest
    needs: quality-checks

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Install Poetry and dependencies
        run: |
          curl -sSL https://install.python-poetry.org | python3 -
          echo "$HOME/.local/bin" >> $GITHUB_PATH
          poetry config virtualenvs.in-project true
          poetry install --no-interaction

      - name: Verify CodeDocSync installation
        run: |
          if poetry run codedocsync --version; then
            echo "‚úÖ CodeDocSync installed successfully"
          else
            echo "‚ùå CodeDocSync not found or failed to run"
            exit 1
          fi

      - name: Run CodeDocSync on itself
        id: codedocsync
        run: |
          # Use analyze command with JSON format (check command is just a placeholder)
          poetry run codedocsync analyze . --format json --no-semantic > codedocsync-report.json || {
            echo "CodeDocSync analysis failed with exit code $?"
            # Create a minimal report if the command fails
            echo '{
              "error": "Analysis failed",
              "summary": {
                "files_analyzed": 0,
                "functions_analyzed": 0,
                "issues_by_severity": {
                  "critical": 0,
                  "high": 0,
                  "medium": 0,
                  "low": 0
                }
              }
            }' > codedocsync-report.json
          }
          echo "=== CodeDocSync Report ==="
          cat codedocsync-report.json
        continue-on-error: true

      - name: Upload CodeDocSync report
        uses: actions/upload-artifact@v4
        with:
          name: codedocsync-report
          path: codedocsync-report.json

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let report;
            try {
              const fileContent = fs.readFileSync('codedocsync-report.json', 'utf8');
              report = JSON.parse(fileContent);
            } catch (error) {
              console.error('Failed to parse CodeDocSync report:', error);
              report = { error: 'Failed to parse report', summary: {} };
            }

            // Safely access nested properties with defaults
            const summary = report.summary || {};
            const filesAnalyzed = summary.files_analyzed || 0;
            const functionsAnalyzed = summary.functions_analyzed || 0;
            const issues = summary.issues_by_severity || {
              critical: 0,
              high: 0,
              medium: 0,
              low: 0
            };

            let comment = `## üìã CodeDocSync Self-Check Results\n\n`;

            if (report.error) {
              comment += `‚ö†Ô∏è **Error during analysis**: ${report.error}\n\n`;
            }

            comment += `**Files analyzed**: ${filesAnalyzed}\n`;
            comment += `**Functions analyzed**: ${functionsAnalyzed}\n\n`;
            comment += `### Issues by Severity\n`;
            comment += `- üî¥ Critical: ${issues.critical || 0}\n`;
            comment += `- üü† High: ${issues.high || 0}\n`;
            comment += `- üü° Medium: ${issues.medium || 0}\n`;
            comment += `- üü¢ Low: ${issues.low || 0}\n\n`;

            if (issues.critical > 0) {
              comment += '**‚ö†Ô∏è Critical issues found! Please fix before merging.**';
            } else if (report.error) {
              comment += '**‚ö†Ô∏è Analysis failed. Please check the logs for details.**';
            } else {
              comment += '‚úÖ No critical issues found.';
            }

            try {
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              console.error('Failed to create PR comment:', error);
            }
