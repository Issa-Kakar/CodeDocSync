============================= test session starts =============================
platform win32 -- Python 3.13.5, pytest-8.4.1, pluggy-1.6.0 -- C:\Users\issak\CodeDocSync\.venv\Scripts\python.exe
cachedir: .pytest_cache
rootdir: C:\Users\issak\CodeDocSync
configfile: pyproject.toml
plugins: anyio-4.9.0, asyncio-1.1.0, mock-3.14.1
asyncio: mode=Mode.AUTO, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 640 items

tests/suggestions/formatters/test_json_formatter.py::TestJSONSuggestionFormatterInit::test_default_initialization PASSED [  0%]
tests/suggestions/formatters/test_json_formatter.py::TestJSONSuggestionFormatterInit::test_custom_initialization PASSED [  0%]
tests/suggestions/formatters/test_json_formatter.py::TestSuggestionFormatting::test_format_basic_suggestion PASSED [  0%]
tests/suggestions/formatters/test_json_formatter.py::TestSuggestionFormatting::test_format_suggestion_without_timestamps PASSED [  0%]
tests/suggestions/formatters/test_json_formatter.py::TestSuggestionFormatting::test_format_suggestion_with_diff PASSED [  0%]
tests/suggestions/formatters/test_json_formatter.py::TestSuggestionFormatting::test_format_suggestion_with_metadata FAILED [  0%]
tests/suggestions/formatters/test_json_formatter.py::TestSuggestionFormatting::test_format_suggestion_without_metadata PASSED [  1%]
tests/suggestions/formatters/test_json_formatter.py::TestSuggestionFormatting::test_format_suggestion_without_diff PASSED [  1%]
tests/suggestions/formatters/test_json_formatter.py::TestEnhancedIssueFormatting::test_format_enhanced_issue PASSED [  1%]
tests/suggestions/formatters/test_json_formatter.py::TestEnhancedIssueFormatting::test_format_issue_without_rich_suggestion PASSED [  1%]
tests/suggestions/formatters/test_json_formatter.py::TestEnhancedIssueFormatting::test_format_issue_without_ranking_score PASSED [  1%]
tests/suggestions/formatters/test_json_formatter.py::TestAnalysisResultFormatting::test_format_analysis_result FAILED [  1%]
tests/suggestions/formatters/test_json_formatter.py::TestAnalysisResultFormatting::test_format_result_without_documentation FAILED [  2%]
tests/suggestions/formatters/test_json_formatter.py::TestAnalysisResultFormatting::test_format_result_with_metadata PASSED [  2%]
tests/suggestions/formatters/test_json_formatter.py::TestAnalysisResultFormatting::test_format_result_without_metadata PASSED [  2%]
tests/suggestions/formatters/test_json_formatter.py::TestBatchFormatting::test_format_batch_results PASSED [  2%]
tests/suggestions/formatters/test_json_formatter.py::TestBatchFormatting::test_format_empty_batch PASSED [  2%]
tests/suggestions/formatters/test_json_formatter.py::TestBatchFormatting::test_format_suggestion_batch FAILED [  2%]
tests/suggestions/formatters/test_json_formatter.py::TestJSONSerialization::test_to_json_string PASSED [  2%]
tests/suggestions/formatters/test_json_formatter.py::TestJSONSerialization::test_to_json_string_no_indent PASSED [  3%]
tests/suggestions/formatters/test_json_formatter.py::TestFunctionInformationExtraction::test_format_function_info_complete PASSED [  3%]
tests/suggestions/formatters/test_json_formatter.py::TestFunctionInformationExtraction::test_format_function_info_minimal FAILED [  3%]
tests/suggestions/formatters/test_json_formatter.py::TestBatchSummaryStatistics::test_create_batch_summary_multiple_results PASSED [  3%]
tests/suggestions/formatters/test_json_formatter.py::TestConvenienceFunctions::test_suggestion_to_json PASSED [  3%]
tests/suggestions/formatters/test_json_formatter.py::TestConvenienceFunctions::test_analysis_result_to_json FAILED [  3%]
tests/suggestions/formatters/test_json_formatter.py::TestConvenienceFunctions::test_batch_results_to_json FAILED [  4%]
tests/suggestions/formatters/test_json_formatter.py::TestConvenienceFunctions::test_suggestion_batch_to_json PASSED [  4%]
tests/suggestions/formatters/test_json_formatter.py::TestEdgeCases::test_format_suggestion_with_none_values PASSED [  4%]
tests/suggestions/formatters/test_json_formatter.py::TestEdgeCases::test_format_issue_with_empty_details PASSED [  4%]
tests/suggestions/formatters/test_json_formatter.py::TestEdgeCases::test_batch_summary_with_no_suggestions PASSED [  4%]
tests/suggestions/formatters/test_json_formatter.py::TestTimestampHandling::test_timestamp_format PASSED [  4%]
tests/suggestions/formatters/test_terminal_formatter.py::TestTerminalFormatterConfig::test_default_config PASSED [  5%]
tests/suggestions/formatters/test_terminal_formatter.py::TestTerminalFormatterConfig::test_custom_config PASSED [  5%]
tests/suggestions/formatters/test_terminal_formatter.py::TestTerminalSuggestionFormatterInit::test_default_initialization PASSED [  5%]
tests/suggestions/formatters/test_terminal_formatter.py::TestTerminalSuggestionFormatterInit::test_custom_config_initialization PASSED [  5%]
tests/suggestions/formatters/test_terminal_formatter.py::TestTerminalSuggestionFormatterInit::test_no_rich_fallback PASSED [  5%]
tests/suggestions/formatters/test_terminal_formatter.py::TestSuggestionFormatting::test_format_basic_suggestion_plain FAILED [  5%]
tests/suggestions/formatters/test_terminal_formatter.py::TestSuggestionFormatting::test_format_suggestion_minimal PASSED [  5%]
tests/suggestions/formatters/test_terminal_formatter.py::TestSuggestionFormatting::test_format_suggestion_with_line_numbers PASSED [  6%]
tests/suggestions/formatters/test_terminal_formatter.py::TestSuggestionFormatting::test_format_suggestion_without_line_numbers PASSED [  6%]
tests/suggestions/formatters/test_terminal_formatter.py::TestSuggestionFormatting::test_format_suggestion_without_confidence PASSED [  6%]
tests/suggestions/formatters/test_terminal_formatter.py::TestSuggestionFormatting::test_format_suggestion_rich FAILED [  6%]
tests/suggestions/formatters/test_terminal_formatter.py::TestEnhancedIssueFormatting::test_format_issue_with_suggestion_plain FAILED [  6%]
tests/suggestions/formatters/test_terminal_formatter.py::TestEnhancedIssueFormatting::test_format_issue_without_suggestion_plain PASSED [  6%]
tests/suggestions/formatters/test_terminal_formatter.py::TestEnhancedIssueFormatting::test_format_issue_minimal PASSED [  7%]
tests/suggestions/formatters/test_terminal_formatter.py::TestEnhancedIssueFormatting::test_severity_indicators PASSED [  7%]
tests/suggestions/formatters/test_terminal_formatter.py::TestAnalysisResultFormatting::test_format_result_with_issues_plain PASSED [  7%]
tests/suggestions/formatters/test_terminal_formatter.py::TestAnalysisResultFormatting::test_format_result_no_issues PASSED [  7%]
tests/suggestions/formatters/test_terminal_formatter.py::TestAnalysisResultFormatting::test_format_result_minimal PASSED [  7%]
tests/suggestions/formatters/test_terminal_formatter.py::TestBatchSummaryFormatting::test_format_batch_summary_plain FAILED [  7%]
tests/suggestions/formatters/test_terminal_formatter.py::TestBatchSummaryFormatting::test_format_batch_summary_minimal FAILED [  7%]
tests/suggestions/formatters/test_terminal_formatter.py::TestBatchSummaryFormatting::test_format_empty_batch FAILED [  8%]
tests/suggestions/formatters/test_terminal_formatter.py::TestDiffFormatting::test_diff_preview_creation PASSED [  8%]
tests/suggestions/formatters/test_terminal_formatter.py::TestDiffFormatting::test_diff_display_configuration PASSED [  8%]
tests/suggestions/formatters/test_terminal_formatter.py::TestDiffFormatting::test_no_diff_display PASSED [  8%]
tests/suggestions/formatters/test_terminal_formatter.py::TestUtilityMethods::test_format_issue_only PASSED [  8%]
tests/suggestions/formatters/test_terminal_formatter.py::TestUtilityMethods::test_format_no_issues PASSED [  8%]
tests/suggestions/formatters/test_terminal_formatter.py::TestConfigurationOptions::test_max_width_configuration PASSED [  9%]
tests/suggestions/formatters/test_terminal_formatter.py::TestConfigurationOptions::test_unicode_configuration PASSED [  9%]
tests/suggestions/formatters/test_terminal_formatter.py::TestConfigurationOptions::test_compact_mode PASSED [  9%]
tests/suggestions/formatters/test_terminal_formatter.py::TestEdgeCases::test_suggestion_without_diff FAILED [  9%]
tests/suggestions/formatters/test_terminal_formatter.py::TestEdgeCases::test_issue_with_zero_line_number FAILED [  9%]
tests/suggestions/formatters/test_terminal_formatter.py::TestEdgeCases::test_function_without_signature FAILED [  9%]
tests/suggestions/formatters/test_terminal_formatter.py::TestEdgeCases::test_very_long_suggestion_text PASSED [ 10%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_control_flow_loops PASSED [ 10%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_data_operations FAILED [ 10%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_side_effects PASSED [ 10%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_error_handling FAILED [ 10%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_performance_characteristics FAILED [ 10%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_recursive_function PASSED [ 10%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_function_purpose_by_name PASSED [ 11%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_looks_like_validation PASSED [ 11%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_syntax_error_handling PASSED [ 11%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_improve_vague_description ERROR [ 11%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_improve_outdated_description ERROR [ 11%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_add_behavior_description ERROR [ 11%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_add_side_effects_documentation ERROR [ 12%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_generate_enhanced_description PASSED [ 12%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_generate_enhanced_description_with_side_effects_focus PASSED [ 12%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_generate_basic_purpose PASSED [ 12%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_no_source_code_fallback ERROR [ 12%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_no_patterns_detected ERROR [ 12%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_unknown_issue_type FAILED [ 12%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorGeneratorIntegration::test_complete_workflow_data_processing FAILED [ 13%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorGeneratorIntegration::test_complete_workflow_file_operations FAILED [ 13%]
tests/suggestions/generators/test_behavior_generator.py::TestBehaviorGeneratorIntegration::test_performance_pattern_detection FAILED [ 13%]
tests/suggestions/generators/test_edge_case_handlers.py::TestSpecialConstructAnalyzer::test_analyze_property_getter FAILED [ 13%]
tests/suggestions/generators/test_edge_case_handlers.py::TestSpecialConstructAnalyzer::test_analyze_classmethod FAILED [ 13%]
tests/suggestions/generators/test_edge_case_handlers.py::TestSpecialConstructAnalyzer::test_analyze_magic_method FAILED [ 13%]
tests/suggestions/generators/test_edge_case_handlers.py::TestSpecialConstructAnalyzer::test_analyze_async_function FAILED [ 14%]
tests/suggestions/generators/test_edge_case_handlers.py::TestPropertyMethodHandler::test_generate_property_getter_docstring ERROR [ 14%]
tests/suggestions/generators/test_edge_case_handlers.py::TestPropertyMethodHandler::test_property_setter_detection FAILED [ 14%]
tests/suggestions/generators/test_edge_case_handlers.py::TestPropertyMethodHandler::test_property_deleter_detection FAILED [ 14%]
tests/suggestions/generators/test_edge_case_handlers.py::TestClassMethodHandler::test_generate_classmethod_docstring ERROR [ 14%]
tests/suggestions/generators/test_edge_case_handlers.py::TestClassMethodHandler::test_staticmethod_handling FAILED [ 14%]
tests/suggestions/generators/test_edge_case_handlers.py::TestEdgeCaseSuggestionGenerator::test_generate_suggestion_delegates_to_handlers ERROR [ 15%]
tests/suggestions/generators/test_edge_case_handlers.py::TestEdgeCaseSuggestionGenerator::test_generate_suggestion_no_handler ERROR [ 15%]
tests/suggestions/generators/test_edge_case_handlers.py::TestEdgeCaseSuggestionGenerator::test_async_function_suggestion FAILED [ 15%]
tests/suggestions/generators/test_edge_case_handlers.py::TestEdgeCaseSuggestionGenerator::test_magic_method_suggestion FAILED [ 15%]
tests/suggestions/generators/test_example_generator.py::TestParameterValueGenerator::test_generate_value_by_name FAILED [ 15%]
tests/suggestions/generators/test_example_generator.py::TestParameterValueGenerator::test_generate_value_by_type PASSED [ 15%]
tests/suggestions/generators/test_example_generator.py::TestParameterValueGenerator::test_generate_value_optional_with_default FAILED [ 15%]
tests/suggestions/generators/test_example_generator.py::TestParameterValueGenerator::test_normalize_type PASSED [ 16%]
tests/suggestions/generators/test_example_generator.py::TestParameterValueGenerator::test_fallback_value PASSED [ 16%]
tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_function_decorators PASSED [ 16%]
tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_async_function FAILED [ 16%]
tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_generator_function FAILED [ 16%]
tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_side_effects FAILED [ 16%]
tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_domain_detection FAILED [ 17%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_basic_example PASSED [ 17%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_edge_case_example PASSED [ 17%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_advanced_example PASSED [ 17%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_async_example FAILED [ 17%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_property_example FAILED [ 17%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_edge_case_values FAILED [ 17%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_advanced_values PASSED [ 18%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_expected_output FAILED [ 18%]
tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_multiple_examples FAILED [ 18%]
tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_add_missing_examples ERROR [ 18%]
tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_fix_invalid_example ERROR [ 18%]
tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_update_outdated_example ERROR [ 18%]
tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_complete_example ERROR [ 19%]
tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_format_example_code PASSED [ 19%]
tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_no_examples_generated_fallback ERROR [ 19%]
tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_unknown_issue_type FAILED [ 19%]
tests/suggestions/generators/test_example_generator.py::TestExampleGeneratorIntegration::test_complete_workflow_mathematical_function FAILED [ 19%]
tests/suggestions/generators/test_example_generator.py::TestExampleGeneratorIntegration::test_complete_workflow_file_processing_function FAILED [ 19%]
tests/suggestions/generators/test_example_generator.py::TestExampleGeneratorIntegration::test_async_function_example_generation FAILED [ 20%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_fix_parameter_name_mismatch ERROR [ 20%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_add_missing_parameter ERROR [ 20%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_fix_parameter_type_mismatch ERROR [ 20%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_fix_parameter_order FAILED [ 20%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_add_kwargs_documentation FAILED [ 20%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_filter_special_parameters FAILED [ 20%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_find_parameter_mismatches PASSED [ 21%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_types_differ PASSED [ 21%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_normalize_type FAILED [ 21%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_generate_parameter_description PASSED [ 21%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_detect_style_from_docstring FAILED [ 21%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_fallback_suggestion FAILED [ 21%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_generic_parameter_fix FAILED [ 22%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterGeneratorEdgeCases::test_empty_function_parameters FAILED [ 22%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterGeneratorEdgeCases::test_empty_documented_parameters PASSED [ 22%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterGeneratorEdgeCases::test_malformed_function_object PASSED [ 22%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterGeneratorEdgeCases::test_malformed_docstring_object PASSED [ 22%]
tests/suggestions/generators/test_parameter_generator.py::TestParameterGeneratorEdgeCases::test_classmethod_detection FAILED [ 22%]
tests/suggestions/generators/test_raises_generator.py::TestExceptionAnalyzer::test_analyze_direct_raise PASSED [ 22%]
tests/suggestions/generators/test_raises_generator.py::TestExceptionAnalyzer::test_analyze_multiple_exceptions PASSED [ 23%]
tests/suggestions/generators/test_raises_generator.py::TestExceptionAnalyzer::test_analyze_function_calls PASSED [ 23%]
tests/suggestions/generators/test_raises_generator.py::TestExceptionAnalyzer::test_analyze_subscript_operations PASSED [ 23%]
tests/suggestions/generators/test_raises_generator.py::TestExceptionAnalyzer::test_analyze_bare_raise PASSED [ 23%]
tests/suggestions/generators/test_raises_generator.py::TestExceptionAnalyzer::test_deduplicate_exceptions PASSED [ 23%]
tests/suggestions/generators/test_raises_generator.py::TestExceptionAnalyzer::test_syntax_error_handling PASSED [ 23%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_add_missing_raises_documentation FAILED [ 24%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_fix_raises_type_mismatch FAILED [ 24%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_improve_raises_description FAILED [ 24%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_is_vague_description FAILED [ 24%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_generate_improved_exception_description PASSED [ 24%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_no_source_code_fallback FAILED [ 24%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_no_significant_exceptions FAILED [ 25%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_unknown_issue_type FAILED [ 25%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesGeneratorIntegration::test_complete_workflow_file_operations FAILED [ 25%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesGeneratorIntegration::test_complete_workflow_mismatch_correction FAILED [ 25%]
tests/suggestions/generators/test_raises_generator.py::TestRaisesGeneratorIntegration::test_edge_case_no_exceptions_detected FAILED [ 25%]
tests/suggestions/generators/test_return_generator.py::TestReturnStatementAnalyzer::test_analyze_simple_return PASSED [ 25%]
tests/suggestions/generators/test_return_generator.py::TestReturnStatementAnalyzer::test_analyze_multiple_returns PASSED [ 25%]
tests/suggestions/generators/test_return_generator.py::TestReturnStatementAnalyzer::test_analyze_generator_function FAILED [ 26%]
tests/suggestions/generators/test_return_generator.py::TestReturnStatementAnalyzer::test_analyze_async_function PASSED [ 26%]
tests/suggestions/generators/test_return_generator.py::TestReturnStatementAnalyzer::test_analyze_no_return PASSED [ 26%]
tests/suggestions/generators/test_return_generator.py::TestReturnStatementAnalyzer::test_analyze_syntax_error PASSED [ 26%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_fix_return_type_mismatch FAILED [ 26%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_add_missing_return_documentation FAILED [ 26%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_improve_return_description FAILED [ 27%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_fix_generator_return FAILED [ 27%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_determine_best_return_type_single FAILED [ 27%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_determine_best_return_type_multiple FAILED [ 27%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_determine_best_return_type_generator PASSED [ 27%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_generate_return_description_basic_types PASSED [ 27%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_generate_return_description_special_cases PASSED [ 27%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_no_source_code_fallback FAILED [ 28%]
tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_unknown_issue_type FAILED [ 28%]
tests/suggestions/generators/test_return_generator.py::TestReturnGeneratorIntegration::test_complete_workflow_missing_returns FAILED [ 28%]
tests/suggestions/generators/test_return_generator.py::TestReturnGeneratorIntegration::test_complete_workflow_generator_function FAILED [ 28%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_parameters_simple FAILED [ 28%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_parameters_empty PASSED [ 28%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_parameters_no_type PASSED [ 29%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_parameters_long_description PASSED [ 29%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_returns_simple PASSED [ 29%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_returns_no_type PASSED [ 29%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_returns_empty PASSED [ 29%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_raises_simple PASSED [ 29%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_raises_empty PASSED [ 30%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_complete_docstring PASSED [ 30%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_format_parameter_line_with_type PASSED [ 30%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_format_parameter_line_without_type PASSED [ 30%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_format_parameter_line_no_description PASSED [ 30%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_match_parameter_line FAILED [ 30%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_extract_section_boundaries FAILED [ 30%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_replace_section PASSED [ 31%]
tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_template_with_max_line_length FAILED [ 31%]
tests/suggestions/templates/test_google_template.py::TestTemplateRegistry::test_register_and_get_template PASSED [ 31%]
tests/suggestions/templates/test_google_template.py::TestTemplateRegistry::test_available_styles PASSED [ 31%]
tests/suggestions/templates/test_google_template.py::TestTemplateRegistry::test_invalid_style_raises_error FAILED [ 31%]
tests/suggestions/templates/test_google_template.py::TestTemplateIntegration::test_realistic_function_docstring FAILED [ 31%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_initialization PASSED [ 32%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_initialization_with_custom_params PASSED [ 32%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_parameters_empty PASSED [ 32%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_parameters_single PASSED [ 32%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_parameters_multiple PASSED [ 32%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_parameters_without_types PASSED [ 32%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_parameters_long_description PASSED [ 32%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_returns_empty PASSED [ 33%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_returns_with_type PASSED [ 33%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_returns_without_type PASSED [ 33%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_raises_empty PASSED [ 33%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_raises_single PASSED [ 33%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_raises_multiple PASSED [ 33%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_raises_without_type FAILED [ 34%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_format_parameter_line_with_type PASSED [ 34%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_format_parameter_line_without_type PASSED [ 34%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_format_return_line_with_type PASSED [ 34%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_format_return_line_without_type PASSED [ 34%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_match_parameter_line FAILED [ 34%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_merge_descriptions PASSED [ 35%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_examples PASSED [ 35%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_format_type_annotation_array_types FAILED [ 35%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_complete_docstring_rendering PASSED [ 35%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_long_line_wrapping FAILED [ 35%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyTemplateEdgeCases::test_empty_descriptions PASSED [ 35%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyTemplateEdgeCases::test_special_characters_in_descriptions PASSED [ 35%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyTemplateEdgeCases::test_unicode_descriptions PASSED [ 36%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyTemplateEdgeCases::test_very_long_parameter_names PASSED [ 36%]
tests/suggestions/templates/test_numpy_template.py::TestNumpyTemplateEdgeCases::test_complex_type_annotations PASSED [ 36%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_initialization PASSED [ 36%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_initialization_with_custom_params PASSED [ 36%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_parameters_empty PASSED [ 36%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_parameters_single PASSED [ 37%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_parameters_multiple PASSED [ 37%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_parameters_without_types PASSED [ 37%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_parameters_without_descriptions PASSED [ 37%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_returns_empty PASSED [ 37%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_returns_with_type PASSED [ 37%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_returns_without_type PASSED [ 37%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_returns_without_description PASSED [ 38%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_raises_empty PASSED [ 38%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_raises_single PASSED [ 38%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_raises_multiple PASSED [ 38%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_raises_without_type PASSED [ 38%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_raises_without_description PASSED [ 38%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_wrap_sphinx_field_short_line PASSED [ 39%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_wrap_sphinx_field_long_line PASSED [ 39%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_match_parameter_line PASSED [ 39%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_merge_descriptions PASSED [ 39%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_examples FAILED [ 39%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_format_type_annotation_simple_types PASSED [ 39%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_format_type_annotation_complex_types PASSED [ 40%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_complete_docstring_rendering PASSED [ 40%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_sphinx_specific_formatting PASSED [ 40%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_long_parameter_names PASSED [ 40%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_empty_field_descriptions PASSED [ 40%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_special_characters_in_sphinx_fields PASSED [ 40%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_colon_in_descriptions PASSED [ 40%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_multiline_descriptions_in_fields PASSED [ 41%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_unicode_in_sphinx_fields FAILED [ 41%]
tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_very_long_field_names FAILED [ 41%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_generator_initialization_default_config PASSED [ 41%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_generator_initialization_custom_config PASSED [ 41%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_generate_with_timing PASSED [ 41%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_generate_with_timing_exception_handling PASSED [ 42%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_suggestion_valid PASSED [ 42%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_suggestion_invalid_python_string PASSED [ 42%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_suggestion_inconsistent_indentation PASSED [ 42%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_suggestion_vague_content PASSED [ 42%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_is_valid_python_string_caching PASSED [ 42%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_has_consistent_indentation_valid PASSED [ 42%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_has_consistent_indentation_mixed_tabs_spaces PASSED [ 43%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_has_consistent_indentation_too_deep PASSED [ 43%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_has_proper_quote_escaping_valid PASSED [ 43%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_has_proper_quote_escaping_unmatched PASSED [ 43%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_matches_expected_style_google PASSED [ 43%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_matches_expected_style_numpy PASSED [ 43%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_matches_expected_style_sphinx PASSED [ 44%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_matches_expected_style_unknown PASSED [ 44%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_google_style_valid PASSED [ 44%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_google_style_missing_colon PASSED [ 44%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_google_style_bad_indentation PASSED [ 44%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_numpy_style_valid PASSED [ 44%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_numpy_style_missing_underline PASSED [ 45%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_numpy_style_wrong_underline_length PASSED [ 45%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_sphinx_style_valid PASSED [ 45%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_rest_style_valid PASSED [ 45%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validate_rest_style_bad_indentation PASSED [ 45%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_is_actionable_valid PASSED [ 45%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_is_actionable_vague_phrases PASSED [ 45%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_is_actionable_too_short PASSED [ 46%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_is_actionable_no_identifiers PASSED [ 46%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_create_metadata PASSED [ 46%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_format_docstring_lines PASSED [ 46%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_format_docstring_lines_custom_indent PASSED [ 46%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_wrap_long_lines_no_wrapping_needed PASSED [ 46%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_wrap_long_lines_wrapping_needed PASSED [ 47%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_wrap_long_lines_preserve_indentation PASSED [ 47%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_preserve_existing_content_empty_original PASSED [ 47%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_preserve_existing_content_with_original PASSED [ 47%]
tests/suggestions/test_base.py::TestBaseSuggestionGenerator::test_validation_exception_handling PASSED [ 47%]
tests/suggestions/test_base.py::TestWithSuggestionFallback::test_decorator_normal_execution PASSED [ 47%]
tests/suggestions/test_base.py::TestWithSuggestionFallback::test_decorator_handles_suggestion_error_with_partial PASSED [ 47%]
tests/suggestions/test_base.py::TestWithSuggestionFallback::test_decorator_handles_suggestion_error_without_partial PASSED [ 48%]
tests/suggestions/test_base.py::TestWithSuggestionFallback::test_decorator_handles_unexpected_exception PASSED [ 48%]
tests/suggestions/test_base.py::TestWithSuggestionFallback::test_decorator_with_fallback_method PASSED [ 48%]
tests/suggestions/test_base.py::TestBaseSuggestionGeneratorIntegration::test_full_validation_pipeline PASSED [ 48%]
tests/suggestions/test_base.py::TestBaseSuggestionGeneratorIntegration::test_style_specific_validation_integration PASSED [ 48%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_default_config_creation PASSED [ 48%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_custom_config_creation PASSED [ 49%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_validation_invalid_style PASSED [ 49%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_validation_invalid_confidence PASSED [ 49%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_validation_invalid_line_length PASSED [ 49%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_validation_invalid_indent_size PASSED [ 49%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_validation_invalid_max_suggestions PASSED [ 49%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_from_dict PASSED [ 50%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_from_dict_ignores_unknown_keys PASSED [ 50%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_to_dict PASSED [ 50%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_from_yaml_file PASSED [ 50%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_from_yaml_file_missing_file PASSED [ 50%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_from_yaml_file_invalid_yaml PASSED [ 50%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_save_to_yaml PASSED [ 50%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_get_style_config PASSED [ 51%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_is_feature_enabled PASSED [ 51%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_get_quality_thresholds PASSED [ 51%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_abbreviation_map_defaults PASSED [ 51%]
tests/suggestions/test_config.py::TestSuggestionConfig::test_config_section_order_defaults PASSED [ 51%]
tests/suggestions/test_config.py::TestRankingConfig::test_default_ranking_config PASSED [ 51%]
tests/suggestions/test_config.py::TestRankingConfig::test_ranking_config_validation_invalid_weights PASSED [ 52%]
tests/suggestions/test_config.py::TestRankingConfig::test_ranking_config_validation_weight_sum PASSED [ 52%]
tests/suggestions/test_config.py::TestRankingConfig::test_ranking_config_validation_invalid_confidence PASSED [ 52%]
tests/suggestions/test_config.py::TestRankingConfig::test_ranking_config_validation_invalid_max_suggestions PASSED [ 52%]
tests/suggestions/test_config.py::TestRankingConfig::test_ranking_config_calculate_score PASSED [ 52%]
tests/suggestions/test_config.py::TestRankingConfig::test_ranking_config_get_severity_score PASSED [ 52%]
tests/suggestions/test_config.py::TestPredefinedConfigs::test_minimal_config PASSED [ 52%]
tests/suggestions/test_config.py::TestPredefinedConfigs::test_comprehensive_config PASSED [ 53%]
tests/suggestions/test_config.py::TestPredefinedConfigs::test_development_config PASSED [ 53%]
tests/suggestions/test_config.py::TestPredefinedConfigs::test_documentation_config PASSED [ 53%]
tests/suggestions/test_config.py::TestConfigManager::test_config_manager_creation PASSED [ 53%]
tests/suggestions/test_config.py::TestConfigManager::test_config_manager_load_config_default PASSED [ 53%]
tests/suggestions/test_config.py::TestConfigManager::test_config_manager_load_config_with_user_config PASSED [ 53%]
tests/suggestions/test_config.py::TestConfigManager::test_config_manager_merge_configs PASSED [ 54%]
tests/suggestions/test_config.py::TestConfigManager::test_config_manager_merge_configs_dictionaries PASSED [ 54%]
tests/suggestions/test_config.py::TestConfigManager::test_config_manager_caching PASSED [ 54%]
tests/suggestions/test_config.py::TestConfigManager::test_config_manager_clear_cache PASSED [ 54%]
tests/suggestions/test_config.py::TestGlobalConfigManager::test_global_config_manager_exists PASSED [ 54%]
tests/suggestions/test_config.py::TestGlobalConfigManager::test_global_config_manager_usage PASSED [ 54%]
tests/suggestions/test_config.py::TestConfigIntegration::test_config_with_yaml_file_and_overrides FAILED [ 55%]
tests/suggestions/test_config.py::TestConfigIntegration::test_config_error_handling PASSED [ 55%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_initialization PASSED [ 55%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_same_style PASSED [ 55%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_google_to_numpy PASSED [ 55%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_google_to_sphinx PASSED [ 55%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_numpy_to_google PASSED [ 55%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_sphinx_to_google PASSED [ 56%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_with_custom_options PASSED [ 56%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_empty_sections PASSED [ 56%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_batch_success PASSED [ 56%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_batch_with_failures PASSED [ 56%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_estimate_conversion_quality PASSED [ 56%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_estimate_quality_complex_types PASSED [ 57%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_get_conversion_statistics PASSED [ 57%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_type_formatter_caching PASSED [ 57%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_parameters_with_none PASSED [ 57%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_returns_with_none PASSED [ 57%]
tests/suggestions/test_converter.py::TestDocstringStyleConverter::test_convert_raises_with_none PASSED [ 57%]
tests/suggestions/test_converter.py::TestConvenienceFunctions::test_convert_docstring_function PASSED [ 57%]
tests/suggestions/test_converter.py::TestConvenienceFunctions::test_batch_convert_docstrings_function PASSED [ 58%]
tests/suggestions/test_converter.py::TestConversionPresets::test_scientific_to_api_preset PASSED [ 58%]
tests/suggestions/test_converter.py::TestConversionPresets::test_api_to_sphinx_preset PASSED [ 58%]
tests/suggestions/test_converter.py::TestConversionPresets::test_legacy_cleanup_preset PASSED [ 58%]
tests/suggestions/test_converter.py::TestErrorHandling::test_conversion_with_invalid_style PASSED [ 58%]
tests/suggestions/test_converter.py::TestErrorHandling::test_conversion_with_malformed_docstring PASSED [ 58%]
tests/suggestions/test_converter.py::TestSpecialCases::test_convert_with_unicode_content FAILED [ 59%]
tests/suggestions/test_converter.py::TestSpecialCases::test_convert_with_very_long_descriptions PASSED [ 59%]
tests/suggestions/test_converter.py::TestSpecialCases::test_convert_with_special_parameter_types PASSED [ 59%]
tests/suggestions/test_e2e_integration.py::TestFullPipeline::test_parse_analyze_suggest_workflow FAILED [ 59%]
tests/suggestions/test_e2e_integration.py::TestFullPipeline::test_batch_processing FAILED [ 59%]
tests/suggestions/test_e2e_integration.py::TestCLIIntegration::test_suggest_command_help PASSED [ 59%]
tests/suggestions/test_e2e_integration.py::TestCLIIntegration::test_suggest_command_with_file FAILED [ 60%]
tests/suggestions/test_e2e_integration.py::TestCLIIntegration::test_suggest_command_dry_run FAILED [ 60%]
tests/suggestions/test_e2e_integration.py::TestPerformanceMonitoring::test_performance_tracking PASSED [ 60%]
tests/suggestions/test_e2e_integration.py::TestPerformanceMonitoring::test_performance_recommendations FAILED [ 60%]
tests/suggestions/test_e2e_integration.py::TestErrorHandling::test_graceful_degradation PASSED [ 60%]
tests/suggestions/test_e2e_integration.py::TestErrorHandling::test_error_recovery_in_batch PASSED [ 60%]
tests/suggestions/test_e2e_integration.py::TestProductionScenarios::test_large_codebase_simulation FAILED [ 60%]
tests/suggestions/test_e2e_integration.py::TestProductionScenarios::test_memory_efficiency PASSED [ 61%]
tests/suggestions/test_e2e_integration.py::TestProductionScenarios::test_concurrent_suggestion_generation PASSED [ 61%]
tests/suggestions/test_e2e_integration.py::TestConfigurationIntegration::test_config_precedence PASSED [ 61%]
tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_name_mismatch_simple FAILED [ 61%]
tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_missing FAILED [ 61%]
tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_type_mismatch FAILED [ 61%]
tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_preserves_descriptions FAILED [ 62%]
tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_return_type_mismatch FAILED [ 62%]
tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_missing_return_documentation FAILED [ 62%]
tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_generator_function_return FAILED [ 62%]
tests/suggestions/test_generators.py::TestRaisesSuggestionGenerator::test_missing_raises_documentation PASSED [ 62%]
tests/suggestions/test_generators.py::TestRaisesSuggestionGenerator::test_updates_existing_raises_section FAILED [ 62%]
tests/suggestions/test_generators.py::TestBehaviorSuggestionGenerator::test_enhance_vague_description FAILED [ 62%]
tests/suggestions/test_generators.py::TestBehaviorSuggestionGenerator::test_identify_side_effects FAILED [ 63%]
tests/suggestions/test_generators.py::TestExampleSuggestionGenerator::test_generate_basic_example FAILED [ 63%]
tests/suggestions/test_generators.py::TestExampleSuggestionGenerator::test_update_invalid_example PASSED [ 63%]
tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_property_method_documentation FAILED [ 63%]
tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_classmethod_documentation FAILED [ 63%]
tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_magic_method_documentation FAILED [ 63%]
tests/suggestions/test_generators.py::TestGeneratorIntegration::test_multiple_issues_same_function FAILED [ 64%]
tests/suggestions/test_generators.py::TestGeneratorIntegration::test_generator_selection_by_issue_type PASSED [ 64%]
tests/suggestions/test_generators.py::TestPerformanceAndScale::test_large_parameter_list PASSED [ 64%]
tests/suggestions/test_generators.py::TestPerformanceAndScale::test_complex_nested_docstring PASSED [ 64%]
tests/suggestions/test_integration.py::TestEnhancedIssue::test_creation PASSED [ 64%]
tests/suggestions/test_integration.py::TestEnhancedIssue::test_validation PASSED [ 64%]
tests/suggestions/test_integration.py::TestEnhancedAnalysisResult::test_creation PASSED [ 65%]
tests/suggestions/test_integration.py::TestEnhancedAnalysisResult::test_has_suggestions PASSED [ 65%]
tests/suggestions/test_integration.py::TestSuggestionIntegration::test_initialization PASSED [ 65%]
tests/suggestions/test_integration.py::TestSuggestionIntegration::test_create_enhanced_issue PASSED [ 65%]
tests/suggestions/test_integration.py::TestSuggestionIntegration::test_create_context PASSED [ 65%]
tests/suggestions/test_integration.py::TestSuggestionIntegration::test_enhance_analysis_result PASSED [ 65%]
tests/suggestions/test_integration.py::TestSuggestionIntegration::test_enhance_with_low_confidence PASSED [ 65%]
tests/suggestions/test_integration.py::TestSuggestionIntegration::test_generator_failure_handling PASSED [ 66%]
tests/suggestions/test_integration.py::TestSuggestionBatchProcessor::test_initialization PASSED [ 66%]
tests/suggestions/test_integration.py::TestSuggestionBatchProcessor::test_process_batch PASSED [ 66%]
tests/suggestions/test_integration.py::TestSuggestionBatchProcessor::test_process_batch_with_failures PASSED [ 66%]
tests/suggestions/test_integration.py::TestSuggestionBatchProcessor::test_create_suggestion_batch PASSED [ 66%]
tests/suggestions/test_integration.py::TestFactoryFunctions::test_enhance_with_suggestions PASSED [ 66%]
tests/suggestions/test_integration.py::TestFactoryFunctions::test_enhance_multiple_with_suggestions PASSED [ 67%]
tests/suggestions/test_integration.py::TestFactoryFunctions::test_enhance_with_default_config PASSED [ 67%]
tests/suggestions/test_integration.py::TestEdgeCases::test_empty_analysis_result PASSED [ 67%]
tests/suggestions/test_integration.py::TestEdgeCases::test_unknown_issue_type PASSED [ 67%]
tests/suggestions/test_integration.py::TestEdgeCases::test_is_edge_case_detection PASSED [ 67%]
tests/suggestions/test_integration.py::TestPerformanceMetrics::test_timing_metrics PASSED [ 67%]
tests/suggestions/test_integration.py::TestPerformanceMetrics::test_generation_counts PASSED [ 67%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_merge_partial_update_parameters PASSED [ 68%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_merge_partial_update_new_section PASSED [ 68%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_merge_multiple_sections PASSED [ 68%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_preserve_custom_content PASSED [ 68%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_smart_parameter_merge_preserve_descriptions FAILED [ 68%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_smart_parameter_merge_no_preservation PASSED [ 68%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_parse_section_boundaries_google_style FAILED [ 69%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_identify_section_type_google PASSED [ 69%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_extract_section_content PASSED [ 69%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_merge_with_confidence_weighting PASSED [ 69%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_validate_merge_result FAILED [ 69%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_merge_empty_existing_docstring PASSED [ 69%]
tests/suggestions/test_merging.py::TestDocstringMerger::test_merge_preserve_spacing PASSED [ 70%]
tests/suggestions/test_merging.py::TestSectionBoundary::test_section_boundary_creation PASSED [ 70%]
tests/suggestions/test_merging.py::TestSectionBoundary::test_section_boundary_with_content_lines PASSED [ 70%]
tests/suggestions/test_merging.py::TestMergerEdgeCases::test_is_generic_description PASSED [ 70%]
tests/suggestions/test_merging.py::TestMergerEdgeCases::test_merge_with_malformed_docstring PASSED [ 70%]
tests/suggestions/test_merging.py::TestMergerEdgeCases::test_merge_numpy_style_sections PASSED [ 70%]
tests/suggestions/test_models.py::TestSuggestionDiff::test_valid_diff_creation PASSED [ 70%]
tests/suggestions/test_models.py::TestSuggestionDiff::test_diff_validation_negative_start_line PASSED [ 71%]
tests/suggestions/test_models.py::TestSuggestionDiff::test_diff_validation_end_before_start PASSED [ 71%]
tests/suggestions/test_models.py::TestSuggestionDiff::test_unified_diff_generation PASSED [ 71%]
tests/suggestions/test_models.py::TestSuggestionDiff::test_diff_statistics PASSED [ 71%]
tests/suggestions/test_models.py::TestSuggestionMetadata::test_valid_metadata_creation PASSED [ 71%]
tests/suggestions/test_models.py::TestSuggestionMetadata::test_metadata_validation_negative_time PASSED [ 71%]
tests/suggestions/test_models.py::TestSuggestionMetadata::test_metadata_validation_empty_generator_type PASSED [ 72%]
tests/suggestions/test_models.py::TestSuggestionMetadata::test_metadata_defaults PASSED [ 72%]
tests/suggestions/test_models.py::TestSuggestionContext::test_valid_context_creation PASSED [ 72%]
tests/suggestions/test_models.py::TestSuggestionContext::test_context_validation_line_length_too_small PASSED [ 72%]
tests/suggestions/test_models.py::TestSuggestionContext::test_context_validation_invalid_style PASSED [ 72%]
tests/suggestions/test_models.py::TestSuggestionContext::test_context_defaults PASSED [ 72%]
tests/suggestions/test_models.py::TestSuggestion::test_valid_suggestion_creation PASSED [ 72%]
tests/suggestions/test_models.py::TestSuggestion::test_suggestion_validation_invalid_confidence PASSED [ 73%]
tests/suggestions/test_models.py::TestSuggestion::test_suggestion_validation_empty_text PASSED [ 73%]
tests/suggestions/test_models.py::TestSuggestion::test_suggestion_validation_invalid_line_range PASSED [ 73%]
tests/suggestions/test_models.py::TestSuggestion::test_suggestion_validation_invalid_style PASSED [ 73%]
tests/suggestions/test_models.py::TestSuggestion::test_suggestion_quality_score PASSED [ 73%]
tests/suggestions/test_models.py::TestSuggestion::test_suggestion_quality_score_with_issues PASSED [ 73%]
tests/suggestions/test_models.py::TestSuggestion::test_suggestion_to_dict PASSED [ 74%]
tests/suggestions/test_models.py::TestSuggestion::test_suggestion_properties PASSED [ 74%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_valid_batch_creation PASSED [ 74%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_batch_validation_negative_time PASSED [ 74%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_batch_high_confidence_suggestions PASSED [ 74%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_batch_ready_to_apply_suggestions PASSED [ 74%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_batch_average_confidence PASSED [ 75%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_batch_empty_suggestions PASSED [ 75%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_batch_best_suggestion PASSED [ 75%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_batch_sort_by_quality PASSED [ 75%]
tests/suggestions/test_models.py::TestSuggestionBatch::test_batch_summary PASSED [ 75%]
tests/suggestions/test_models.py::TestSuggestionExceptions::test_suggestion_error PASSED [ 75%]
tests/suggestions/test_models.py::TestSuggestionExceptions::test_style_detection_error PASSED [ 75%]
tests/suggestions/test_models.py::TestSuggestionExceptions::test_style_detection_error_default_fallback PASSED [ 76%]
tests/suggestions/test_models.py::TestSuggestionExceptions::test_suggestion_generation_error PASSED [ 76%]
tests/suggestions/test_models.py::TestSuggestionExceptions::test_suggestion_generation_error_no_partial PASSED [ 76%]
tests/suggestions/test_models.py::TestSuggestionExceptions::test_suggestion_validation_error PASSED [ 76%]
tests/suggestions/test_models.py::TestEnums::test_suggestion_type_enum PASSED [ 76%]
tests/suggestions/test_models.py::TestEnums::test_docstring_style_enum PASSED [ 76%]
tests/suggestions/test_models.py::TestEnums::test_enum_iteration PASSED  [ 77%]
tests/suggestions/test_performance.py::TestSuggestionPerformance::test_single_suggestion_performance FAILED [ 77%]
tests/suggestions/test_performance.py::TestSuggestionPerformance::test_batch_suggestion_performance FAILED [ 77%]
tests/suggestions/test_performance.py::TestSuggestionPerformance::test_generator_direct_performance FAILED [ 77%]
tests/suggestions/test_performance.py::TestSuggestionPerformance::test_complex_function_performance FAILED [ 77%]
tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[google] FAILED [ 77%]
tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[numpy] FAILED [ 77%]
tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[sphinx] FAILED [ 78%]
tests/suggestions/test_ranking.py::TestRankingConfig::test_default_config PASSED [ 78%]
tests/suggestions/test_ranking.py::TestRankingConfig::test_custom_config PASSED [ 78%]
tests/suggestions/test_ranking.py::TestRankingMetrics::test_total_score_calculation PASSED [ 78%]
tests/suggestions/test_ranking.py::TestRankingMetrics::test_zero_scores PASSED [ 78%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_initialization PASSED [ 78%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_rank_by_severity PASSED [ 79%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_rank_by_confidence FAILED [ 79%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_filter_by_confidence PASSED [ 79%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_filter_by_severity PASSED [ 79%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_exclude_issue_types PASSED [ 79%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_copy_paste_ready_filter PASSED [ 79%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_max_suggestions_limit PASSED [ 80%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_empty_issues_list PASSED [ 80%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_ranking_score_assignment PASSED [ 80%]
tests/suggestions/test_ranking.py::TestSuggestionRanker::test_rank_analysis_results PASSED [ 80%]
tests/suggestions/test_ranking.py::TestSuggestionFilter::test_by_confidence PASSED [ 80%]
tests/suggestions/test_ranking.py::TestSuggestionFilter::test_by_severity PASSED [ 80%]
tests/suggestions/test_ranking.py::TestSuggestionFilter::test_by_issue_type PASSED [ 80%]
tests/suggestions/test_ranking.py::TestSuggestionFilter::test_exclude_issue_types PASSED [ 81%]
tests/suggestions/test_ranking.py::TestSuggestionFilter::test_copy_paste_ready_only PASSED [ 81%]
tests/suggestions/test_ranking.py::TestSuggestionFilter::test_top_n PASSED [ 81%]
tests/suggestions/test_ranking.py::TestPriorityBooster::test_initialization PASSED [ 81%]
tests/suggestions/test_ranking.py::TestPriorityBooster::test_calculate_boost PASSED [ 81%]
tests/suggestions/test_ranking.py::TestPriorityBooster::test_add_custom_rule PASSED [ 81%]
tests/suggestions/test_ranking.py::TestPriorityBooster::test_rule_failure_handling PASSED [ 82%]
tests/suggestions/test_ranking.py::TestRankingStrategies::test_severity_first_strategy PASSED [ 82%]
tests/suggestions/test_ranking.py::TestRankingStrategies::test_confidence_first_strategy FAILED [ 82%]
tests/suggestions/test_ranking.py::TestRankingStrategies::test_balanced_strategy PASSED [ 82%]
tests/suggestions/test_ranking.py::TestFactoryFunctions::test_create_strict_ranker PASSED [ 82%]
tests/suggestions/test_ranking.py::TestFactoryFunctions::test_create_permissive_ranker PASSED [ 82%]
tests/suggestions/test_ranking.py::TestFactoryFunctions::test_create_balanced_ranker PASSED [ 82%]
tests/suggestions/test_ranking.py::TestActionabilityScoring::test_high_actionability_suggestion PASSED [ 83%]
tests/suggestions/test_ranking.py::TestActionabilityScoring::test_low_actionability_suggestion PASSED [ 83%]
tests/suggestions/test_ranking.py::TestComplexityPenalty::test_low_confidence_penalty PASSED [ 83%]
tests/suggestions/test_ranking.py::TestComplexityPenalty::test_complex_issue_type_penalty PASSED [ 83%]
tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_parameter_name_mismatch FAILED [ 83%]
tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_return_type_mismatch FAILED [ 83%]
tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_missing_raises_complex FAILED [ 84%]
tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_parameter_order_different FAILED [ 84%]
tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_missing_params_with_complex_types FAILED [ 84%]
tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_example_invalid FAILED [ 84%]
tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_description_outdated FAILED [ 84%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detector_initialization PASSED [ 84%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detector_with_custom_config PASSED [ 85%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_google_style_docstring PASSED [ 85%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_numpy_style_docstring PASSED [ 85%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_sphinx_style_docstring PASSED [ 85%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_rest_style_docstring PASSED [ 85%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_empty_docstring PASSED [ 85%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_plain_docstring PASSED [ 85%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_ambiguous_docstring PASSED [ 86%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_from_file_with_python_code PASSED [ 86%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_from_file_missing_file PASSED [ 86%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_from_file_no_docstrings PASSED [ 86%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_extract_docstrings_from_code PASSED [ 86%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_extract_docstrings_invalid_syntax PASSED [ 86%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_analyze_multiple_docstrings_consistent PASSED [ 87%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_analyze_multiple_docstrings_mixed PASSED [ 87%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_analyze_multiple_docstrings_empty PASSED [ 87%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_calculate_style_score_google PASSED [ 87%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_calculate_style_score_with_forbidden_patterns PASSED [ 87%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_validate_style_consistency_google PASSED [ 87%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_validate_style_consistency_google_issues PASSED [ 87%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_validate_style_consistency_numpy PASSED [ 88%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_validate_style_consistency_numpy_issues PASSED [ 88%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_validate_style_consistency_sphinx PASSED [ 88%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_validate_style_consistency_unknown_style PASSED [ 88%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_get_style_confidence PASSED [ 88%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_get_all_style_scores PASSED [ 88%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_caching_behavior PASSED [ 89%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_clear_cache PASSED [ 89%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_get_style_template_google PASSED [ 89%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_get_style_template_numpy PASSED [ 89%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_get_style_template_sphinx PASSED [ 89%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_get_style_template_unknown PASSED [ 89%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_from_project_sampling PASSED [ 90%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_from_project_no_python_files PASSED [ 90%]
tests/suggestions/test_style_detector.py::TestDocstringStyleDetector::test_detect_from_project_with_errors PASSED [ 90%]
tests/suggestions/test_style_detector.py::TestGlobalStyleDetector::test_global_style_detector_exists PASSED [ 90%]
tests/suggestions/test_style_detector.py::TestGlobalStyleDetector::test_global_style_detector_usage PASSED [ 90%]
tests/suggestions/test_style_detector.py::TestStyleDetectionIntegration::test_real_world_google_examples PASSED [ 90%]
tests/suggestions/test_style_detector.py::TestStyleDetectionIntegration::test_real_world_numpy_examples PASSED [ 90%]
tests/suggestions/test_style_detector.py::TestStyleDetectionIntegration::test_style_detection_edge_cases PASSED [ 91%]
tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_google_style_docstring FAILED [ 91%]
tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_numpy_style_docstring FAILED [ 91%]
tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_sphinx_style_docstring FAILED [ 91%]
tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_preserve_existing_content FAILED [ 91%]
tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_merge_partial_updates FAILED [ 91%]
tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_fix_specific_issues FAILED [ 92%]
tests/suggestions/test_suggestion_generator.py::TestPerformanceBenchmarks::test_suggestion_generation_performance FAILED [ 92%]
tests/suggestions/test_suggestion_generator.py::TestPerformanceBenchmarks::test_template_accuracy FAILED [ 92%]
tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_empty_function_docstring_generation FAILED [ 92%]
tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_complex_type_annotations FAILED [ 92%]
tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_multiline_descriptions FAILED [ 92%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_initialization PASSED [ 92%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_initialization_with_style PASSED [ 93%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_simple_types PASSED [ 93%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_empty_type PASSED [ 93%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_optional_types PASSED [ 93%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_union_types PASSED [ 93%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_generic_types PASSED [ 93%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_complex_types FAILED [ 94%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_normalize_type_string PASSED [ 94%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_assess_complexity FAILED [ 94%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_for_numpy_style PASSED [ 94%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_for_sphinx_style PASSED [ 94%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_split_union_types PASSED [ 94%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_extract_from_ast_name PASSED [ 95%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_extract_from_ast_attribute PASSED [ 95%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_extract_from_ast_subscript PASSED [ 95%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_extract_from_ast_none PASSED [ 95%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_simplify_for_style PASSED [ 95%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_type_mappings_numpy PASSED [ 95%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_type_mappings_sphinx PASSED [ 95%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_caching_behavior PASSED [ 96%]
tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_new_style_union_syntax FAILED [ 96%]
tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_deeply_nested_generics PASSED [ 96%]
tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_very_long_type_annotations FAILED [ 96%]
tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_recursive_type_structures PASSED [ 96%]
tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_malformed_type_annotations PASSED [ 96%]
tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_custom_generic_types PASSED [ 97%]
tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_forward_references PASSED [ 97%]
tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_special_typing_constructs PASSED [ 97%]
tests/suggestions/test_type_formatter.py::TestConvenienceFunctions::test_format_type_for_style_function PASSED [ 97%]
tests/suggestions/test_type_formatter.py::TestConvenienceFunctions::test_extract_type_from_ast_function PASSED [ 97%]
tests/suggestions/test_type_formatter.py::TestConvenienceFunctions::test_convenience_function_with_empty PASSED [ 97%]
tests/suggestions/test_type_formatter.py::TestPerformanceAndEdgeCases::test_cache_performance PASSED [ 97%]
tests/suggestions/test_type_formatter.py::TestPerformanceAndEdgeCases::test_unicode_in_type_annotations PASSED [ 98%]
tests/suggestions/test_type_formatter.py::TestPerformanceAndEdgeCases::test_very_long_type_names PASSED [ 98%]
tests/suggestions/test_type_formatter.py::TestPerformanceAndEdgeCases::test_special_characters_in_types PASSED [ 98%]
tests/suggestions/test_type_formatter.py::TestPerformanceAndEdgeCases::test_empty_and_whitespace_types PASSED [ 98%]
tests/suggestions/test_type_formatter.py::TestPerformanceAndEdgeCases::test_complexity_cache_size PASSED [ 98%]
tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_google_style_template_validity PASSED [ 98%]
tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_numpy_style_template_validity PASSED [ 99%]
tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_sphinx_style_template_validity PASSED [ 99%]
tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_return_documentation_validity FAILED [ 99%]
tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_raises_documentation_validity FAILED [ 99%]
tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_complete_docstring_validity FAILED [ 99%]
tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_edge_case_validity FAILED [ 99%]
tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_multiline_descriptions_validity FAILED [100%]

=================================== ERRORS ====================================
_ ERROR at setup of TestBehaviorSuggestionGenerator.test_improve_vague_description _

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorSuggestionGenerator object at 0x000002078A7407D0>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="description_vague",
            severity="medium",
            description="Description is too vague",
            suggestion="Improve description",
            line_number=10,
        )

tests\suggestions\generators\test_behavior_generator.py:256:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Improve description', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestBehaviorSuggestionGenerator.test_improve_outdated_description _

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorSuggestionGenerator object at 0x000002078A740910>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="description_vague",
            severity="medium",
            description="Description is too vague",
            suggestion="Improve description",
            line_number=10,
        )

tests\suggestions\generators\test_behavior_generator.py:256:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Improve description', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestBehaviorSuggestionGenerator.test_add_behavior_description _

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorSuggestionGenerator object at 0x000002078A67EB10>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="description_vague",
            severity="medium",
            description="Description is too vague",
            suggestion="Improve description",
            line_number=10,
        )

tests\suggestions\generators\test_behavior_generator.py:256:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Improve description', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestBehaviorSuggestionGenerator.test_add_side_effects_documentation _

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorSuggestionGenerator object at 0x000002078A67EC40>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="description_vague",
            severity="medium",
            description="Description is too vague",
            suggestion="Improve description",
            line_number=10,
        )

tests\suggestions\generators\test_behavior_generator.py:256:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Improve description', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestBehaviorSuggestionGenerator.test_no_source_code_fallback _

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorSuggestionGenerator object at 0x000002078A6B4E50>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="description_vague",
            severity="medium",
            description="Description is too vague",
            suggestion="Improve description",
            line_number=10,
        )

tests\suggestions\generators\test_behavior_generator.py:256:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Improve description', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestBehaviorSuggestionGenerator.test_no_patterns_detected _

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorSuggestionGenerator object at 0x000002078A6B4F50>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="description_vague",
            severity="medium",
            description="Description is too vague",
            suggestion="Improve description",
            line_number=10,
        )

tests\suggestions\generators\test_behavior_generator.py:256:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Improve description', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestPropertyMethodHandler.test_generate_property_getter_docstring _

self = <tests.suggestions.generators.test_edge_case_handlers.TestPropertyMethodHandler object at 0x000002078A740F50>

    @pytest.fixture
    def property_context(self) -> Any:
        """Create a context for property methods."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.name = "username"
        function.signature.decorators = ["property"]
        function.signature.return_annotation = "str"
        function.signature.parameters = []

>       issue = InconsistencyIssue(
            issue_type="missing_docstring",
            severity="high",
            description="Property getter has no docstring",
            suggestion="Add a docstring",
            line_number=10,
        )

tests\suggestions\generators\test_edge_case_handlers.py:112:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_docstring', severity='high', description='Property getter has no docstring', suggestion='Add a docstring', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_docstring'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestClassMethodHandler.test_generate_classmethod_docstring _

self = <tests.suggestions.generators.test_edge_case_handlers.TestClassMethodHandler object at 0x000002078A7411D0>

    @pytest.fixture
    def classmethod_context(self) -> Any:
        """Create a context for class methods."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.name = "from_config"
        function.signature.decorators = ["classmethod"]
        function.signature.return_annotation = "MyClass"

        # Mock parameters
        cls_param: Mock = Mock()
        cls_param.name = "cls"
        cls_param.type_annotation = None

        config_param: Mock = Mock()
        config_param.name = "config"
        config_param.type_annotation = "dict"

        function.signature.parameters = [cls_param, config_param]

>       issue = InconsistencyIssue(
            issue_type="missing_docstring",
            severity="high",
            description="Class method has no docstring",
            suggestion="Add a docstring",
            line_number=20,
        )

tests\suggestions\generators\test_edge_case_handlers.py:185:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_docstring', severity='high', description='Class method has no docstring', suggestion='Add a docstring', line_number=20, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_docstring'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestEdgeCaseSuggestionGenerator.test_generate_suggestion_delegates_to_handlers _
file C:\Users\issak\CodeDocSync\tests\suggestions\generators\test_edge_case_handlers.py, line 240
      def test_generate_suggestion_delegates_to_handlers(
E       fixture 'property_context' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, generator, mock_handlers, mocker, module_mocker, monkeypatch, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

C:\Users\issak\CodeDocSync\tests\suggestions\generators\test_edge_case_handlers.py:240
_ ERROR at setup of TestEdgeCaseSuggestionGenerator.test_generate_suggestion_no_handler _
file C:\Users\issak\CodeDocSync\tests\suggestions\generators\test_edge_case_handlers.py, line 258
      def test_generate_suggestion_no_handler(
E       fixture 'property_context' not found
>       available fixtures: _class_scoped_runner, _function_scoped_runner, _module_scoped_runner, _package_scoped_runner, _session_scoped_runner, anyio_backend, anyio_backend_name, anyio_backend_options, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, capteesys, class_mocker, doctest_namespace, event_loop_policy, free_tcp_port, free_tcp_port_factory, free_udp_port, free_udp_port_factory, generator, mock_handlers, mocker, module_mocker, monkeypatch, package_mocker, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, session_mocker, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory, unused_tcp_port, unused_tcp_port_factory, unused_udp_port, unused_udp_port_factory
>       use 'pytest --fixtures [testpath]' for help on them.

C:\Users\issak\CodeDocSync\tests\suggestions\generators\test_edge_case_handlers.py:258
_ ERROR at setup of TestExampleSuggestionGenerator.test_add_missing_examples __

self = <tests.suggestions.generators.test_example_generator.TestExampleSuggestionGenerator object at 0x000002078A741E50>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="missing_examples",
            severity="low",
            description="Missing usage examples",
            suggestion="Add examples",
            line_number=10,
        )

tests\suggestions\generators\test_example_generator.py:425:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='Missing usage examples', suggestion='Add examples', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
__ ERROR at setup of TestExampleSuggestionGenerator.test_fix_invalid_example __

self = <tests.suggestions.generators.test_example_generator.TestExampleSuggestionGenerator object at 0x000002078A741F90>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="missing_examples",
            severity="low",
            description="Missing usage examples",
            suggestion="Add examples",
            line_number=10,
        )

tests\suggestions\generators\test_example_generator.py:425:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='Missing usage examples', suggestion='Add examples', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestExampleSuggestionGenerator.test_update_outdated_example _

self = <tests.suggestions.generators.test_example_generator.TestExampleSuggestionGenerator object at 0x000002078A67FCE0>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="missing_examples",
            severity="low",
            description="Missing usage examples",
            suggestion="Add examples",
            line_number=10,
        )

tests\suggestions\generators\test_example_generator.py:425:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='Missing usage examples', suggestion='Add examples', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
___ ERROR at setup of TestExampleSuggestionGenerator.test_complete_example ____

self = <tests.suggestions.generators.test_example_generator.TestExampleSuggestionGenerator object at 0x000002078A67FE10>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="missing_examples",
            severity="low",
            description="Missing usage examples",
            suggestion="Add examples",
            line_number=10,
        )

tests\suggestions\generators\test_example_generator.py:425:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='Missing usage examples', suggestion='Add examples', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestExampleSuggestionGenerator.test_no_examples_generated_fallback _

self = <tests.suggestions.generators.test_example_generator.TestExampleSuggestionGenerator object at 0x000002078A696690>

    @pytest.fixture
    def mock_issue(self) -> InconsistencyIssue:
        """Create mock issue."""
>       return InconsistencyIssue(
            issue_type="missing_examples",
            severity="low",
            description="Missing usage examples",
            suggestion="Add examples",
            line_number=10,
        )

tests\suggestions\generators\test_example_generator.py:425:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='Missing usage examples', suggestion='Add examples', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
_ ERROR at setup of TestParameterSuggestionGenerator.test_fix_parameter_name_mismatch _

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A742710>

    @pytest.fixture
    def sample_function(self) -> Any:
        """Create sample function for testing."""
        signature = FunctionSignature(
            name="test_function",
            parameters=[
                FunctionParameter(
                    name="param1", type_annotation="str", is_required=True
                ),
                FunctionParameter(
                    name="param2",
                    type_annotation="int",
                    is_required=False,
                    default_value="0",
                ),
            ],
        )

>       return ParsedFunction(
            signature=signature, docstring=None, file_path="test.py", line_number=10
        )

tests\suggestions\generators\test_parameter_generator.py:55:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param1', type_ann...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=10, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (10)

codedocsync\parser\ast_parser.py:159: ValidationError
_ ERROR at setup of TestParameterSuggestionGenerator.test_add_missing_parameter _

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A742850>

    @pytest.fixture
    def sample_function(self) -> Any:
        """Create sample function for testing."""
        signature = FunctionSignature(
            name="test_function",
            parameters=[
                FunctionParameter(
                    name="param1", type_annotation="str", is_required=True
                ),
                FunctionParameter(
                    name="param2",
                    type_annotation="int",
                    is_required=False,
                    default_value="0",
                ),
            ],
        )

>       return ParsedFunction(
            signature=signature, docstring=None, file_path="test.py", line_number=10
        )

tests\suggestions\generators\test_parameter_generator.py:55:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param1', type_ann...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=10, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (10)

codedocsync\parser\ast_parser.py:159: ValidationError
_ ERROR at setup of TestParameterSuggestionGenerator.test_fix_parameter_type_mismatch _

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A7B03E0>

    @pytest.fixture
    def sample_function(self) -> Any:
        """Create sample function for testing."""
        signature = FunctionSignature(
            name="test_function",
            parameters=[
                FunctionParameter(
                    name="param1", type_annotation="str", is_required=True
                ),
                FunctionParameter(
                    name="param2",
                    type_annotation="int",
                    is_required=False,
                    default_value="0",
                ),
            ],
        )

>       return ParsedFunction(
            signature=signature, docstring=None, file_path="test.py", line_number=10
        )

tests\suggestions\generators\test_parameter_generator.py:55:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param1', type_ann...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=10, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (10)

codedocsync\parser\ast_parser.py:159: ValidationError
================================== FAILURES ===================================
________ TestSuggestionFormatting.test_format_suggestion_with_metadata ________

self = <test_json_formatter.TestSuggestionFormatting object at 0x000002078A67CFC0>
suggestion_with_metadata = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='"""Returns something."""', ... rule_triggers=[], llm_used=False, generation_time_ms=25.5, token_usage=None), affected_sections=[], line_range=(1, 1))

    def test_format_suggestion_with_metadata(
        self, suggestion_with_metadata: Any
    ) -> None:
        """Test formatting suggestion with metadata."""
        formatter = JSONSuggestionFormatter(include_metadata=True)
        result = formatter.format_suggestion(suggestion_with_metadata)

        assert "metadata" in result
        metadata = result["metadata"]
        assert metadata["generation_time_ms"] == 25.5
>       assert metadata["generator_used"] == "ParameterGenerator"
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'generator_used'

tests\suggestions\formatters\test_json_formatter.py:270: KeyError
__________ TestAnalysisResultFormatting.test_format_analysis_result ___________

self = <test_json_formatter.TestAnalysisResultFormatting object at 0x000002078A6B9590>
enhanced_result = EnhancedAnalysisResult(matched_pair=<Mock id='2231414865408'>, issues=[EnhancedIssue(issue_type='parameter_name_mismat...lysis_time_ms=25.5, cache_hit=True, suggestion_generation_time_ms=15.2, suggestions_generated=1, suggestions_skipped=0)

    def test_format_analysis_result(self, enhanced_result: Any) -> None:
        """Test formatting complete analysis result."""
        formatter = JSONSuggestionFormatter()
        result = formatter.format_analysis_result(enhanced_result)

        # Function information
        assert result["function"]["name"] == "authenticate_user"
        assert result["function"]["line_number"] == 42
        assert result["file_path"] == "auth/user.py"

        # Match information
>       assert result["match_confidence"] == 0.8
E       AssertionError: assert <Mock name='mock.confidence.overall' id='2231416570944'> == 0.8

tests\suggestions\formatters\test_json_formatter.py:363: AssertionError
____ TestAnalysisResultFormatting.test_format_result_without_documentation ____

self = <test_json_formatter.TestAnalysisResultFormatting object at 0x000002078A6B96D0>
enhanced_result = EnhancedAnalysisResult(matched_pair=<Mock id='2231416573296'>, issues=[EnhancedIssue(issue_type='parameter_name_mismat...lysis_time_ms=25.5, cache_hit=True, suggestion_generation_time_ms=15.2, suggestions_generated=1, suggestions_skipped=0)

    def test_format_result_without_documentation(self, enhanced_result: Any) -> None:
        """Test formatting result without documentation."""
        enhanced_result.matched_pair.documentation = None

        formatter = JSONSuggestionFormatter()
        result = formatter.format_analysis_result(enhanced_result)

>       assert "documentation" not in result
E       AssertionError: assert 'documentation' not in {'analysis': {'analysis_time_ms': 25.5, 'cache_hit': True, 'suggestion_generation_time_ms': 15.2, 'suggestions_generated': 1, ...}, 'documentation': {'format': 'raw', 'raw_text': <Mock name='mock.docstring.raw_text' id='2231416574976'>}, 'file_path': 'auth/user.py', 'function': {'line_number': 42, 'name': 'authenticate_user', 'parameters': [], 'return_annotation': 'bool'}, ...}

tests\suggestions\formatters\test_json_formatter.py:400: AssertionError
______________ TestBatchFormatting.test_format_suggestion_batch _______________

self = <test_json_formatter.TestBatchFormatting object at 0x000002078A67D5B0>
suggestion_batch = SuggestionBatch(suggestions=[Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, origina...), affected_sections=[], line_range=(1, 1))], function_name='func', file_path='test.py', total_generation_time_ms=50.0)

    def test_format_suggestion_batch(self, suggestion_batch: Any) -> None:
        """Test formatting suggestion batch."""
        formatter = JSONSuggestionFormatter()
        result = formatter.format_suggestion_batch(suggestion_batch)

        assert len(result["suggestions"]) == 1

        summary = result["summary"]
        assert summary["total_suggestions"] == 1
>       assert summary["total_issues"] == 2
               ^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'total_issues'

tests\suggestions\formatters\test_json_formatter.py:469: KeyError
_____ TestFunctionInformationExtraction.test_format_function_info_minimal _____

self = <test_json_formatter.TestFunctionInformationExtraction object at 0x000002078A6B9E50>

    def test_format_function_info_minimal(self) -> None:
        """Test extracting minimal function information."""
        minimal_function: Mock = Mock()
        # No signature attribute

        formatter = JSONSuggestionFormatter()
>       info = formatter._format_function_info(minimal_function)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\formatters\test_json_formatter.py:545:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.formatters.json_formatter.JSONSuggestionFormatter object at 0x000002078ABCE060>
function = <Mock id='2231416583712'>

    def _format_function_info(self, function: ParsedFunction) -> dict[str, Any]:
        """Extract function information for JSON."""
        info = {
            "name": "Unknown",
            "line_number": 0,
            "parameters": [],
        }

        if hasattr(function, "signature"):
            signature = function.signature
            info["name"] = signature.name
            info["line_number"] = function.line_number

            # Add parameter information
            if hasattr(signature, "parameters"):
>               for param in signature.parameters:
                             ^^^^^^^^^^^^^^^^^^^^
E               TypeError: 'Mock' object is not iterable

codedocsync\suggestions\formatters\json_formatter.py:266: TypeError
____________ TestConvenienceFunctions.test_analysis_result_to_json ____________

self = <test_json_formatter.TestConvenienceFunctions object at 0x000002078A6BA210>
enhanced_result = EnhancedAnalysisResult(matched_pair=<Mock id='2231416573296'>, issues=[EnhancedIssue(issue_type='parameter_name_mismat...lysis_time_ms=25.5, cache_hit=True, suggestion_generation_time_ms=15.2, suggestions_generated=1, suggestions_skipped=0)

    def test_analysis_result_to_json(self, enhanced_result: Any) -> None:
        """Test analysis_result_to_json convenience function."""
>       json_string = analysis_result_to_json(enhanced_result)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\formatters\test_json_formatter.py:602:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\formatters\json_formatter.py:342: in analysis_result_to_json
    return formatter.to_json_string(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\formatters\json_formatter.py:249: in to_json_string
    return json.dumps(data, indent=self.indent, ensure_ascii=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python313\Lib\json\__init__.py:238: in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
C:\Python313\Lib\json\encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python313\Lib\json\encoder.py:261: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <json.encoder.JSONEncoder object at 0x000002078AB53E10>
o = <Mock name='mock.confidence.overall' id='2231416572624'>

    def default(self, o):
        """Implement this method in a subclass such that it returns
        a serializable object for ``o``, or calls the base implementation
        (to raise a ``TypeError``).

        For example, to support arbitrary iterators, you could
        implement default like this::

            def default(self, o):
                try:
                    iterable = iter(o)
                except TypeError:
                    pass
                else:
                    return list(iterable)
                # Let the base class default method raise the TypeError
                return super().default(o)

        """
>       raise TypeError(f'Object of type {o.__class__.__name__} '
                        f'is not JSON serializable')
E       TypeError: Object of type Mock is not JSON serializable

C:\Python313\Lib\json\encoder.py:180: TypeError
_____________ TestConvenienceFunctions.test_batch_results_to_json _____________

self = <test_json_formatter.TestConvenienceFunctions object at 0x000002078A67D6E0>
enhanced_result = EnhancedAnalysisResult(matched_pair=<Mock id='2231414865072'>, issues=[EnhancedIssue(issue_type='parameter_name_mismat...lysis_time_ms=25.5, cache_hit=True, suggestion_generation_time_ms=15.2, suggestions_generated=1, suggestions_skipped=0)

    def test_batch_results_to_json(self, enhanced_result: Any) -> None:
        """Test batch_results_to_json convenience function."""
>       json_string = batch_results_to_json([enhanced_result])
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\formatters\test_json_formatter.py:609:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\formatters\json_formatter.py:349: in batch_results_to_json
    return formatter.to_json_string(data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\formatters\json_formatter.py:249: in to_json_string
    return json.dumps(data, indent=self.indent, ensure_ascii=False)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python313\Lib\json\__init__.py:238: in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
C:\Python313\Lib\json\encoder.py:200: in encode
    chunks = self.iterencode(o, _one_shot=True)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
C:\Python313\Lib\json\encoder.py:261: in iterencode
    return _iterencode(o, 0)
           ^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <json.encoder.JSONEncoder object at 0x00000207E95F2450>
o = <Mock name='mock.confidence.overall' id='2231416583376'>

    def default(self, o):
        """Implement this method in a subclass such that it returns
        a serializable object for ``o``, or calls the base implementation
        (to raise a ``TypeError``).

        For example, to support arbitrary iterators, you could
        implement default like this::

            def default(self, o):
                try:
                    iterable = iter(o)
                except TypeError:
                    pass
                else:
                    return list(iterable)
                # Let the base class default method raise the TypeError
                return super().default(o)

        """
>       raise TypeError(f'Object of type {o.__class__.__name__} '
                        f'is not JSON serializable')
E       TypeError: Object of type Mock is not JSON serializable

C:\Python313\Lib\json\encoder.py:180: TypeError
_________ TestSuggestionFormatting.test_format_basic_suggestion_plain _________

self = <test_terminal_formatter.TestSuggestionFormatting object at 0x000002078A6BAE90>
basic_suggestion = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='def func(email: str):..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1))

    def test_format_basic_suggestion_plain(self, basic_suggestion: Any) -> None:
        """Test formatting basic suggestion in plain text."""
        formatter = TerminalSuggestionFormatter(style=OutputStyle.PLAIN)
        result = formatter.format_suggestion(basic_suggestion)

        assert "Parameter Update" in result
        assert "Confidence: 90%" in result
>       assert basic_suggestion.suggested_text in result
E       assert 'def func(username: str):\n    """Function with username param."""' in '=== Parameter Update ===\nConfidence: 90%\n\nSuggested code:\n----------------------------------------\n  1: def func(username: str):\n  2:     """Function with username param."""\n----------------------------------------'
E        +  where 'def func(username: str):\n    """Function with username param."""' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='def func(email: str):\n    """Function with email param."""', suggested_text='def func(username: str):\n    """Function with username param."""', confidence=0.9, diff=SuggestionDiff(original_lines=['def func(email: str):', '    """Function with email param."""'], suggested_lines=['def func(username: str):', '    """Function with username param."""'], start_line=1, end_line=2), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='unknown', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\formatters\test_terminal_formatter.py:210: AssertionError
____________ TestSuggestionFormatting.test_format_suggestion_rich _____________

self = <test_terminal_formatter.TestSuggestionFormatting object at 0x000002078A695040>
basic_suggestion = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='def func(email: str):..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1))

    @patch("codedocsync.suggestions.formatters.terminal_formatter.RICH_AVAILABLE", True)
    def test_format_suggestion_rich(self, basic_suggestion: Any) -> None:
        """Test rich formatting (mocked)."""
        with patch(
            "codedocsync.suggestions.formatters.terminal_formatter.Console"
        ) as mock_console:
            mock_console_instance: Mock = Mock()
            mock_console.return_value = mock_console_instance
>           mock_console_instance.capture.return_value.__enter__.return_value = Mock()
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\formatters\test_terminal_formatter.py:257:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <Mock name='Console().capture()' id='2231416582368'>, name = '__enter__'

    def __getattr__(self, name):
        if name in {'_mock_methods', '_mock_unsafe'}:
            raise AttributeError(name)
        elif self._mock_methods is not None:
            if name not in self._mock_methods or name in _all_magics:
                raise AttributeError("Mock object has no attribute %r" % name)
        elif _is_magic(name):
>           raise AttributeError(name)
E           AttributeError: __enter__

C:\Python313\Lib\unittest\mock.py:692: AttributeError
_____ TestEnhancedIssueFormatting.test_format_issue_with_suggestion_plain _____

self = <test_terminal_formatter.TestEnhancedIssueFormatting object at 0x000002078A6BAAD0>
enhanced_issue = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description="Parameter 'email' doesn't match ...on_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)), formatted_output=None, ranking_score=None)

    def test_format_issue_with_suggestion_plain(self, enhanced_issue: Any) -> None:
        """Test formatting issue with suggestion in plain text."""
        formatter = TerminalSuggestionFormatter(style=OutputStyle.PLAIN)
        result = formatter.format_enhanced_issue(enhanced_issue)

        assert "[CRITICAL]" in result
        assert enhanced_issue.description in result
        assert f"Line: {enhanced_issue.line_number}" in result
>       assert enhanced_issue.rich_suggestion.suggested_text in result
E       assert 'def func(username: str):\n    """Function with username param."""' in '[CRITICAL] Parameter \'email\' doesn\'t match \'username\' in code\n  Line: 45\n\n=== Parameter Update ===\nConfidence: 90%\n\nSuggested code:\n----------------------------------------\n  1: def func(username: str):\n  2:     """Function with username param."""\n----------------------------------------'
E        +  where 'def func(username: str):\n    """Function with username param."""' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='def func(email: str):\n    """Function with email param."""', suggested_text='def func(username: str):\n    """Function with username param."""', confidence=0.9, diff=SuggestionDiff(original_lines=['def func(email: str):', '    """Function with email param."""'], suggested_lines=['def func(username: str):', '    """Function with username param."""'], start_line=1, end_line=2), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='unknown', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text
E        +    where Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='def func(email: str):\n    """Function with email param."""', suggested_text='def func(username: str):\n    """Function with username param."""', confidence=0.9, diff=SuggestionDiff(original_lines=['def func(email: str):', '    """Function with email param."""'], suggested_lines=['def func(username: str):', '    """Function with username param."""'], start_line=1, end_line=2), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='unknown', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)) = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description="Parameter 'email' doesn't match 'username' in code", suggestion='Update parameter name', line_number=45, confidence=0.9, details={}, rich_suggestion=Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='def func(email: str):\n    """Function with email param."""', suggested_text='def func(username: str):\n    """Function with username param."""', confidence=0.9, diff=SuggestionDiff(original_lines=['def func(email: str):', '    """Function with email param."""'], suggested_lines=['def func(username: str):', '    """Function with username param."""'], start_line=1, end_line=2), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='unknown', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)), formatted_output=None, ranking_score=None).rich_suggestion

tests\suggestions\formatters\test_terminal_formatter.py:280: AssertionError
_________ TestBatchSummaryFormatting.test_format_batch_summary_plain __________

self = <test_terminal_formatter.TestBatchSummaryFormatting object at 0x000002078A6BB4D0>
suggestion_batch = SuggestionBatch(suggestions=[Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, origina...fected_sections=[], line_range=(1, 1))], function_name='test_func', file_path='test.py', total_generation_time_ms=50.0)

    def test_format_batch_summary_plain(self, suggestion_batch: Any) -> None:
        """Test formatting batch summary in plain text."""
        formatter = TerminalSuggestionFormatter(style=OutputStyle.PLAIN)
        result = formatter.format_batch_summary(suggestion_batch)

        assert "Suggestion Generation Summary" in result
>       assert "Functions Processed: 1" in result
E       AssertionError: assert 'Functions Processed: 1' in 'Suggestion Generation Summary\n==============================\nFunction: test_func\nFile: test.py\nSuggestions Generated: 1\nGeneration Time: 50.0ms\nAverage Confidence: 90.0%'

tests\suggestions\formatters\test_terminal_formatter.py:375: AssertionError
________ TestBatchSummaryFormatting.test_format_batch_summary_minimal _________

self = <test_terminal_formatter.TestBatchSummaryFormatting object at 0x000002078A6BB610>
suggestion_batch = SuggestionBatch(suggestions=[Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, origina...fected_sections=[], line_range=(1, 1))], function_name='test_func', file_path='test.py', total_generation_time_ms=50.0)

    def test_format_batch_summary_minimal(self, suggestion_batch: Any) -> None:
        """Test formatting batch summary in minimal mode."""
        formatter = TerminalSuggestionFormatter(style=OutputStyle.MINIMAL)
        result = formatter.format_batch_summary(suggestion_batch)

>       assert "Processed: 1" in result
E       AssertionError: assert 'Processed: 1' in 'Function: test_func, Suggestions: 1, Time: 50.0ms'

tests\suggestions\formatters\test_terminal_formatter.py:386: AssertionError
_____________ TestBatchSummaryFormatting.test_format_empty_batch ______________

self = <test_terminal_formatter.TestBatchSummaryFormatting object at 0x000002078A67E2C0>

    def test_format_empty_batch(self) -> None:
        """Test formatting empty batch summary."""
        empty_batch = SuggestionBatch(
            suggestions=[],
            function_name="",
            file_path="",
            total_generation_time_ms=0.0,
        )

        formatter = TerminalSuggestionFormatter(style=OutputStyle.PLAIN)
        result = formatter.format_batch_summary(empty_batch)

>       assert "Functions Processed: 0" in result
E       AssertionError: assert 'Functions Processed: 0' in 'Suggestion Generation Summary\n==============================\nFunction: \nFile: \nSuggestions Generated: 0\nGeneration Time: 0.0ms'

tests\suggestions\formatters\test_terminal_formatter.py:402: AssertionError
_________________ TestEdgeCases.test_suggestion_without_diff __________________

self = <test_terminal_formatter.TestEdgeCases object at 0x000002078A6BBED0>
basic_suggestion = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='def func(email: str):..., rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1))

    def test_suggestion_without_diff(self, basic_suggestion: Any) -> None:
        """Test suggestion without diff information."""
        # Ensure no diff
        basic_suggestion.diff = None

        formatter = TerminalSuggestionFormatter(style=OutputStyle.PLAIN)
        result = formatter.format_suggestion(basic_suggestion)

        # Should handle gracefully
        assert isinstance(result, str)
>       assert basic_suggestion.suggested_text in result
E       assert 'def func(username: str):\n    """Function with username param."""' in '=== Parameter Update ===\nConfidence: 90%\n\nSuggested code:\n----------------------------------------\n  1: def func(username: str):\n  2:     """Function with username param."""\n----------------------------------------'
E        +  where 'def func(username: str):\n    """Function with username param."""' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='def func(email: str):\n    """Function with email param."""', suggested_text='def func(username: str):\n    """Function with username param."""', confidence=0.9, diff=None, style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='unknown', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\formatters\test_terminal_formatter.py:525: AssertionError
_______________ TestEdgeCases.test_issue_with_zero_line_number ________________

self = <test_terminal_formatter.TestEdgeCases object at 0x000002078A740050>

    def test_issue_with_zero_line_number(self) -> None:
        """Test issue with zero line number."""
>       issue = EnhancedIssue(
            issue_type="test",
            severity="medium",
            description="Test issue",
            suggestion="Test suggestion",
            line_number=0,  # Edge case
        )

tests\suggestions\formatters\test_terminal_formatter.py:529:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:13: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = EnhancedIssue(issue_type='test', severity='medium', description='Test issue', suggestion='Test suggestion', line_number=0, confidence=1.0, details={}, rich_suggestion=None, formatted_output=None, ranking_score=None)

    def __post_init__(self) -> None:
        """Validate enhanced issue."""
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError(f"confidence must be 0.0-1.0, got {self.confidence}")
        if self.line_number < 1:
>           raise ValueError(f"line_number must be positive, got {self.line_number}")
E           ValueError: line_number must be positive, got 0

codedocsync\suggestions\integration.py:54: ValueError
________________ TestEdgeCases.test_function_without_signature ________________

self = <test_terminal_formatter.TestEdgeCases object at 0x000002078A67E650>

    def test_function_without_signature(self) -> None:
        """Test function without proper signature."""
        mock_function: Mock = Mock()
        # No signature attribute

        mock_pair: Mock = Mock()
        mock_pair.function = mock_function

        result = EnhancedAnalysisResult(
            matched_pair=mock_pair,
            issues=[],
        )

        formatter = TerminalSuggestionFormatter(style=OutputStyle.PLAIN)
        formatted = formatter.format_analysis_result(result)

        # Should handle gracefully with "Unknown" function name
>       assert "Unknown" in formatted
E       assert 'Unknown' in "\u2705 No issues found in <Mock name='mock.function.signature.name' id='2231414864736'>"

tests\suggestions\formatters\test_terminal_formatter.py:561: AssertionError
______________ TestBehaviorAnalyzer.test_analyze_data_operations ______________

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorAnalyzer object at 0x000002078A740690>

        def test_analyze_data_operations(self) -> None:
            """Test analyzing data manipulation patterns."""
            source_code = """
    def test_func(data: Any) -> None:
        processed = [x * 2 for x in data]
        result = {}
        for item in processed:
            result[str(item)] = item
        return result
    """
            analyzer = BehaviorAnalyzer()
            patterns = analyzer.analyze_behavior(source_code, "test_func")

            pattern_types = [p.pattern_type for p in patterns]
            assert "data_transformation" in pattern_types
>           assert "data_creation" in pattern_types
E           AssertionError: assert 'data_creation' in ['iteration', 'early_exit', 'data_transformation']

tests\suggestions\generators\test_behavior_generator.py:63: AssertionError
______________ TestBehaviorAnalyzer.test_analyze_error_handling _______________

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorAnalyzer object at 0x000002078A67E8B0>

        def test_analyze_error_handling(self) -> None:
            """Test analyzing error handling patterns."""
            source_code = """
    def test_func(value: Any) -> None:
        assert isinstance(value, str), "Value must be string"

        if not value:
            raise ValueError("Value cannot be empty")

        try:
            result = risky_operation(value)
        except Exception as e:
            log_error(e)
            return None

        return result
    """
            analyzer = BehaviorAnalyzer()
            patterns = analyzer.analyze_behavior(source_code, "test_func")

            pattern_types = [p.pattern_type for p in patterns]
            assert "error_handling" in pattern_types
>           assert "input_validation" in pattern_types
E           AssertionError: assert 'input_validation' in ['conditional', 'early_exit', 'error_handling', 'assertion_checks']

tests\suggestions\generators\test_behavior_generator.py:106: AssertionError
________ TestBehaviorAnalyzer.test_analyze_performance_characteristics ________

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorAnalyzer object at 0x000002078A70B0B0>

        def test_analyze_performance_characteristics(self) -> None:
            """Test analyzing performance-related patterns."""
            source_code = """
    def test_func(matrix: Any) -> None:
        result = []
        for i in range(len(matrix)):
            row = []
            for j in range(len(matrix[i])):
                row.append(matrix[i][j] * 2)
            result.append(row)
        return result
    """
            analyzer = BehaviorAnalyzer()
            patterns = analyzer.analyze_behavior(source_code, "test_func")

            pattern_types = [p.pattern_type for p in patterns]
>           assert "nested_iteration" in pattern_types
E           AssertionError: assert 'nested_iteration' in ['iteration', 'early_exit', 'data_modification']

tests\suggestions\generators\test_behavior_generator.py:125: AssertionError
___________ TestBehaviorSuggestionGenerator.test_unknown_issue_type ___________

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorSuggestionGenerator object at 0x000002078A4DB6B0>
generator = <codedocsync.suggestions.generators.behavior_generator.BehaviorSuggestionGenerator object at 0x000002078AB1A850>
mock_function = <Mock id='2231414864400'>
mock_docstring = <Mock id='2231416570944'>

    def test_unknown_issue_type(
        self,
        generator: Any,
        mock_function: MockerFixture,
        mock_docstring: MockerFixture,
    ) -> None:
        """Test handling unknown issue types."""
>       unknown_issue = InconsistencyIssue(
            issue_type="unknown_behavior_issue",
            severity="medium",
            description="Unknown issue",
            suggestion="",
            line_number=10,
        )

tests\suggestions\generators\test_behavior_generator.py:470:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='unknown_behavior_issue', severity='medium', description='Unknown issue', suggestion='', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'unknown_behavior_issue'

codedocsync\analyzer\models.py:63: ValueError
___ TestBehaviorGeneratorIntegration.test_complete_workflow_data_processing ___

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorGeneratorIntegration object at 0x000002078A740A50>
generator = <codedocsync.suggestions.generators.behavior_generator.BehaviorSuggestionGenerator object at 0x000002078AB7FB60>

        def test_complete_workflow_data_processing(self, generator: Any) -> None:
            """Test complete workflow for data processing function."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "filter_and_transform_data"
            function.line_number = 5
            function.source_code = '''
    def filter_and_transform_data(raw_data, threshold=0.5):
        """Filter data."""
        filtered = []

        # Validate input
        if not isinstance(raw_data, list):
            raise TypeError("Expected list")

        # Process each item
        for item in raw_data:
            if hasattr(item, 'score') and item.score > threshold:
                # Transform the item
                transformed = {
                    'id': item.id,
                    'value': item.value * 2,
                    'normalized_score': item.score / 100
                }
                filtered.append(transformed)

        # Log results
        import logging
        logging.info(f"Processed {len(filtered)} items")

        return filtered
    '''

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Filter data"  # Vague
            docstring.description = None
            docstring.parameters = []
            docstring.returns = None
            docstring.raises = []
            docstring.examples = []
            docstring.raw_text = '"""Filter data."""'

>           issue = InconsistencyIssue(
                issue_type="description_vague",
                severity="medium",
                description="Description is too vague",
                suggestion="Improve description clarity",
                line_number=5,
            )

tests\suggestions\generators\test_behavior_generator.py:545:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Improve description clarity', line_number=5, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
___ TestBehaviorGeneratorIntegration.test_complete_workflow_file_operations ___

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorGeneratorIntegration object at 0x000002078A740B90>
generator = <codedocsync.suggestions.generators.behavior_generator.BehaviorSuggestionGenerator object at 0x000002078AD82300>

        def test_complete_workflow_file_operations(self, generator: Any) -> None:
            """Test complete workflow for file operations with side effects."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "backup_and_process_file"
            function.line_number = 8
            function.source_code = '''
    def backup_and_process_file(filepath, backup_dir):
        """Process file."""
        import os
        import shutil
        import logging

        # Create backup
        backup_path = os.path.join(backup_dir, os.path.basename(filepath))
        shutil.copy2(filepath, backup_path)
        logging.info(f"Created backup: {backup_path}")

        # Process original file
        with open(filepath, 'r') as f:
            content = f.read()

        processed_content = content.upper()

        with open(filepath, 'w') as f:
            f.write(processed_content)

        print(f"Processed file: {filepath}")
        return backup_path
    '''

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Process file"
            docstring.description = None
            docstring.parameters = []
            docstring.returns = None
            docstring.raises = []
            docstring.examples = []
            docstring.raw_text = '"""Process file."""'

>           issue = InconsistencyIssue(
                issue_type="side_effects_undocumented",
                severity="high",
                description="Side effects not documented",
                suggestion="Document side effects",
                line_number=8,
            )

tests\suggestions\generators\test_behavior_generator.py:614:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='side_effects_undocumented', severity='high', description='Side effects not documented', suggestion='Document side effects', line_number=8, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'side_effects_undocumented'

codedocsync\analyzer\models.py:63: ValueError
_____ TestBehaviorGeneratorIntegration.test_performance_pattern_detection _____

self = <tests.suggestions.generators.test_behavior_generator.TestBehaviorGeneratorIntegration object at 0x000002078A67ED70>
generator = <codedocsync.suggestions.generators.behavior_generator.BehaviorSuggestionGenerator object at 0x00000207E964FBD0>

        def test_performance_pattern_detection(self, generator: Any) -> None:
            """Test detection of performance-related patterns."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "matrix_multiply"
            function.line_number = 3
            function.source_code = '''
    def matrix_multiply(a, b):
        """Multiply matrices."""
        result = []
        for i in range(len(a)):
            row = []
            for j in range(len(b[0])):
                sum_val = 0
                for k in range(len(b)):
                    sum_val += a[i][k] * b[k][j]
                row.append(sum_val)
            result.append(row)
        return result
    '''

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Multiply matrices"
            docstring.description = None
            docstring.raw_text = '"""Multiply matrices."""'

>           issue = InconsistencyIssue(
                issue_type="description_vague",
                severity="medium",
                description="Should mention performance characteristics",
                suggestion="",
                line_number=3,
            )

tests\suggestions\generators\test_behavior_generator.py:667:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Should mention performance characteristics', suggestion='', line_number=3, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
__________ TestSpecialConstructAnalyzer.test_analyze_property_getter __________

self = <tests.suggestions.generators.test_edge_case_handlers.TestSpecialConstructAnalyzer object at 0x000002078A740CD0>
analyzer = <codedocsync.suggestions.generators.edge_case_handlers.SpecialConstructAnalyzer object at 0x000002078ACAC2F0>

    def test_analyze_property_getter(self, analyzer: Any) -> None:
        """Test analyzing property getter."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.decorators = ["property"]

>       constructs = analyzer.analyze_function(function)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_edge_case_handlers.py:41:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\edge_case_handlers.py:121: in analyze_function
    if self._is_generator_function(source_code):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\edge_case_handlers.py:162: in _is_generator_function
    tree = ast.parse(source_code)
           ^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

source = <Mock name='mock.source_code' id='2231416574640'>
filename = '<unknown>', mode = 'exec'

    def parse(source, filename='<unknown>', mode='exec', *,
              type_comments=False, feature_version=None, optimize=-1):
        """
        Parse the source into an AST node.
        Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
        Pass type_comments=True to get back type comments where the syntax allows.
        """
        flags = PyCF_ONLY_AST
        if optimize > 0:
            flags |= PyCF_OPTIMIZED_AST
        if type_comments:
            flags |= PyCF_TYPE_COMMENTS
        if feature_version is None:
            feature_version = -1
        elif isinstance(feature_version, tuple):
            major, minor = feature_version  # Should be a 2-tuple.
            if major != 3:
                raise ValueError(f"Unsupported major version: {major}")
            feature_version = minor
        # Else it should be an int giving the minor version for 3.x.
>       return compile(source, filename, mode, flags,
                       _feature_version=feature_version, optimize=optimize)
E       TypeError: compile() arg 1 must be a string, bytes or AST object

C:\Python313\Lib\ast.py:50: TypeError
____________ TestSpecialConstructAnalyzer.test_analyze_classmethod ____________

self = <tests.suggestions.generators.test_edge_case_handlers.TestSpecialConstructAnalyzer object at 0x000002078A740E10>
analyzer = <codedocsync.suggestions.generators.edge_case_handlers.SpecialConstructAnalyzer object at 0x000002078ACE82D0>

    def test_analyze_classmethod(self, analyzer: Any) -> None:
        """Test analyzing class method."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.decorators = ["classmethod"]

>       constructs = analyzer.analyze_function(function)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_edge_case_handlers.py:55:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\edge_case_handlers.py:121: in analyze_function
    if self._is_generator_function(source_code):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\edge_case_handlers.py:162: in _is_generator_function
    tree = ast.parse(source_code)
           ^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

source = <Mock name='mock.source_code' id='2231416579344'>
filename = '<unknown>', mode = 'exec'

    def parse(source, filename='<unknown>', mode='exec', *,
              type_comments=False, feature_version=None, optimize=-1):
        """
        Parse the source into an AST node.
        Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
        Pass type_comments=True to get back type comments where the syntax allows.
        """
        flags = PyCF_ONLY_AST
        if optimize > 0:
            flags |= PyCF_OPTIMIZED_AST
        if type_comments:
            flags |= PyCF_TYPE_COMMENTS
        if feature_version is None:
            feature_version = -1
        elif isinstance(feature_version, tuple):
            major, minor = feature_version  # Should be a 2-tuple.
            if major != 3:
                raise ValueError(f"Unsupported major version: {major}")
            feature_version = minor
        # Else it should be an int giving the minor version for 3.x.
>       return compile(source, filename, mode, flags,
                       _feature_version=feature_version, optimize=optimize)
E       TypeError: compile() arg 1 must be a string, bytes or AST object

C:\Python313\Lib\ast.py:50: TypeError
___________ TestSpecialConstructAnalyzer.test_analyze_magic_method ____________

self = <tests.suggestions.generators.test_edge_case_handlers.TestSpecialConstructAnalyzer object at 0x000002078A67EFD0>
analyzer = <codedocsync.suggestions.generators.edge_case_handlers.SpecialConstructAnalyzer object at 0x000002078AB6F750>

    def test_analyze_magic_method(self, analyzer: Any) -> None:
        """Test analyzing magic method."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.name = "__init__"
        function.signature.decorators = []

>       constructs = analyzer.analyze_function(function)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_edge_case_handlers.py:70:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\edge_case_handlers.py:121: in analyze_function
    if self._is_generator_function(source_code):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\edge_case_handlers.py:162: in _is_generator_function
    tree = ast.parse(source_code)
           ^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

source = <Mock name='mock.source_code' id='2231414864736'>
filename = '<unknown>', mode = 'exec'

    def parse(source, filename='<unknown>', mode='exec', *,
              type_comments=False, feature_version=None, optimize=-1):
        """
        Parse the source into an AST node.
        Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
        Pass type_comments=True to get back type comments where the syntax allows.
        """
        flags = PyCF_ONLY_AST
        if optimize > 0:
            flags |= PyCF_OPTIMIZED_AST
        if type_comments:
            flags |= PyCF_TYPE_COMMENTS
        if feature_version is None:
            feature_version = -1
        elif isinstance(feature_version, tuple):
            major, minor = feature_version  # Should be a 2-tuple.
            if major != 3:
                raise ValueError(f"Unsupported major version: {major}")
            feature_version = minor
        # Else it should be an int giving the minor version for 3.x.
>       return compile(source, filename, mode, flags,
                       _feature_version=feature_version, optimize=optimize)
E       TypeError: compile() arg 1 must be a string, bytes or AST object

C:\Python313\Lib\ast.py:50: TypeError
__________ TestSpecialConstructAnalyzer.test_analyze_async_function ___________

self = <tests.suggestions.generators.test_edge_case_handlers.TestSpecialConstructAnalyzer object at 0x000002078A67F100>
analyzer = <codedocsync.suggestions.generators.edge_case_handlers.SpecialConstructAnalyzer object at 0x000002078AB53100>

    def test_analyze_async_function(self, analyzer: Any) -> None:
        """Test analyzing async function."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.is_async = True
        function.signature.decorators = []

>       constructs = analyzer.analyze_function(function)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_edge_case_handlers.py:85:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\edge_case_handlers.py:121: in analyze_function
    if self._is_generator_function(source_code):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\edge_case_handlers.py:162: in _is_generator_function
    tree = ast.parse(source_code)
           ^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

source = <Mock name='mock.source_code' id='2231416573968'>
filename = '<unknown>', mode = 'exec'

    def parse(source, filename='<unknown>', mode='exec', *,
              type_comments=False, feature_version=None, optimize=-1):
        """
        Parse the source into an AST node.
        Equivalent to compile(source, filename, mode, PyCF_ONLY_AST).
        Pass type_comments=True to get back type comments where the syntax allows.
        """
        flags = PyCF_ONLY_AST
        if optimize > 0:
            flags |= PyCF_OPTIMIZED_AST
        if type_comments:
            flags |= PyCF_TYPE_COMMENTS
        if feature_version is None:
            feature_version = -1
        elif isinstance(feature_version, tuple):
            major, minor = feature_version  # Should be a 2-tuple.
            if major != 3:
                raise ValueError(f"Unsupported major version: {major}")
            feature_version = minor
        # Else it should be an int giving the minor version for 3.x.
>       return compile(source, filename, mode, flags,
                       _feature_version=feature_version, optimize=optimize)
E       TypeError: compile() arg 1 must be a string, bytes or AST object

C:\Python313\Lib\ast.py:50: TypeError
__________ TestPropertyMethodHandler.test_property_setter_detection ___________

self = <tests.suggestions.generators.test_edge_case_handlers.TestPropertyMethodHandler object at 0x000002078A741090>
handler = <codedocsync.suggestions.generators.edge_case_handlers.PropertyMethodHandler object at 0x000002078ACE87D0>

    def test_property_setter_detection(self, handler: Any) -> None:
        """Test detecting property setter."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.name = "username"
        function.signature.decorators = ["username.setter"]

>       assert handler._is_property_setter(function) is True
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'PropertyMethodHandler' object has no attribute '_is_property_setter'. Did you mean: 'handle_property_setter'?

tests\suggestions\generators\test_edge_case_handlers.py:145: AttributeError
__________ TestPropertyMethodHandler.test_property_deleter_detection __________

self = <tests.suggestions.generators.test_edge_case_handlers.TestPropertyMethodHandler object at 0x000002078A67F230>
handler = <codedocsync.suggestions.generators.edge_case_handlers.PropertyMethodHandler object at 0x000002078ACE8050>

    def test_property_deleter_detection(self, handler: Any) -> None:
        """Test detecting property deleter."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.name = "username"
        function.signature.decorators = ["username.deleter"]

>       assert handler._is_property_deleter(function) is True
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'PropertyMethodHandler' object has no attribute '_is_property_deleter'. Did you mean: 'handle_property_deleter'?

tests\suggestions\generators\test_edge_case_handlers.py:154: AttributeError
______________ TestClassMethodHandler.test_staticmethod_handling ______________

self = <tests.suggestions.generators.test_edge_case_handlers.TestClassMethodHandler object at 0x000002078A741310>
handler = <codedocsync.suggestions.generators.edge_case_handlers.ClassMethodHandler object at 0x000002078ACE8B90>

    def test_staticmethod_handling(self, handler: Any) -> None:
        """Test that static methods are also handled."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.decorators = ["staticmethod"]

>       constructs = handler._analyze_constructs(function)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
E       AttributeError: 'ClassMethodHandler' object has no attribute '_analyze_constructs'

tests\suggestions\generators\test_edge_case_handlers.py:219: AttributeError
_______ TestEdgeCaseSuggestionGenerator.test_async_function_suggestion ________

self = <tests.suggestions.generators.test_edge_case_handlers.TestEdgeCaseSuggestionGenerator object at 0x000002078A67F360>
generator = <codedocsync.suggestions.generators.edge_case_handlers.EdgeCaseSuggestionGenerator object at 0x000002078ACE9090>

    def test_async_function_suggestion(self, generator: Any) -> None:
        """Test generating suggestion for async function."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.name = "fetch_data"
        function.signature.is_async = True
        function.signature.return_annotation = "dict"
        function.signature.parameters = []

>       issue = InconsistencyIssue(
            issue_type="missing_docstring",
            severity="high",
            description="Async function has no docstring",
            suggestion="Add a docstring",
            line_number=30,
        )

tests\suggestions\generators\test_edge_case_handlers.py:279:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_docstring', severity='high', description='Async function has no docstring', suggestion='Add a docstring', line_number=30, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_docstring'

codedocsync\analyzer\models.py:63: ValueError
________ TestEdgeCaseSuggestionGenerator.test_magic_method_suggestion _________

self = <tests.suggestions.generators.test_edge_case_handlers.TestEdgeCaseSuggestionGenerator object at 0x000002078A67F490>
generator = <codedocsync.suggestions.generators.edge_case_handlers.EdgeCaseSuggestionGenerator object at 0x000002078AB53230>

    def test_magic_method_suggestion(self, generator: Any) -> None:
        """Test generating suggestion for magic method."""
        function: Mock = Mock()
        function.signature = Mock()
        function.signature.name = "__str__"
        function.signature.return_annotation = "str"
        function.signature.parameters = []

>       issue = InconsistencyIssue(
            issue_type="missing_docstring",
            severity="medium",
            description="Magic method has no docstring",
            suggestion="Add a docstring",
            line_number=40,
        )

tests\suggestions\generators\test_edge_case_handlers.py:309:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_docstring', severity='medium', description='Magic method has no docstring', suggestion='Add a docstring', line_number=40, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_docstring'

codedocsync\analyzer\models.py:63: ValueError
___________ TestParameterValueGenerator.test_generate_value_by_name ___________

self = <tests.suggestions.generators.test_example_generator.TestParameterValueGenerator object at 0x000002078A741810>
generator = <codedocsync.suggestions.generators.example_generator.ParameterValueGenerator object at 0x000002078AB0BE00>

    def test_generate_value_by_name(self, generator: Any) -> None:
        """Test value generation based on parameter names."""
        test_cases = [
            ("name", '"John Doe"'),
            ("filename", '"example.txt"'),
            ("url", '"https://example.com"'),
            ("email", '"user@example.com"'),
            ("count", "10"),
            ("age", "25"),
            ("data", "[1, 2, 3, 4, 5]"),
        ]

        for param_name, expected_value in test_cases:
            param: Mock = Mock()
            param.name = param_name
            param.type_annotation = None
            param.is_required = True
            param.default_value = None

            result = generator.generate_value(param)
>           assert result == expected_value
E           assert '"John Doe"' == '"example.txt"'
E
E             - "example.txt"
E             + "John Doe"

tests\suggestions\generators\test_example_generator.py:58: AssertionError
____ TestParameterValueGenerator.test_generate_value_optional_with_default ____

self = <tests.suggestions.generators.test_example_generator.TestParameterValueGenerator object at 0x000002078A67F5C0>
generator = <codedocsync.suggestions.generators.example_generator.ParameterValueGenerator object at 0x000002078AB6EE90>

    def test_generate_value_optional_with_default(self, generator: Any) -> None:
        """Test value generation for optional parameters with defaults."""
        param: Mock = Mock()
        param.name = "timeout"
        param.type_annotation = "int"
        param.is_required = False
        param.default_value = "30"

        result = generator.generate_value(param)
>       assert result == "30"
E       AssertionError: assert '42' == '30'
E
E         - 30
E         + 42

tests\suggestions\generators\test_example_generator.py:90: AssertionError
___________ TestExamplePatternAnalyzer.test_analyze_async_function ____________

self = <tests.suggestions.generators.test_example_generator.TestExamplePatternAnalyzer object at 0x000002078A741A90>
analyzer = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AB6F610>

        def test_analyze_async_function(self, analyzer: Any) -> None:
            """Test analyzing async functions."""
            source_code = """
    async def fetch_data():
        return await api_call()
    """

>           analysis = analyzer.analyze_function(Mock(), source_code)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_example_generator.py:144:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AB6F610>
function = <Mock id='2231416572288'>
source_code = '\nasync def fetch_data():\n    return await api_call()\n'

    def analyze_function(self, function: Any, source_code: str = "") -> dict[str, Any]:
        """Analyze function to determine example characteristics."""
        analysis = {
            "is_property": False,
            "is_classmethod": False,
            "is_staticmethod": False,
            "is_async": False,
            "is_generator": False,
            "has_side_effects": False,
            "return_type": None,
            "complexity": "basic",
            "domain": "general",
        }

        # Analyze function signature
        if hasattr(function, "signature"):
            sig = function.signature

            # Check decorators
            if hasattr(sig, "decorators"):
                decorators = sig.decorators or []
>               analysis["is_property"] = "property" in decorators
                                          ^^^^^^^^^^^^^^^^^^^^^^^^
E               TypeError: argument of type 'Mock' is not iterable

codedocsync\suggestions\generators\example_generator.py:151: TypeError
_________ TestExamplePatternAnalyzer.test_analyze_generator_function __________

self = <tests.suggestions.generators.test_example_generator.TestExamplePatternAnalyzer object at 0x000002078A67F820>
analyzer = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AB6F750>

        def test_analyze_generator_function(self, analyzer: Any) -> None:
            """Test analyzing generator functions."""
            source_code = """
    def number_generator():
        for i in range(10):
            yield i
    """

>           analysis = analyzer.analyze_function(Mock(), source_code)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_example_generator.py:156:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AB6F750>
function = <Mock id='2231416572624'>
source_code = '\ndef number_generator():\n    for i in range(10):\n        yield i\n'

    def analyze_function(self, function: Any, source_code: str = "") -> dict[str, Any]:
        """Analyze function to determine example characteristics."""
        analysis = {
            "is_property": False,
            "is_classmethod": False,
            "is_staticmethod": False,
            "is_async": False,
            "is_generator": False,
            "has_side_effects": False,
            "return_type": None,
            "complexity": "basic",
            "domain": "general",
        }

        # Analyze function signature
        if hasattr(function, "signature"):
            sig = function.signature

            # Check decorators
            if hasattr(sig, "decorators"):
                decorators = sig.decorators or []
>               analysis["is_property"] = "property" in decorators
                                          ^^^^^^^^^^^^^^^^^^^^^^^^
E               TypeError: argument of type 'Mock' is not iterable

codedocsync\suggestions\generators\example_generator.py:151: TypeError
____________ TestExamplePatternAnalyzer.test_analyze_side_effects _____________

self = <tests.suggestions.generators.test_example_generator.TestExamplePatternAnalyzer object at 0x000002078A67F950>
analyzer = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AB529E0>

        def test_analyze_side_effects(self, analyzer: Any) -> None:
            """Test analyzing functions with side effects."""
            source_code = """
    def process_file(filename):
        with open(filename, 'w') as f:
            f.write("data")
        print("Done")
    """

>           analysis = analyzer.analyze_function(Mock(), source_code)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_example_generator.py:169:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AB529E0>
function = <Mock id='2231416573296'>
source_code = '\ndef process_file(filename):\n    with open(filename, \'w\') as f:\n        f.write("data")\n    print("Done")\n'

    def analyze_function(self, function: Any, source_code: str = "") -> dict[str, Any]:
        """Analyze function to determine example characteristics."""
        analysis = {
            "is_property": False,
            "is_classmethod": False,
            "is_staticmethod": False,
            "is_async": False,
            "is_generator": False,
            "has_side_effects": False,
            "return_type": None,
            "complexity": "basic",
            "domain": "general",
        }

        # Analyze function signature
        if hasattr(function, "signature"):
            sig = function.signature

            # Check decorators
            if hasattr(sig, "decorators"):
                decorators = sig.decorators or []
>               analysis["is_property"] = "property" in decorators
                                          ^^^^^^^^^^^^^^^^^^^^^^^^
E               TypeError: argument of type 'Mock' is not iterable

codedocsync\suggestions\generators\example_generator.py:151: TypeError
__________ TestExamplePatternAnalyzer.test_analyze_domain_detection ___________

self = <tests.suggestions.generators.test_example_generator.TestExamplePatternAnalyzer object at 0x000002078A74D490>
analyzer = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AC755B0>

        def test_analyze_domain_detection(self, analyzer: Any) -> None:
            """Test domain detection from function calls."""
            math_source = """
    def calculate():
        return sqrt(x) + sin(y)
    """

            file_source = """
    def process():
        with open("file.txt") as f:
            return f.read()
    """

>           math_analysis = analyzer.analyze_function(Mock(), math_source)
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_example_generator.py:186:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AC755B0>
function = <Mock id='2231416570608'>
source_code = '\ndef calculate():\n    return sqrt(x) + sin(y)\n'

    def analyze_function(self, function: Any, source_code: str = "") -> dict[str, Any]:
        """Analyze function to determine example characteristics."""
        analysis = {
            "is_property": False,
            "is_classmethod": False,
            "is_staticmethod": False,
            "is_async": False,
            "is_generator": False,
            "has_side_effects": False,
            "return_type": None,
            "complexity": "basic",
            "domain": "general",
        }

        # Analyze function signature
        if hasattr(function, "signature"):
            sig = function.signature

            # Check decorators
            if hasattr(sig, "decorators"):
                decorators = sig.decorators or []
>               analysis["is_property"] = "property" in decorators
                                          ^^^^^^^^^^^^^^^^^^^^^^^^
E               TypeError: argument of type 'Mock' is not iterable

codedocsync\suggestions\generators\example_generator.py:151: TypeError
______________ TestExampleGenerator.test_generate_async_example _______________

self = <tests.suggestions.generators.test_example_generator.TestExampleGenerator object at 0x000002078A67FBB0>
generator = <codedocsync.suggestions.generators.example_generator.ExampleGenerator object at 0x000002078AC74D60>

    def test_generate_async_example(self, generator: Any) -> None:
        """Test generating example for async function."""
        async_function: Mock = Mock()
        async_function.signature = Mock()
        async_function.signature.name = "fetch_data"
        async_function.signature.parameters = []

        analysis = {
            "is_async": True,
            "return_type": "dict",
        }

>       example = generator._generate_basic_example(async_function, analysis)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_example_generator.py:286:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.example_generator.ExampleGenerator object at 0x000002078AC74D60>
function = <Mock id='2231416578336'>
analysis = {'is_async': True, 'return_type': 'dict'}

    def _generate_basic_example(
        self, function: Any, analysis: dict[str, Any]
    ) -> ExampleTemplate | None:
        """Generate a basic usage example."""
        if not hasattr(function, "signature"):
            return None

        sig = function.signature
        function_name = sig.name

        # Generate parameter values
        call_args = []
        setup_lines = []
        imports: list[str] = []

        # Handle different function types
>       if analysis["is_classmethod"]:
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'is_classmethod'

codedocsync\suggestions\generators\example_generator.py:265: KeyError
_____________ TestExampleGenerator.test_generate_property_example _____________

self = <tests.suggestions.generators.test_example_generator.TestExampleGenerator object at 0x000002078A7097F0>
generator = <codedocsync.suggestions.generators.example_generator.ExampleGenerator object at 0x000002078AB529E0>

    def test_generate_property_example(self, generator: Any) -> None:
        """Test generating example for property."""
        property_function: Mock = Mock()
        property_function.signature = Mock()
        property_function.signature.name = "name"
        property_function.signature.parameters = []

        analysis = {
            "is_property": True,
            "return_type": "str",
        }

>       example = generator._generate_basic_example(property_function, analysis)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_example_generator.py:303:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.example_generator.ExampleGenerator object at 0x000002078AB529E0>
function = <Mock id='2231414862384'>
analysis = {'is_property': True, 'return_type': 'str'}

    def _generate_basic_example(
        self, function: Any, analysis: dict[str, Any]
    ) -> ExampleTemplate | None:
        """Generate a basic usage example."""
        if not hasattr(function, "signature"):
            return None

        sig = function.signature
        function_name = sig.name

        # Generate parameter values
        call_args = []
        setup_lines = []
        imports: list[str] = []

        # Handle different function types
>       if analysis["is_classmethod"]:
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'is_classmethod'

codedocsync\suggestions\generators\example_generator.py:265: KeyError
_____________ TestExampleGenerator.test_generate_edge_case_values _____________

self = <tests.suggestions.generators.test_example_generator.TestExampleGenerator object at 0x000002078A696470>
generator = <codedocsync.suggestions.generators.example_generator.ExampleGenerator object at 0x000002078AB2AB10>

    def test_generate_edge_case_values(self, generator: Any) -> None:
        """Test generation of edge case parameter values."""
        test_cases = [
            ("count", "0"),
            ("index", "-1"),
            ("items", "[]"),
            ("config", "{}"),
        ]

        for param_name, expected_value in test_cases:
            param: Mock = Mock()
            param.name = param_name
            param.type_annotation = None

            result = generator._generate_edge_case_value(param)
>           assert result == expected_value
E           AssertionError: assert 'None' == '{}'
E
E             - {}
E             + None

tests\suggestions\generators\test_example_generator.py:324: AssertionError
_____________ TestExampleGenerator.test_generate_expected_output ______________

self = <tests.suggestions.generators.test_example_generator.TestExampleGenerator object at 0x000002078A6B5B50>
generator = <codedocsync.suggestions.generators.example_generator.ExampleGenerator object at 0x000002078ABB6360>

    def test_generate_expected_output(self, generator: Any) -> None:
        """Test generation of expected output."""
        test_cases = [
            ({"return_type": "str"}, '"result"'),
            ({"return_type": "int"}, "42"),
            ({"return_type": "bool"}, "True"),
            ({"return_type": "None"}, "None"),
            ({"is_generator": True}, "# Generator object"),
        ]

        for analysis, expected_output in test_cases:
>           result = generator._generate_expected_output(analysis)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_example_generator.py:348:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.example_generator.ExampleGenerator object at 0x000002078ABB6360>
analysis = {'is_generator': True}

    def _generate_expected_output(self, analysis: dict[str, Any]) -> str:
        """Generate expected output description."""
>       if analysis["return_type"]:
           ^^^^^^^^^^^^^^^^^^^^^^^
E       KeyError: 'return_type'

codedocsync\suggestions\generators\example_generator.py:447: KeyError
____________ TestExampleGenerator.test_generate_multiple_examples _____________

self = <tests.suggestions.generators.test_example_generator.TestExampleGenerator object at 0x000002078A6B5C50>
generator = <codedocsync.suggestions.generators.example_generator.ExampleGenerator object at 0x000002078AB1A450>
mock_function = <Mock id='2231414864400'>

    def test_generate_multiple_examples(
        self, generator: Any, mock_function: Mock
    ) -> None:
        """Test generating multiple examples."""
>       examples = generator.generate_examples(mock_function, count=3)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_example_generator.py:355:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\example_generator.py:226: in generate_examples
    analysis = self.pattern_analyzer.analyze_function(function, source_code)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.example_generator.ExamplePatternAnalyzer object at 0x000002078AC7DFD0>
function = <Mock id='2231414864400'>, source_code = ''

    def analyze_function(self, function: Any, source_code: str = "") -> dict[str, Any]:
        """Analyze function to determine example characteristics."""
        analysis = {
            "is_property": False,
            "is_classmethod": False,
            "is_staticmethod": False,
            "is_async": False,
            "is_generator": False,
            "has_side_effects": False,
            "return_type": None,
            "complexity": "basic",
            "domain": "general",
        }

        # Analyze function signature
        if hasattr(function, "signature"):
            sig = function.signature

            # Check decorators
            if hasattr(sig, "decorators"):
                decorators = sig.decorators or []
>               analysis["is_property"] = "property" in decorators
                                          ^^^^^^^^^^^^^^^^^^^^^^^^
E               TypeError: argument of type 'Mock' is not iterable

codedocsync\suggestions\generators\example_generator.py:151: TypeError
___________ TestExampleSuggestionGenerator.test_unknown_issue_type ____________

self = <tests.suggestions.generators.test_example_generator.TestExampleSuggestionGenerator object at 0x000002078A6967A0>
generator = <codedocsync.suggestions.generators.example_generator.ExampleSuggestionGenerator object at 0x000002078ABB4E20>
mock_function = <Mock id='2231416572960'>
mock_docstring = <Mock id='2231416578672'>

    def test_unknown_issue_type(
        self, generator: Any, mock_function: Mock, mock_docstring: Mock
    ) -> None:
        """Test handling unknown issue types."""
>       unknown_issue = InconsistencyIssue(
            issue_type="unknown_example_issue",
            severity="low",
            description="Unknown issue",
            suggestion="",
            line_number=10,
        )

tests\suggestions\generators\test_example_generator.py:556:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='unknown_example_issue', severity='low', description='Unknown issue', suggestion='', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'unknown_example_issue'

codedocsync\analyzer\models.py:63: ValueError
_ TestExampleGeneratorIntegration.test_complete_workflow_mathematical_function _

self = <tests.suggestions.generators.test_example_generator.TestExampleGeneratorIntegration object at 0x000002078A7420D0>
generator = <codedocsync.suggestions.generators.example_generator.ExampleSuggestionGenerator object at 0x000002078ABB67A0>

        def test_complete_workflow_mathematical_function(self, generator: Any) -> None:
            """Test complete workflow for mathematical function."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "calculate_distance"
            function.line_number = 5

            # Parameters
            x1_param: Mock = Mock()
            x1_param.name = "x1"
            x1_param.type_annotation = "float"
            x1_param.is_required = True
            x1_param.default_value = None

            y1_param: Mock = Mock()
            y1_param.name = "y1"
            y1_param.type_annotation = "float"
            y1_param.is_required = True
            y1_param.default_value = None

            x2_param: Mock = Mock()
            x2_param.name = "x2"
            x2_param.type_annotation = "float"
            x2_param.is_required = True
            x2_param.default_value = None

            y2_param: Mock = Mock()
            y2_param.name = "y2"
            y2_param.type_annotation = "float"
            y2_param.is_required = True
            y2_param.default_value = None

            function.signature.parameters = [x1_param, y1_param, x2_param, y2_param]
            function.source_code = """
    def calculate_distance(x1, y1, x2, y2):
        import math
        return math.sqrt((x2 - x1)**2 + (y2 - y1)**2)
    """

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Calculate distance between two points"
            docstring.description = None
            docstring.parameters = []
            docstring.returns = None
            docstring.raises = []
            docstring.examples = []  # Missing examples
            docstring.raw_text = '"""Calculate distance between two points."""'

>           issue = InconsistencyIssue(
                issue_type="missing_examples",
                severity="low",
                description="Function lacks usage examples",
                suggestion="Add examples",
                line_number=5,
            )

tests\suggestions\generators\test_example_generator.py:637:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='Function lacks usage examples', suggestion='Add examples', line_number=5, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
_ TestExampleGeneratorIntegration.test_complete_workflow_file_processing_function _

self = <tests.suggestions.generators.test_example_generator.TestExampleGeneratorIntegration object at 0x000002078A742210>
generator = <codedocsync.suggestions.generators.example_generator.ExampleSuggestionGenerator object at 0x000002078ACB0950>

        def test_complete_workflow_file_processing_function(self, generator: Any) -> None:
            """Test complete workflow for file processing function."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "process_csv_file"
            function.line_number = 8

            # Parameters with meaningful names
            filepath_param: Mock = Mock()
            filepath_param.name = "filepath"
            filepath_param.type_annotation = "str"
            filepath_param.is_required = True
            filepath_param.default_value = None

            encoding_param: Mock = Mock()
            encoding_param.name = "encoding"
            encoding_param.type_annotation = "str"
            encoding_param.is_required = False
            encoding_param.default_value = "'utf-8'"

            function.signature.parameters = [filepath_param, encoding_param]
            function.source_code = """
    def process_csv_file(filepath, encoding='utf-8'):
        import csv
        with open(filepath, 'r', encoding=encoding) as f:
            return list(csv.reader(f))
    """

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Process CSV file and return rows"
            docstring.examples = []  # Missing examples
            docstring.raw_text = '"""Process CSV file and return rows."""'

>           issue = InconsistencyIssue(
                issue_type="missing_examples",
                severity="low",
                description="Add usage examples",
                suggestion="",
                line_number=8,
            )

tests\suggestions\generators\test_example_generator.py:700:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='Add usage examples', suggestion='', line_number=8, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
___ TestExampleGeneratorIntegration.test_async_function_example_generation ____

self = <tests.suggestions.generators.test_example_generator.TestExampleGeneratorIntegration object at 0x000002078A7B0050>
generator = <codedocsync.suggestions.generators.example_generator.ExampleSuggestionGenerator object at 0x000002078ACB0550>

        def test_async_function_example_generation(self, generator: Any) -> None:
            """Test example generation for async functions."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "fetch_user_data"
            function.line_number = 3

            user_id_param: Mock = Mock()
            user_id_param.name = "user_id"
            user_id_param.type_annotation = "int"
            user_id_param.is_required = True
            user_id_param.default_value = None

            function.signature.parameters = [user_id_param]
            function.source_code = """
    async def fetch_user_data(user_id):
        async with aiohttp.ClientSession() as session:
            async with session.get(f"/users/{user_id}") as response:
                return await response.json()
    """

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Fetch user data asynchronously"
            docstring.examples = []
            docstring.raw_text = '"""Fetch user data asynchronously."""'

>           issue = InconsistencyIssue(
                issue_type="missing_examples",
                severity="low",
                description="Add async examples",
                suggestion="",
                line_number=3,
            )

tests\suggestions\generators\test_example_generator.py:754:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='Add async examples', suggestion='', line_number=3, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
__________ TestParameterSuggestionGenerator.test_fix_parameter_order __________

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A7B0510>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AC76060>

    def test_fix_parameter_order(self, generator: Any) -> None:
        """Test fixing parameter order mismatch."""
        # Function with param1, param2 but docstring has param2, param1
        signature = FunctionSignature(
            name="test_function",
            parameters=[
                FunctionParameter(name="param1", type_annotation="str"),
                FunctionParameter(name="param2", type_annotation="int"),
            ],
        )

>       function = ParsedFunction(
            signature=signature, docstring=None, file_path="test.py", line_number=10
        )

tests\suggestions\generators\test_parameter_generator.py:181:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param1', type_ann...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=10, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (10)

codedocsync\parser\ast_parser.py:159: ValidationError
_______ TestParameterSuggestionGenerator.test_add_kwargs_documentation ________

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A79F410>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AB529E0>

    def test_add_kwargs_documentation(self, generator: Any) -> None:
        """Test adding **kwargs documentation."""
        signature = FunctionSignature(
            name="test_function",
            parameters=[
                FunctionParameter(name="param1", type_annotation="str"),
                FunctionParameter(name="**kwargs", type_annotation=None),
            ],
        )

>       function = ParsedFunction(
            signature=signature, docstring=None, file_path="test.py", line_number=10
        )

tests\suggestions\generators\test_parameter_generator.py:226:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param1', type_ann...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=10, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (10)

codedocsync\parser\ast_parser.py:159: ValidationError
_______ TestParameterSuggestionGenerator.test_filter_special_parameters _______

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A6969C0>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AB66570>

    def test_filter_special_parameters(self, generator: Any) -> None:
        """Test filtering special parameters like self and cls."""
        # Test with self parameter (instance method)
        signature = FunctionSignature(
            name="test_method",
            parameters=[
                FunctionParameter(name="self"),
                FunctionParameter(name="param1", type_annotation="str"),
            ],
            is_method=True,
        )

>       function = ParsedFunction(
            signature=signature, docstring=None, file_path="test.py", line_number=10
        )

tests\suggestions\generators\test_parameter_generator.py:268:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_method', parameters=[FunctionParameter(name='self', type_annotat...is_method=True, decorators=[]), docstring=None, file_path='test.py', line_number=10, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (10)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestParameterSuggestionGenerator.test_normalize_type _____________

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A6B6150>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078ACB0450>

    def test_normalize_type(self, generator: Any) -> None:
        """Test type normalization."""
        assert generator._normalize_type("str") == "str"
>       assert generator._normalize_type("List[str]") == "list"
E       AssertionError: assert 'list[str]' == 'list'
E
E         - list
E         + list[str]

tests\suggestions\generators\test_parameter_generator.py:320: AssertionError
______ TestParameterSuggestionGenerator.test_detect_style_from_docstring ______

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A71D040>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AD82030>

    def test_detect_style_from_docstring(self, generator: Any) -> None:
        """Test detecting docstring style."""
        google_docstring = ParsedDocstring(
            format=DocstringFormat.GOOGLE, summary="Test"
        )

        style = generator._detect_style(google_docstring)
>       assert style == DocstringStyle.GOOGLE
E       AssertionError: assert 'google' == <DocstringStyle.GOOGLE: 'google'>
E        +  where <DocstringStyle.GOOGLE: 'google'> = DocstringStyle.GOOGLE

tests\suggestions\generators\test_parameter_generator.py:343: AssertionError
__________ TestParameterSuggestionGenerator.test_fallback_suggestion __________

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A7C4830>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AEA9130>

    def test_fallback_suggestion(self, generator: Any) -> None:
        """Test fallback suggestion for unknown issues."""
>       issue = InconsistencyIssue(
            issue_type="unknown_issue",
            severity="low",
            description="Unknown issue",
            suggestion="Manual fix needed",
            line_number=10,
        )

tests\suggestions\generators\test_parameter_generator.py:347:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='unknown_issue', severity='low', description='Unknown issue', suggestion='Manual fix needed', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'unknown_issue'

codedocsync\analyzer\models.py:63: ValueError
_________ TestParameterSuggestionGenerator.test_generic_parameter_fix _________

self = <tests.suggestions.generators.test_parameter_generator.TestParameterSuggestionGenerator object at 0x000002078A7C4AD0>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AE0DB70>

    def test_generic_parameter_fix(self, generator: Any) -> None:
        """Test generic parameter fix for unhandled issue types."""
>       issue = InconsistencyIssue(
            issue_type="unhandled_parameter_issue",
            severity="medium",
            description="Unhandled issue",
            suggestion="Fix manually",
            line_number=10,
        )

tests\suggestions\generators\test_parameter_generator.py:364:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='unhandled_parameter_issue', severity='medium', description='Unhandled issue', suggestion='Fix manually', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'unhandled_parameter_issue'

codedocsync\analyzer\models.py:63: ValueError
_______ TestParameterGeneratorEdgeCases.test_empty_function_parameters ________

self = <tests.suggestions.generators.test_parameter_generator.TestParameterGeneratorEdgeCases object at 0x000002078A742990>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AE0E970>

    def test_empty_function_parameters(self, generator: Any) -> None:
        """Test handling function with no parameters."""
        signature = FunctionSignature(name="test_function", parameters=[])
>       function = ParsedFunction(
            signature=signature, docstring=None, file_path="test.py", line_number=10
        )

tests\suggestions\generators\test_parameter_generator.py:392:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[], return_type=None, is_async=False, is_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=10, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (10)

codedocsync\parser\ast_parser.py:159: ValidationError
_________ TestParameterGeneratorEdgeCases.test_classmethod_detection __________

self = <tests.suggestions.generators.test_parameter_generator.TestParameterGeneratorEdgeCases object at 0x000002078A7CD370>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AE5CF70>

    def test_classmethod_detection(self, generator: Any) -> None:
        """Test detection of classmethod decorator."""
        signature = FunctionSignature(
            name="test_classmethod",
            decorators=["classmethod"],
            parameters=[
                FunctionParameter(name="cls"),
                FunctionParameter(name="param1", type_annotation="str"),
            ],
        )

>       function = ParsedFunction(
            signature=signature, docstring=None, file_path="test.py", line_number=10
        )

tests\suggestions\generators\test_parameter_generator.py:437:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_classmethod', parameters=[FunctionParameter(name='cls', type_ann...e, decorators=['classmethod']), docstring=None, file_path='test.py', line_number=10, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (10)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestRaisesSuggestionGenerator.test_add_missing_raises_documentation _____

self = <tests.suggestions.generators.test_raises_generator.TestRaisesSuggestionGenerator object at 0x000002078A743110>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078AB0BCB0>
mock_function = <Mock id='2231416585728'>
mock_docstring = <Mock id='2231416577664'>
mock_issue = InconsistencyIssue(issue_type='missing_raises', severity='medium', description='Missing exception documentation', suggestion='Add raises documentation', line_number=10, confidence=1.0, details={})

    def test_add_missing_raises_documentation(
        self,
        generator: Any,
        mock_function: Mock,
        mock_docstring: Mock,
        mock_issue: InconsistencyIssue,
    ) -> None:
        """Test adding missing raises documentation."""
        context = SuggestionContext(
            function=mock_function, docstring=mock_docstring, issue=mock_issue
        )

>       suggestion = generator._add_missing_raises_documentation(context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_raises_generator.py:213:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\raises_generator.py:286: in _add_missing_raises_documentation
    updated_docstring = self._add_exceptions_to_docstring(
codedocsync\suggestions\generators\raises_generator.py:468: in _add_exceptions_to_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078AB0BCB0>
docstring = <Mock id='2231416577664'>

    def _detect_style(self, docstring: Any) -> DocstringStyle:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Convert string to DocstringStyle enum
>           style_value = docstring.format.value
                          ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\raises_generator.py:514: AttributeError
_________ TestRaisesSuggestionGenerator.test_fix_raises_type_mismatch _________

self = <tests.suggestions.generators.test_raises_generator.TestRaisesSuggestionGenerator object at 0x000002078A743250>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x00000207E95E7D90>
mock_function = <Mock id='2231416581024'>
mock_docstring = <Mock id='2231416581360'>
mock_issue = InconsistencyIssue(issue_type='raises_type_mismatch', severity='medium', description='Missing exception documentation', suggestion='Add raises documentation', line_number=10, confidence=1.0, details={})

    def test_fix_raises_type_mismatch(
        self,
        generator: Any,
        mock_function: Mock,
        mock_docstring: Mock,
        mock_issue: InconsistencyIssue,
    ) -> None:
        """Test fixing raises type mismatch."""
        # Add existing (incorrect) raises documentation
        mock_docstring.raises = [
            DocstringRaises(
                exception_type="RuntimeError", description="Wrong exception"
            ),
            DocstringRaises(
                exception_type="ValueError", description="Correct exception"
            ),
        ]
        mock_issue.issue_type = "raises_type_mismatch"

        context = SuggestionContext(
            function=mock_function, docstring=mock_docstring, issue=mock_issue
        )

>       suggestion = generator._fix_raises_type_mismatch(context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_raises_generator.py:248:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\raises_generator.py:357: in _fix_raises_type_mismatch
    corrected_docstring = self._update_raises_in_docstring(
codedocsync\suggestions\generators\raises_generator.py:498: in _update_raises_in_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x00000207E95E7D90>
docstring = <Mock id='2231416581360'>

    def _detect_style(self, docstring: Any) -> DocstringStyle:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Convert string to DocstringStyle enum
>           style_value = docstring.format.value
                          ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\raises_generator.py:514: AttributeError
________ TestRaisesSuggestionGenerator.test_improve_raises_description ________

self = <tests.suggestions.generators.test_raises_generator.TestRaisesSuggestionGenerator object at 0x000002078A7B0D60>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078ACEA490>
mock_function = <Mock id='2231416571616'>
mock_docstring = <Mock id='2231416572960'>
mock_issue = InconsistencyIssue(issue_type='raises_description_vague', severity='medium', description='Missing exception documentation', suggestion='Add raises documentation', line_number=10, confidence=1.0, details={})

    def test_improve_raises_description(
        self,
        generator: Any,
        mock_function: Mock,
        mock_docstring: Mock,
        mock_issue: InconsistencyIssue,
    ) -> None:
        """Test improving vague raises descriptions."""
        mock_docstring.raises = [
            DocstringRaises(exception_type="ValueError", description="error"),
            DocstringRaises(exception_type="TypeError", description="failure"),
        ]
        mock_issue.issue_type = "raises_description_vague"

        context = SuggestionContext(
            function=mock_function, docstring=mock_docstring, issue=mock_issue
        )

>       suggestion = generator._improve_raises_description(context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_raises_generator.py:275:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\raises_generator.py:414: in _improve_raises_description
    updated_docstring = self._update_raises_in_docstring(context, improved_raises)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\raises_generator.py:498: in _update_raises_in_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078ACEA490>
docstring = <Mock id='2231416572960'>

    def _detect_style(self, docstring: Any) -> DocstringStyle:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Convert string to DocstringStyle enum
>           style_value = docstring.format.value
                          ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\raises_generator.py:514: AttributeError
___________ TestRaisesSuggestionGenerator.test_is_vague_description ___________

self = <tests.suggestions.generators.test_raises_generator.TestRaisesSuggestionGenerator object at 0x000002078A7B0E90>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078AC756E0>

    def test_is_vague_description(self, generator: Any) -> None:
        """Test detection of vague exception descriptions."""
        # Test vague descriptions
        assert generator._is_vague_description("error")
        assert generator._is_vague_description("exception")
        assert generator._is_vague_description("failure")
>       assert generator._is_vague_description("when error occurs")
E       AssertionError: assert False
E        +  where False = _is_vague_description('when error occurs')
E        +    where _is_vague_description = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078AC756E0>._is_vague_description

tests\suggestions\generators\test_raises_generator.py:291: AssertionError
_________ TestRaisesSuggestionGenerator.test_no_source_code_fallback __________

self = <tests.suggestions.generators.test_raises_generator.TestRaisesSuggestionGenerator object at 0x000002078A697350>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078ABE3650>
mock_function = <Mock id='2231416573968'>
mock_docstring = <Mock id='2231416570608'>
mock_issue = InconsistencyIssue(issue_type='missing_raises', severity='medium', description='Missing exception documentation', suggestion='Add raises documentation', line_number=10, confidence=1.0, details={})

    def test_no_source_code_fallback(
        self,
        generator: Any,
        mock_function: Mock,
        mock_docstring: Mock,
        mock_issue: InconsistencyIssue,
    ) -> None:
        """Test fallback when source code is not available."""
        mock_function.source_code = ""

        context = SuggestionContext(
            function=mock_function, docstring=mock_docstring, issue=mock_issue
        )

>       suggestion = generator._add_missing_raises_documentation(context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_raises_generator.py:339:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\raises_generator.py:267: in _add_missing_raises_documentation
    return self._create_fallback_suggestion(
codedocsync\suggestions\generators\raises_generator.py:563: in _create_fallback_suggestion
    return self._create_suggestion(
codedocsync\suggestions\generators\raises_generator.py:555: in _create_suggestion
    style=self._detect_style(context.docstring).value,
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078ABE3650>
docstring = <Mock id='2231416570608'>

    def _detect_style(self, docstring: Any) -> DocstringStyle:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Convert string to DocstringStyle enum
>           style_value = docstring.format.value
                          ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\raises_generator.py:514: AttributeError
________ TestRaisesSuggestionGenerator.test_no_significant_exceptions _________

self = <tests.suggestions.generators.test_raises_generator.TestRaisesSuggestionGenerator object at 0x000002078A697460>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078ACFD7B0>
mock_function = <Mock id='2231418962000'>
mock_docstring = <Mock id='2231418962672'>
mock_issue = InconsistencyIssue(issue_type='missing_raises', severity='medium', description='Missing exception documentation', suggestion='Add raises documentation', line_number=10, confidence=1.0, details={})

        def test_no_significant_exceptions(
            self,
            generator: Any,
            mock_function: Mock,
            mock_docstring: Mock,
            mock_issue: InconsistencyIssue,
        ) -> None:
            """Test handling when no significant exceptions are detected."""
            # Function with only very low-confidence exceptions
            mock_function.source_code = """
    def simple_func():
        return "hello"
    """

            context = SuggestionContext(
                function=mock_function, docstring=mock_docstring, issue=mock_issue
            )

>           suggestion = generator._add_missing_raises_documentation(context)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_raises_generator.py:362:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\raises_generator.py:281: in _add_missing_raises_documentation
    return self._create_fallback_suggestion(
codedocsync\suggestions\generators\raises_generator.py:563: in _create_fallback_suggestion
    return self._create_suggestion(
codedocsync\suggestions\generators\raises_generator.py:555: in _create_suggestion
    style=self._detect_style(context.docstring).value,
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078ACFD7B0>
docstring = <Mock id='2231418962672'>

    def _detect_style(self, docstring: Any) -> DocstringStyle:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Convert string to DocstringStyle enum
>           style_value = docstring.format.value
                          ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\raises_generator.py:514: AttributeError
____________ TestRaisesSuggestionGenerator.test_unknown_issue_type ____________

self = <tests.suggestions.generators.test_raises_generator.TestRaisesSuggestionGenerator object at 0x000002078A6B6850>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078ABB6360>
mock_function = <Mock id='2231414865072'>
mock_docstring = <Mock id='2231416573968'>

    def test_unknown_issue_type(
        self, generator: Any, mock_function: Mock, mock_docstring: Mock
    ) -> None:
        """Test handling unknown issue types."""
>       unknown_issue = InconsistencyIssue(
            issue_type="unknown_raises_issue",
            severity="medium",
            description="Unknown issue",
            suggestion="",
            line_number=10,
        )

tests\suggestions\generators\test_raises_generator.py:371:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='unknown_raises_issue', severity='medium', description='Unknown issue', suggestion='', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'unknown_raises_issue'

codedocsync\analyzer\models.py:63: ValueError
____ TestRaisesGeneratorIntegration.test_complete_workflow_file_operations ____

self = <tests.suggestions.generators.test_raises_generator.TestRaisesGeneratorIntegration object at 0x000002078A743390>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078AB1A850>

        def test_complete_workflow_file_operations(self, generator: Any) -> None:
            """Test complete workflow for file operations function."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "read_config_file"
            function.line_number = 5
            function.source_code = """
    def read_config_file(filename):
        if not filename:
            raise ValueError("Filename cannot be empty")

        try:
            with open(filename, 'r') as f:
                content = f.read()
        except FileNotFoundError:
            raise FileNotFoundError(f"Config file {filename} not found")
        except PermissionError:
            raise PermissionError(f"Permission denied: {filename}")

        try:
            import json
            return json.loads(content)
        except json.JSONDecodeError:
            raise ValueError(f"Invalid JSON in {filename}")
    """

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Read configuration from file"
            docstring.description = None
            docstring.parameters = []
            docstring.returns = None
            docstring.raises = []  # Missing raises documentation
            docstring.examples = []
            docstring.raw_text = '"""Read configuration from file."""'

            issue = InconsistencyIssue(
                issue_type="missing_raises",
                severity="medium",
                description="Missing exception documentation",
                suggestion="Document exceptions",
                line_number=5,
            )

            context = SuggestionContext(function=function, docstring=docstring, issue=issue)

>           suggestion = generator.generate(context)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_raises_generator.py:449:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\raises_generator.py:248: in generate
    return self._add_missing_raises_documentation(context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\raises_generator.py:286: in _add_missing_raises_documentation
    updated_docstring = self._add_exceptions_to_docstring(
codedocsync\suggestions\generators\raises_generator.py:468: in _add_exceptions_to_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078AB1A850>
docstring = <Mock id='2231416572960'>

    def _detect_style(self, docstring: Any) -> DocstringStyle:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Convert string to DocstringStyle enum
>           style_value = docstring.format.value
                          ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\raises_generator.py:514: AttributeError
__ TestRaisesGeneratorIntegration.test_complete_workflow_mismatch_correction __

self = <tests.suggestions.generators.test_raises_generator.TestRaisesGeneratorIntegration object at 0x000002078A7434D0>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078ACB1B50>

        def test_complete_workflow_mismatch_correction(self, generator: Any) -> None:
            """Test complete workflow for correcting exception mismatches."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "validate_input"
            function.line_number = 8
            function.source_code = """
    def validate_input(data):
        if not isinstance(data, dict):
            raise TypeError("Expected dictionary")
        if 'required_field' not in data:
            raise ValueError("Missing required field")
        return True
    """

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Validate input data"
            docstring.raises = [
                # Incorrect exception documented
                DocstringRaises(
                    exception_type="RuntimeError", description="When validation fails"
                ),
                # Missing TypeError, has ValueError but different description
                DocstringRaises(exception_type="ValueError", description="Old description"),
            ]
            docstring.parameters = []
            docstring.returns = None
            docstring.examples = []
            docstring.raw_text = '"""Validate input data."""'

>           issue = InconsistencyIssue(
                issue_type="raises_type_mismatch",
                severity="high",
                description="Exception type mismatch",
                suggestion="Fix documented exceptions",
                line_number=8,
            )

tests\suggestions\generators\test_raises_generator.py:495:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='raises_type_mismatch', severity='high', description='Exception type mismatch', suggestion='Fix documented exceptions', line_number=8, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'raises_type_mismatch'

codedocsync\analyzer\models.py:63: ValueError
____ TestRaisesGeneratorIntegration.test_edge_case_no_exceptions_detected _____

self = <tests.suggestions.generators.test_raises_generator.TestRaisesGeneratorIntegration object at 0x000002078A7B0FC0>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078AD82210>

        def test_edge_case_no_exceptions_detected(self, generator: Any) -> None:
            """Test edge case where no exceptions are detected."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "simple_getter"
            function.line_number = 3
            function.source_code = """
    def simple_getter(self):
        return self._value
    """

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Get the value"
            docstring.raises = []
            docstring.raw_text = '"""Get the value."""'

>           issue = InconsistencyIssue(
                issue_type="missing_raises",
                severity="low",
                description="Check for exceptions",
                suggestion="",
                line_number=3,
            )

tests\suggestions\generators\test_raises_generator.py:538:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_raises', severity='low', description='Check for exceptions', suggestion='', line_number=3, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
            raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )

        # Validate severity
        valid_severities = ["critical", "high", "medium", "low"]
        if self.severity not in valid_severities:
            raise ValueError(
                f"severity must be one of {valid_severities}, got '{self.severity}'"
            )

        # Validate confidence
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError(
                f"confidence must be between 0.0 and 1.0, got {self.confidence}"
            )

        # Validate line_number
        if self.line_number < 1:
            raise ValueError(f"line_number must be positive, got {self.line_number}")

        # Validate required strings are not empty
        if not self.description.strip():
            raise ValueError("description cannot be empty")

        if not self.suggestion.strip():
>           raise ValueError("suggestion cannot be empty")
E           ValueError: suggestion cannot be empty

codedocsync\analyzer\models.py:90: ValueError
_________ TestReturnStatementAnalyzer.test_analyze_generator_function _________

self = <tests.suggestions.generators.test_return_generator.TestReturnStatementAnalyzer object at 0x000002078A7B1350>

        def test_analyze_generator_function(self) -> None:
            """Test analyzing generator function."""
            source_code = """
    def test_func() -> None:
        for i in range(10):
            yield i
    """
            analyzer = ReturnStatementAnalyzer()
            result = analyzer.analyze(source_code)

            assert result.is_generator
>           assert "Generator[int]" in result.return_types
E           AssertionError: assert 'Generator[int]' in set()
E            +  where set() = <codedocsync.suggestions.generators.return_generator.ReturnAnalysisResult object at 0x000002078ACEA490>.return_types

tests\suggestions\generators\test_return_generator.py:74: AssertionError
_________ TestReturnSuggestionGenerator.test_fix_return_type_mismatch _________

self = <tests.suggestions.generators.test_return_generator.TestReturnSuggestionGenerator object at 0x000002078A743890>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ACAE900>
mock_function = <Mock id='2231416577328'>
mock_docstring = <Mock id='2231416585392'>
mock_issue = InconsistencyIssue(issue_type='return_type_mismatch', severity='high', description='Return type mismatch', suggestion='Fix return type', line_number=10, confidence=1.0, details={})

    def test_fix_return_type_mismatch(
        self,
        generator: Any,
        mock_function: Mock,
        mock_docstring: Mock,
        mock_issue: InconsistencyIssue,
    ) -> None:
        """Test fixing return type mismatch."""
        context = SuggestionContext(
            function=mock_function, docstring=mock_docstring, issue=mock_issue
        )

>       suggestion = generator._fix_return_type(context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_return_generator.py:182:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\return_generator.py:172: in _fix_return_type
    corrected_docstring = self._update_return_type_in_docstring(
codedocsync\suggestions\generators\return_generator.py:346: in _update_return_type_in_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ACAE900>
docstring = <Mock id='2231416585392'>

    def _detect_style(self, docstring: Any) -> str:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Return the string format directly
>           return str(docstring.format.value)
                       ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\return_generator.py:483: AttributeError
_____ TestReturnSuggestionGenerator.test_add_missing_return_documentation _____

self = <tests.suggestions.generators.test_return_generator.TestReturnSuggestionGenerator object at 0x000002078A7439D0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ACEA350>
mock_function = <Mock id='2231418964016'>
mock_docstring = <Mock id='2231418964688'>
mock_issue = InconsistencyIssue(issue_type='missing_returns', severity='high', description='Return type mismatch', suggestion='Fix return type', line_number=10, confidence=1.0, details={})

    def test_add_missing_return_documentation(
        self,
        generator: Any,
        mock_function: Mock,
        mock_docstring: Mock,
        mock_issue: InconsistencyIssue,
    ) -> None:
        """Test adding missing return documentation."""
        mock_issue.issue_type = "missing_returns"
        context = SuggestionContext(
            function=mock_function, docstring=mock_docstring, issue=mock_issue
        )

>       suggestion = generator._add_missing_return_documentation(context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_return_generator.py:202:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\return_generator.py:209: in _add_missing_return_documentation
    updated_docstring = self._add_return_to_docstring(context, suggested_type)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\return_generator.py:369: in _add_return_to_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ACEA350>
docstring = <Mock id='2231418964688'>

    def _detect_style(self, docstring: Any) -> str:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Return the string format directly
>           return str(docstring.format.value)
                       ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\return_generator.py:483: AttributeError
________ TestReturnSuggestionGenerator.test_improve_return_description ________

self = <tests.suggestions.generators.test_return_generator.TestReturnSuggestionGenerator object at 0x000002078A7B15B0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ACEA0D0>
mock_function = <Mock id='2231418965024'>
mock_docstring = <Mock id='2231418965696'>
mock_issue = InconsistencyIssue(issue_type='return_description_vague', severity='high', description='Return type mismatch', suggestion='Fix return type', line_number=10, confidence=1.0, details={})

    def test_improve_return_description(
        self,
        generator: Any,
        mock_function: Mock,
        mock_docstring: Mock,
        mock_issue: InconsistencyIssue,
    ) -> None:
        """Test improving vague return description."""
        mock_docstring.returns = DocstringReturns(type_str="str", description="result")
        mock_issue.issue_type = "return_description_vague"

        context = SuggestionContext(
            function=mock_function, docstring=mock_docstring, issue=mock_issue
        )

>       suggestion = generator._improve_return_description(context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_return_generator.py:226:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\return_generator.py:246: in _improve_return_description
    updated_docstring = self._update_return_description_in_docstring(
codedocsync\suggestions\generators\return_generator.py:456: in _update_return_description_in_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ACEA0D0>
docstring = <Mock id='2231418965696'>

    def _detect_style(self, docstring: Any) -> str:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Return the string format directly
>           return str(docstring.format.value)
                       ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\return_generator.py:483: AttributeError
___________ TestReturnSuggestionGenerator.test_fix_generator_return ___________

self = <tests.suggestions.generators.test_return_generator.TestReturnSuggestionGenerator object at 0x000002078A7B16E0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AB52D70>
mock_function = <Mock id='2231414865072'>
mock_docstring = <Mock id='2231416577328'>
mock_issue = InconsistencyIssue(issue_type='generator_return_incorrect', severity='high', description='Return type mismatch', suggestion='Fix return type', line_number=10, confidence=1.0, details={})

        def test_fix_generator_return(
            self,
            generator: Any,
            mock_function: Mock,
            mock_docstring: Mock,
            mock_issue: InconsistencyIssue,
        ) -> None:
            """Test fixing generator return documentation."""
            mock_function.source_code = """
    def test_function() -> None:
        for i in range(10):
            yield i
    """
            mock_issue.issue_type = "generator_return_incorrect"

            context = SuggestionContext(
                function=mock_function, docstring=mock_docstring, issue=mock_issue
            )

>           suggestion = generator._fix_generator_return(context)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_return_generator.py:250:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\return_generator.py:291: in _fix_generator_return
    updated_docstring = self._update_return_type_in_docstring(
codedocsync\suggestions\generators\return_generator.py:346: in _update_return_type_in_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AB52D70>
docstring = <Mock id='2231416577328'>

    def _detect_style(self, docstring: Any) -> str:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Return the string format directly
>           return str(docstring.format.value)
                       ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\return_generator.py:483: AttributeError
____ TestReturnSuggestionGenerator.test_determine_best_return_type_single _____

self = <tests.suggestions.generators.test_return_generator.TestReturnSuggestionGenerator object at 0x000002078A7CF0B0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AB52C40>

    def test_determine_best_return_type_single(self, generator: Any) -> None:
        """Test determining best return type with single type."""
        analysis = ReturnAnalysisResult()
        analysis.return_types = {"str"}
        analysis.is_generator = False
        analysis.has_implicit_none = False

        mock_function: Mock = Mock()
        mock_function.signature.return_annotation = None

        result = generator._determine_best_return_type(analysis, mock_function)
>       assert result == "str"
E       AssertionError: assert 'None' == 'str'
E
E         - str
E         + None

tests\suggestions\generators\test_return_generator.py:267: AssertionError
___ TestReturnSuggestionGenerator.test_determine_best_return_type_multiple ____

self = <tests.suggestions.generators.test_return_generator.TestReturnSuggestionGenerator object at 0x000002078A7FC050>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ABE39B0>

    def test_determine_best_return_type_multiple(self, generator: Any) -> None:
        """Test determining best return type with multiple types."""
        analysis = ReturnAnalysisResult()
        analysis.return_types = {"str", "int"}
        analysis.is_generator = False
        analysis.has_implicit_none = False

        mock_function: Mock = Mock()
        mock_function.signature.return_annotation = None

        result = generator._determine_best_return_type(analysis, mock_function)
>       assert "Union" in result
E       AssertionError: assert 'Union' in 'None'

tests\suggestions\generators\test_return_generator.py:280: AssertionError
_________ TestReturnSuggestionGenerator.test_no_source_code_fallback __________

self = <tests.suggestions.generators.test_return_generator.TestReturnSuggestionGenerator object at 0x000002078A71D7C0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ACB2450>
mock_function = <Mock id='2231416581360'>
mock_docstring = <Mock id='2231416583040'>
mock_issue = InconsistencyIssue(issue_type='return_type_mismatch', severity='high', description='Return type mismatch', suggestion='Fix return type', line_number=10, confidence=1.0, details={})

    def test_no_source_code_fallback(
        self,
        generator: Any,
        mock_function: Mock,
        mock_docstring: Mock,
        mock_issue: InconsistencyIssue,
    ) -> None:
        """Test fallback when source code is not available."""
        mock_function.source_code = ""

        context = SuggestionContext(
            function=mock_function, docstring=mock_docstring, issue=mock_issue
        )

>       suggestion = generator._fix_return_type(context)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_return_generator.py:335:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\return_generator.py:157: in _fix_return_type
    return self._create_fallback_suggestion(
codedocsync\suggestions\generators\return_generator.py:531: in _create_fallback_suggestion
    return self._create_suggestion(
codedocsync\suggestions\generators\return_generator.py:523: in _create_suggestion
    style=self._detect_style(context.docstring),
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078ACB2450>
docstring = <Mock id='2231416583040'>

    def _detect_style(self, docstring: Any) -> str:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Return the string format directly
>           return str(docstring.format.value)
                       ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\return_generator.py:483: AttributeError
____________ TestReturnSuggestionGenerator.test_unknown_issue_type ____________

self = <tests.suggestions.generators.test_return_generator.TestReturnSuggestionGenerator object at 0x000002078A71D9A0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AEA95E0>
mock_function = <Mock id='2231416574640'>
mock_docstring = <Mock id='2231416578672'>

    def test_unknown_issue_type(
        self, generator: Any, mock_function: Mock, mock_docstring: Mock
    ) -> None:
        """Test handling unknown issue types."""
>       unknown_issue = InconsistencyIssue(
            issue_type="unknown_return_issue",
            severity="medium",
            description="Unknown issue",
            suggestion="",
            line_number=10,
        )

tests\suggestions\generators\test_return_generator.py:344:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='unknown_return_issue', severity='medium', description='Unknown issue', suggestion='', line_number=10, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'unknown_return_issue'

codedocsync\analyzer\models.py:63: ValueError
____ TestReturnGeneratorIntegration.test_complete_workflow_missing_returns ____

self = <tests.suggestions.generators.test_return_generator.TestReturnGeneratorIntegration object at 0x000002078A743B10>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AEA85F0>

        def test_complete_workflow_missing_returns(self, generator: Any) -> None:
            """Test complete workflow for missing returns."""
            # Create realistic function and docstring
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "calculate_sum"
            function.signature.return_annotation = "int"
            function.line_number = 5
            function.source_code = """
    def calculate_sum(a, b):
        return a + b
    """

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Calculate sum of two numbers"
            docstring.description = None
            docstring.parameters = []
            docstring.returns = None  # Missing returns
            docstring.raises = []
            docstring.examples = []
            docstring.raw_text = '"""Calculate sum of two numbers."""'

            issue = InconsistencyIssue(
                issue_type="missing_returns",
                severity="high",
                description="Missing return documentation",
                suggestion="Add return documentation",
                line_number=5,
            )

            context = SuggestionContext(function=function, docstring=docstring, issue=issue)

>           suggestion = generator.generate(context)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\generators\test_return_generator.py:409:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\generators\return_generator.py:141: in generate
    return self._add_missing_return_documentation(context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\return_generator.py:209: in _add_missing_return_documentation
    updated_docstring = self._add_return_to_docstring(context, suggested_type)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
codedocsync\suggestions\generators\return_generator.py:369: in _add_return_to_docstring
    style = self._detect_style(docstring)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AEA85F0>
docstring = <Mock id='2231416570608'>

    def _detect_style(self, docstring: Any) -> str:
        """Detect docstring style from parsed docstring."""
        if hasattr(docstring, "format"):
            # Return the string format directly
>           return str(docstring.format.value)
                       ^^^^^^^^^^^^^^^^^^^^^^
E           AttributeError: 'str' object has no attribute 'value'

codedocsync\suggestions\generators\return_generator.py:483: AttributeError
__ TestReturnGeneratorIntegration.test_complete_workflow_generator_function ___

self = <tests.suggestions.generators.test_return_generator.TestReturnGeneratorIntegration object at 0x000002078A743C50>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AEDC3D0>

        def test_complete_workflow_generator_function(self, generator: Any) -> None:
            """Test complete workflow for generator function."""
            function: Mock = Mock()
            function.signature = Mock()
            function.signature.name = "number_generator"
            function.signature.return_annotation = None
            function.line_number = 8
            function.source_code = """
    def number_generator(n):
        for i in range(n):
            yield i * 2
    """

            docstring: Mock = Mock()
            docstring.format = "google"
            docstring.summary = "Generate numbers"
            docstring.returns = DocstringReturns(
                type_str="list", description="List of numbers"
            )  # Wrong for generator
            docstring.parameters = []
            docstring.raises = []
            docstring.examples = []
            docstring.raw_text = '"""Generate numbers."""'

>           issue = InconsistencyIssue(
                issue_type="generator_return_incorrect",
                severity="high",
                description="Generator return type incorrect",
                suggestion="Fix generator return",
                line_number=8,
            )

tests\suggestions\generators\test_return_generator.py:447:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='generator_return_incorrect', severity='high', description='Generator return type incorrect', suggestion='Fix generator return', line_number=8, confidence=1.0, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'generator_return_incorrect'

codedocsync\analyzer\models.py:63: ValueError
____________ TestGoogleStyleTemplate.test_render_parameters_simple ____________

self = <test_google_template.TestGoogleStyleTemplate object at 0x000002078A743ED0>
template = <codedocsync.suggestions.templates.google_template.GoogleStyleTemplate object at 0x000002078AEF5160>

    def test_render_parameters_simple(self, template: Any) -> None:
        """Test rendering simple parameters."""
        parameters = [
            DocstringParameter(
                name="param1", type_str="str", description="First parameter"
            ),
            DocstringParameter(
                name="param2",
                type_str="int",
                description="Second parameter",
                is_optional=True,
            ),
        ]

        result = template.render_parameters(parameters)

        assert result[0] == "Args:"
        assert "    param1 (str): First parameter" in result
>       assert "    param2 (int, optional): Second parameter" in result
E       AssertionError: assert '    param2 (int, optional): Second parameter' in ['Args:', '    param1 (str): First parameter', '    param2 (int): Second parameter']

tests\suggestions\templates\test_google_template.py:41: AssertionError
______________ TestGoogleStyleTemplate.test_match_parameter_line ______________

self = <test_google_template.TestGoogleStyleTemplate object at 0x000002078A76A5B0>
template = <codedocsync.suggestions.templates.google_template.GoogleStyleTemplate object at 0x000002078AEDECF0>

    def test_match_parameter_line(self, template: Any) -> None:
        """Test matching parameter lines to extract names."""
        test_cases = [
            ("    param_name (str): Description", "param_name"),
            ("    param: Description", "param"),
            ("    *args: Variable arguments", "*args"),
            ("    **kwargs: Keyword arguments", "**kwargs"),
            ("    Regular line without parameter", None),
        ]

        for line, expected in test_cases:
            result = template._match_parameter_line(line)
>           assert result == expected
E           AssertionError: assert None == '**kwargs'

tests\suggestions\templates\test_google_template.py:189: AssertionError
___________ TestGoogleStyleTemplate.test_extract_section_boundaries ___________

self = <test_google_template.TestGoogleStyleTemplate object at 0x000002078A6B37D0>
template = <codedocsync.suggestions.templates.google_template.GoogleStyleTemplate object at 0x000002078AF33110>

    def test_extract_section_boundaries(self, template: Any) -> None:
        """Test extracting section boundaries from docstring."""
        docstring_lines = [
            '"""Function docstring.',
            "",
            "Args:",
            "    param1: First parameter",
            "    param2: Second parameter",
            "",
            "Returns:",
            "    Success status",
            "",
            "Raises:",
            "    ValueError: Invalid input",
            '"""',
        ]

        boundaries = template.extract_section_boundaries(docstring_lines)

        assert "parameters" in boundaries
        assert "returns" in boundaries
        assert "raises" in boundaries

        # Check parameter section boundaries
        params_start, params_end = boundaries["parameters"]
        assert params_start == 2  # "Args:" line
>       assert params_end == 4  # Last parameter line
        ^^^^^^^^^^^^^^^^^^^^^^
E       assert 5 == 4

tests\suggestions\templates\test_google_template.py:217: AssertionError
_________ TestGoogleStyleTemplate.test_template_with_max_line_length __________

self = <test_google_template.TestGoogleStyleTemplate object at 0x000002078A7754F0>

    def test_template_with_max_line_length(self) -> None:
        """Test template respects max line length setting."""
        template = GoogleStyleTemplate(max_line_length=50)

        parameters = [
            DocstringParameter(
                name="param",
                type_str="str",
                description="This is a very long description that should be wrapped",
            )
        ]

        result = template.render_parameters(parameters)

        # Check that lines don't exceed max length (accounting for indentation)
        for line in result:
>           assert len(line) <= 50 or line.strip() == ""
E           AssertionError: assert (71 <= 50 or 'param (str):...ld be wrapped' == ''
E            +  where 71 = len('    param (str): This is a very long description that should be wrapped')
E
E             + param (str): This is a very long description that should be wrapped)

tests\suggestions\templates\test_google_template.py:266: AssertionError
____________ TestTemplateRegistry.test_invalid_style_raises_error _____________

self = <test_google_template.TestTemplateRegistry object at 0x000002078A7B1BA0>

    def test_invalid_style_raises_error(self) -> None:
        """Test that invalid style raises error."""
        from codedocsync.suggestions.templates import DocstringStyle, template_registry

>       with pytest.raises(ValueError):
             ^^^^^^^^^^^^^^^^^^^^^^^^^
E       Failed: DID NOT RAISE <class 'ValueError'>

tests\suggestions\templates\test_google_template.py:291: Failed
__________ TestTemplateIntegration.test_realistic_function_docstring __________

self = <test_google_template.TestTemplateIntegration object at 0x000002078A814410>

    def test_realistic_function_docstring(self) -> None:
        """Test generating realistic function docstring."""
        template = GoogleStyleTemplate()

        parameters = [
            DocstringParameter(
                name="data",
                type_str="List[Dict[str, Any]]",
                description="Input data to process",
            ),
            DocstringParameter(
                name="config",
                type_str="Optional[Config]",
                description="Configuration object",
                is_optional=True,
                default_value="None",
            ),
            DocstringParameter(
                name="verbose",
                type_str="bool",
                description="Enable verbose output",
                is_optional=True,
                default_value="False",
            ),
        ]

        returns = DocstringReturns(
            type_str="ProcessedData",
            description="Processed data object with validation results",
        )

        raises = [
            DocstringRaises(
                exception_type="ValidationError",
                description="When input data fails validation",
            ),
            DocstringRaises(
                exception_type="ConfigurationError",
                description="When configuration is invalid",
            ),
        ]

        result = template.render_complete_docstring(
            summary="Process input data with optional configuration.",
            description="This function validates and processes input data according to the provided configuration. It supports various input formats and provides detailed error reporting.",
            parameters=parameters,
            returns=returns,
            raises=raises,
        )

        # Verify structure and content
        assert '"""' in result
        assert "Process input data with optional configuration." in result
        assert "Args:" in result
        assert "data (List[Dict[str, Any]]): Input data to process" in result
>       assert "config (Optional[Config], optional): Configuration object" in result
E       assert 'config (Optional[Config], optional): Configuration object' in '"""\nProcess input data with optional configuration.\n\nThis function validates and processes input data according to the provided\nconfiguration. It supports various input formats and provides detailed error reporting.\n\nArgs:\n    data (List[Dict[str, Any]]): Input data to process\n    config (Config, optional): Configuration object\n    verbose (bool): Enable verbose output\n\nReturns:\n    ProcessedData: Processed data object with validation results\n\nRaises:\n    ValidationError: When input data fails validation\n    ConfigurationError: When configuration is invalid\n"""'

tests\suggestions\templates\test_google_template.py:353: AssertionError
___________ TestNumpyStyleTemplate.test_render_raises_without_type ____________

self = <test_numpy_template.TestNumpyStyleTemplate object at 0x000002078A76AC30>
template = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000002078ADFF040>

    def test_render_raises_without_type(self, template: Any) -> None:
        """Test rendering raises without exception type."""
        raises = [
            DocstringRaises(
                exception_type="Exception",
                description="If something goes wrong",
            )
        ]

        result = template.render_raises(raises)

        # Should use generic "Exception"
        assert "Exception" in result
>       assert "If something goes wrong" in result
E       AssertionError: assert 'If something goes wrong' in ['Raises', '------', 'Exception', '    If something goes wrong']

tests\suggestions\templates\test_numpy_template.py:259: AssertionError
______________ TestNumpyStyleTemplate.test_match_parameter_line _______________

self = <test_numpy_template.TestNumpyStyleTemplate object at 0x000002078A832A30>
template = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000002078AEA6C10>

    def test_match_parameter_line(self, template: Any) -> None:
        """Test parameter line matching."""
        # Valid parameter lines
        assert template._match_parameter_line("param_name : str") == "param_name"
        assert template._match_parameter_line("param") == "param"
        assert template._match_parameter_line("param_name : List[str]") == "param_name"

        # Invalid lines
>       assert template._match_parameter_line("    description") is None
E       AssertionError: assert 'description' is None
E        +  where 'description' = _match_parameter_line('    description')
E        +    where _match_parameter_line = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000002078AEA6C10>._match_parameter_line

tests\suggestions\templates\test_numpy_template.py:315: AssertionError
_______ TestNumpyStyleTemplate.test_format_type_annotation_array_types ________

self = <test_numpy_template.TestNumpyStyleTemplate object at 0x000002078A840CD0>
template = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000002078AD166D0>

    def test_format_type_annotation_array_types(self, template: Any) -> None:
        """Test formatting array types for NumPy style."""
        # NumPy arrays should become array_like
        assert template._format_type_annotation("np.ndarray") == "array_like"
        assert template._format_type_annotation("ndarray") == "array_like"

        # Lists should become list of type
        assert template._format_type_annotation("List[str]") == "list of str"
        assert template._format_type_annotation("List[int]") == "list of int"

        # Dicts should become dict of type
>       assert template._format_type_annotation("Dict[str, Any]") == "dict of Any"
E       AssertionError: assert 'dict of str, Any' == 'dict of Any'
E
E         - dict of Any
E         + dict of str, Any
E         ?        +++++

tests\suggestions\templates\test_numpy_template.py:366: AssertionError
_______________ TestNumpyStyleTemplate.test_long_line_wrapping ________________

self = <test_numpy_template.TestNumpyStyleTemplate object at 0x000002078A7F3380>
template = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000002078AEF65F0>

    def test_long_line_wrapping(self, template: Any) -> None:
        """Test that long lines are properly wrapped."""
        template.max_line_length = 50  # Short line for testing

        params = [
            DocstringParameter(
                name="very_long_parameter_name_that_exceeds_limit",
                type_str="Dict[str, List[Tuple[int, str]]]",
                description="This is an extremely long description that definitely exceeds the maximum line length and should be wrapped properly across multiple lines",
                is_optional=False,
            )
        ]

        result = template.render_parameters(params)

        # Check that no line exceeds the limit (accounting for indentation)
        for line in result:
>           assert len(line) <= template.max_line_length or line.strip() == ""
E           AssertionError: assert (81 <= 50 or 'very_long_pa...uple[int, str' == ''
E            +  where 81 = len('very_long_parameter_name_that_exceeds_limit : dict of str, list of Tuple[int, str')
E            +  and   50 = <codedocsync.suggestions.templates.numpy_template.NumpyStyleTemplate object at 0x000002078AEF65F0>.max_line_length
E
E             + very_long_parameter_name_that_exceeds_limit : dict of str, list of Tuple[int, str)

tests\suggestions\templates\test_numpy_template.py:413: AssertionError
________________ TestSphinxStyleTemplate.test_render_examples _________________

self = <test_sphinx_template.TestSphinxStyleTemplate object at 0x000002078A860200>
template = <codedocsync.suggestions.templates.sphinx_template.SphinxStyleTemplate object at 0x000002078AFC82D0>

    def test_render_examples(self, template: Any) -> None:
        """Test rendering examples."""
        examples = [
            "from mymodule import process\nresult = process(data)",
            "with open('file.txt') as f:\n    content = process(f.read())",
        ]

        result = template._render_examples(examples)

        # Should use Sphinx rubric and code-block directives
        assert ".. rubric:: Examples" in result
        assert ".. code-block:: python" in result
>       assert "from mymodule import process" in result
E       AssertionError: assert 'from mymodule import process' in ['.. rubric:: Examples', '', '.. code-block:: python', '', '   from mymodule import process', '   result = process(data)', ...]

tests\suggestions\templates\test_sphinx_template.py:339: AssertionError
__________ TestSphinxTemplateEdgeCases.test_unicode_in_sphinx_fields __________

self = <test_sphinx_template.TestSphinxTemplateEdgeCases object at 0x000002078A83F890>
template = <codedocsync.suggestions.templates.sphinx_template.SphinxStyleTemplate object at 0x000002078AF3BBF0>

    def test_unicode_in_sphinx_fields(self, template: Any) -> None:
        """Test handling of Unicode characters in Sphinx fields."""
        params = [
>           DocstringParameter(
                name="\u03b1lpha",  # Unicode parameter name
                type_str="str",
                description="Parameter with \xe9mojis \U0001f680 and symbols \u03b1 \u03b2 \u03b3",
                is_optional=False,
            )
        ]

tests\suggestions\templates\test_sphinx_template.py:510:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:8: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = DocstringParameter(name='\u03b1lpha', type_str='str', description='Parameter with \xe9mojis \U0001f680 and symbols \u03b1 \u03b2 \u03b3', is_optional=False, default_value=None)

    def __post_init__(self) -> None:
        """Validate parameter name."""
        # Validate parameter name
        if not re.match(r"^[a-zA-Z_][a-zA-Z0-9_]*$", self.name):
            # Allow *args and **kwargs
            if not re.match(r"^(\*{1,2})?[a-zA-Z_][a-zA-Z0-9_]*$", self.name):
>               raise ValueError(f"Invalid parameter name: {self.name}")
E               ValueError: Invalid parameter name: \u03b1lpha

codedocsync\parser\docstring_models.py:38: ValueError
___________ TestSphinxTemplateEdgeCases.test_very_long_field_names ____________

self = <test_sphinx_template.TestSphinxTemplateEdgeCases object at 0x000002078A7FD590>
template = <codedocsync.suggestions.templates.sphinx_template.SphinxStyleTemplate object at 0x000002078AF39430>

    def test_very_long_field_names(self, template: Any) -> None:
        """Test field names that might cause formatting issues."""
        template.max_line_length = 60

        params = [
            DocstringParameter(
                name="parameter_with_extremely_long_name_that_exceeds_normal_limits",
                type_str="str",
                description="Short desc",
                is_optional=False,
            )
        ]

>       result = template.render_parameters(params)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\templates\test_sphinx_template.py:539:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
codedocsync\suggestions\templates\sphinx_template.py:49: in render_parameters
    wrapped_lines = self._wrap_sphinx_field(param_line, ":param")
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <codedocsync.suggestions.templates.sphinx_template.SphinxStyleTemplate object at 0x000002078AF39430>
field_line = ':param parameter_with_extremely_long_name_that_exceeds_normal_limits: Short desc'
field_prefix = ':param'

    def _wrap_sphinx_field(self, field_line: str, field_prefix: str) -> list[str]:
        """Wrap Sphinx field line with proper continuation indentation."""
        if len(field_line) <= self.max_line_length:
            return [field_line]

        # Find the description part after the field prefix
        colon_pos = field_line.find(": ", len(field_prefix))
        if colon_pos == -1:
            return [field_line]

        field_part = field_line[: colon_pos + 2]
        description_part = field_line[colon_pos + 2 :]

        # Calculate continuation indent (align with description start)
        continuation_indent = " " * len(field_part)

        # Wrap the description part
        available_width = self.max_line_length - len(field_part)

        if len(description_part) <= available_width:
            return [field_line]

        # Split description and wrap
        lines = [field_part + description_part[:available_width]]
        remaining = description_part[available_width:]

        while remaining:
            chunk_size = self.max_line_length - len(continuation_indent)
            if len(remaining) <= chunk_size:
                lines.append(continuation_indent + remaining)
                break
            else:
                # Find a good break point
                chunk = remaining[:chunk_size]
                last_space = chunk.rfind(" ")
                if last_space > chunk_size * 0.7:  # If space is reasonably close to end
>                   lines.append(continuation_indent + remaining[:last_space])
E                   MemoryError

codedocsync\suggestions\templates\sphinx_template.py:153: MemoryError
_______ TestConfigIntegration.test_config_with_yaml_file_and_overrides ________

self = <tests.suggestions.test_config.TestConfigIntegration object at 0x000002078A817110>

    def test_config_with_yaml_file_and_overrides(self) -> None:
        """Test loading config from YAML with user overrides."""
        yaml_content = """
        suggestions:
          default_style: numpy
          max_line_length: 100
          confidence_threshold: 0.8
        """

        with tempfile.NamedTemporaryFile(mode="w", suffix=".yml", delete=False) as f:
            f.write(yaml_content)
            temp_path = Path(f.name)

        try:
            manager = ConfigManager()

            user_overrides = {
                "confidence_threshold": 0.9,  # Override YAML value
                "include_examples": True,  # New value
            }

            config = manager.load_config(
                config_path=temp_path,
                user_config=user_overrides,
            )

            # Should have YAML values
>           assert config.default_style == "numpy"
E           AssertionError: assert 'google' == 'numpy'
E
E             - numpy
E             + google

tests\suggestions\test_config.py:576: AssertionError
_____________ TestSpecialCases.test_convert_with_unicode_content ______________

self = <tests.suggestions.test_converter.TestSpecialCases object at 0x000002078A817ED0>
converter = <codedocsync.suggestions.converter.DocstringStyleConverter object at 0x000002078AE37140>

    def test_convert_with_unicode_content(self, converter: Any) -> None:
        """Test conversion with Unicode content."""
        unicode_docstring = ParsedDocstring(
            summary="Funci\xf3n con caracteres especiales \U0001f680.",
            description="Procesa datos con s\xedmbolos \u03b1, \u03b2, \u03b3.",
            parameters=[
>               DocstringParameter(
                    name="donnes",  # French
                    type_str="str",
                    description="Donn\xe9es d'entr\xe9e avec \xe9mojis \U0001f4ca",
                    is_optional=False,
                )
            ],
            returns=None,
            raises=[],
            raw_text="",
            format=DocstringFormat.GOOGLE,
        )

tests\suggestions\test_converter.py:574:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:8: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = DocstringParameter(name='donn\xe9es', type_str='str', description="Donn\xe9es d'entr\xe9e avec \xe9mojis \U0001f4ca", is_optional=False, default_value=None)

    def __post_init__(self) -> None:
        """Validate parameter name."""
        # Validate parameter name
        if not re.match(r"^[a-zA-Z_][a-zA-Z0-9_]*$", self.name):
            # Allow *args and **kwargs
            if not re.match(r"^(\*{1,2})?[a-zA-Z_][a-zA-Z0-9_]*$", self.name):
>               raise ValueError(f"Invalid parameter name: {self.name}")
E               ValueError: Invalid parameter name: donnes

codedocsync\parser\docstring_models.py:38: ValueError
____________ TestFullPipeline.test_parse_analyze_suggest_workflow _____________

self = <tests.suggestions.test_e2e_integration.TestFullPipeline object at 0x000002078AA5CCD0>

    def test_parse_analyze_suggest_workflow(self) -> None:
        """Test full workflow from parsing to suggestion generation."""
        # Step 1: Create test function
        function = create_test_function(
            name="calculate_total",
            params=["items", "tax_rate"],
            return_type="float",
            docstring="""Calculate total with tax.

            Args:
                items: List of items
                rate: Tax rate

            Returns:
                Total amount
            """,
        )

        # Step 2: Create matched pair
        pair = MatchedPair(
            function=function,
            docstring=create_parsed_docstring(
                summary="Calculate total with tax.",
                params={
                    "items": "List of items",
                    "rate": "Tax rate",
                },
                returns="Total amount",
            ),
            confidence=MatchConfidence(
                overall=0.9,
                name_similarity=1.0,
                location_score=1.0,
                signature_similarity=0.7,
            ),
            match_type=MatchType.EXACT,
            match_reason="Same file documentation",
        )

        # Step 3: Create analysis result with issues
        issues = [
            create_test_issue(
                issue_type="parameter_name_mismatch",
                description="Parameter 'rate' doesn't match 'tax_rate' in code",
            ),
            create_test_issue(
                issue_type="return_type_mismatch",
                description="Return type not documented",
                severity="medium",
            ),
        ]

        analysis_result = AnalysisResult(
            matched_pair=pair,
            issues=issues,
            used_llm=False,
            analysis_time_ms=15.3,
        )

        # Step 4: Generate suggestions
        config = SuggestionConfig(default_style="google")
        enhanced_result = enhance_with_suggestions(analysis_result, config)

        # Verify complete pipeline
        assert enhanced_result is not None
        assert len(enhanced_result.issues) == 2

        # Check parameter mismatch suggestion
        param_issue = enhanced_result.issues[0]
>       assert param_issue.rich_suggestion is not None
E       assert None is not None
E        +  where None = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description="Parameter 'rate' doesn't match 'tax_rate' in code", suggestion='Fix parameter_name_mismatch', line_number=10, confidence=0.95, details={}, rich_suggestion=None, formatted_output=None, ranking_score=None).rich_suggestion

tests\suggestions\test_e2e_integration.py:113: AssertionError
------------------------------ Captured log call ------------------------------
WARNING  codedocsync.suggestions.integration:integration.py:227 Generator failed for parameter_name_mismatch: 'DocstringParameter' object has no attribute 'type_annotation'
___________________ TestFullPipeline.test_batch_processing ____________________

self = <tests.suggestions.test_e2e_integration.TestFullPipeline object at 0x000002078AA5CB90>

    def test_batch_processing(self) -> None:
        """Test processing multiple functions in batch."""
        # Create multiple test scenarios
        test_cases: list[dict[str, Any]] = [
            {
                "name": "func1",
                "params": ["x", "y"],
                "issue": "parameter_missing",
                "missing": "y",
            },
            {
                "name": "func2",
                "params": ["data"],
                "issue": "missing_returns",
                "return_type": "Dict[str, Any]",
            },
            {
                "name": "func3",
                "params": ["value"],
                "issue": "missing_raises",
                "exceptions": ["ValueError"],
            },
        ]

        results = []
        for case in test_cases:
            function = create_test_function(
                name=case["name"],
                params=case["params"],
                return_type=case.get("return_type"),
            )

            issue = create_test_issue(
                issue_type=case["issue"],
            )

            pair = MatchedPair(
                function=function,
                docstring=None,
                confidence=MatchConfidence(
                    overall=0.9,
                    name_similarity=1.0,
                    location_score=1.0,
                    signature_similarity=0.9,
                ),
                match_type=MatchType.EXACT,
                match_reason="Test",
            )

            result = AnalysisResult(
                matched_pair=pair,
                issues=[issue],
                used_llm=False,
                analysis_time_ms=10.0,
            )

            results.append(result)

        # Process batch
        config = SuggestionConfig()

        enhanced_results = enhance_multiple_with_suggestions(results, config)

        # Verify batch results
        assert len(enhanced_results) == 3
        enhanced_result: EnhancedAnalysisResult
        for enhanced_result in enhanced_results:
            assert len(enhanced_result.issues) > 0
>           assert enhanced_result.issues[0].rich_suggestion is not None
E           AssertionError: assert None is not None
E            +  where None = EnhancedIssue(issue_type='parameter_missing', severity='critical', description='Test issue of type parameter_missing', suggestion='Fix parameter_missing', line_number=10, confidence=0.95, details={}, rich_suggestion=None, formatted_output=None, ranking_score=None).rich_suggestion

tests\suggestions\test_e2e_integration.py:190: AssertionError
------------------------------ Captured log call ------------------------------
WARNING  codedocsync.suggestions.integration:integration.py:227 Generator failed for parameter_missing: original_text cannot be empty
WARNING  codedocsync.suggestions.integration:integration.py:227 Generator failed for missing_returns: original_text cannot be empty
WARNING  codedocsync.suggestions.integration:integration.py:227 Generator failed for missing_raises: original_text cannot be empty
______________ TestCLIIntegration.test_suggest_command_with_file ______________

self = <tests.suggestions.test_e2e_integration.TestCLIIntegration object at 0x000002078AA5CF50>
tmp_path = WindowsPath('C:/Users/issak/AppData/Local/Temp/pytest-of-issak/pytest-50/test_suggest_command_with_file0')

        def test_suggest_command_with_file(self, tmp_path: Path) -> None:
            """Test suggest command with a Python file."""
            # Create test file
            test_file = tmp_path / "test.py"
            test_file.write_text(
                '''
    def process_data(items, threshold=0.5):
        """Process data items.

        Args:
            items: List of items
            limit: Threshold value

        Returns:
            Processed items
        """
        return [item for item in items if item > threshold]
    '''
            )

            # Mock the analysis pipeline
>           with patch("codedocsync.main.UnifiedMatchingFacade") as mock_facade:
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_e2e_integration.py:226:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python313\Lib\unittest\mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000002078AE0F230>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'codedocsync.main' from 'C:\\Users\\issak\\CodeDocSync\\codedocsync\\main.py'> does not have the attribute 'UnifiedMatchingFacade'

C:\Python313\Lib\unittest\mock.py:1467: AttributeError
_______________ TestCLIIntegration.test_suggest_command_dry_run _______________

self = <tests.suggestions.test_e2e_integration.TestCLIIntegration object at 0x000002078AA34FC0>
tmp_path = WindowsPath('C:/Users/issak/AppData/Local/Temp/pytest-of-issak/pytest-50/test_suggest_command_dry_run0')

    def test_suggest_command_dry_run(self, tmp_path: Path) -> None:
        """Test suggest command with dry-run option."""
        test_file = tmp_path / "test.py"
        test_file.write_text("def test(): pass")

>       with patch("codedocsync.main.UnifiedMatchingFacade"):
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_e2e_integration.py:280:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Python313\Lib\unittest\mock.py:1497: in __enter__
    original, local = self.get_original()
                      ^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x000002078AE0C130>

    def get_original(self):
        target = self.getter()
        name = self.attribute

        original = DEFAULT
        local = False

        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True

        if name in _builtins and isinstance(target, ModuleType):
            self.create = True

        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'codedocsync.main' from 'C:\\Users\\issak\\CodeDocSync\\codedocsync\\main.py'> does not have the attribute 'UnifiedMatchingFacade'

C:\Python313\Lib\unittest\mock.py:1467: AttributeError
_________ TestPerformanceMonitoring.test_performance_recommendations __________

self = <tests.suggestions.test_e2e_integration.TestPerformanceMonitoring object at 0x000002078AA5D1D0>

    def test_performance_recommendations(self) -> None:
        """Test performance optimization recommendations."""
        monitor = get_performance_monitor()
        monitor.reset()

        # Simulate slow operations
        import time

        for _i in range(5):
            with monitor.measure("slow_operation"):
                time.sleep(0.1)  # Simulate slow operation

        recommendations = monitor.get_recommendations()
>       assert len(recommendations) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests\suggestions\test_e2e_integration.py:331: AssertionError
___________ TestProductionScenarios.test_large_codebase_simulation ____________

self = <tests.suggestions.test_e2e_integration.TestProductionScenarios object at 0x000002078AA5D590>

    def test_large_codebase_simulation(self) -> None:
        """Test handling of large codebase with many functions."""
        # Simulate 100 functions with various issues
        num_functions = 100
        results = []

        issue_types = [
            "parameter_name_mismatch",
            "parameter_missing",
            "return_type_mismatch",
            "missing_raises",
            "description_vague",
        ]

        for i in range(num_functions):
            function = create_test_function(
                name=f"function_{i}",
                params=[f"param_{j}" for j in range(i % 5 + 1)],
            )

>           issue = create_test_issue(
                issue_type=issue_types[i % len(issue_types)],
                severity=["critical", "high", "medium", "low"][i % 4],
            )

tests\suggestions\test_e2e_integration.py:419:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='critical', description='Test issue of type description_vague', suggestion='Fix description_vague', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
____ TestParameterSuggestionGenerator.test_parameter_name_mismatch_simple _____

self = <tests.suggestions.test_generators.TestParameterSuggestionGenerator object at 0x000002078AA5D950>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AF4AB70>

    def test_parameter_name_mismatch_simple(self, generator: Any) -> None:
        """Test fixing simple parameter name mismatch."""
        # Create function with mismatched parameter
        function = create_test_function(
            name="authenticate_user",
            params=["username", "password"],
            docstring=DOCSTRING_EXAMPLES["google_simple"],
        )

        # Create issue
        issue = create_test_issue(
            issue_type="parameter_name_mismatch",
            description="Parameter 'email' doesn't match 'username' in code",
            details={"expected": "username", "found": "email"},
        )

        # Create context
        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                summary="Simple function description.",
                params={"email": "First parameter", "password": "Second parameter"},
            ),
            project_style="google",
        )

        # Generate suggestion
        suggestion = generator.generate(context)

        # Verify suggestion
        assert suggestion.suggestion_type == SuggestionType.PARAMETER_UPDATE
>       assert "username" in suggestion.suggested_text
E       AssertionError: assert 'username' in 'Simple function description.\n\nArgs:\n    email: First parameter\n    password: Second parameter'
E        +  where 'Simple function description.\n\nArgs:\n    email: First parameter\n    password: Second parameter' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='Simple function description.\n\nArgs:\n    email: First parameter\n    password: Second parameter', suggested_text='Simple function description.\n\nArgs:\n    email: First parameter\n    password: Second parameter', confidence=0.1, diff=SuggestionDiff(original_lines=['Simple function description.', '', 'Args:', '    email: First parameter', '    password: Second parameter'], suggested_lines=['Simple function description.', '', 'Args:', '    email: First parameter', '    password: Second parameter'], start_line=10, end_line=15), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ParameterSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:72: AssertionError
___________ TestParameterSuggestionGenerator.test_parameter_missing ___________

self = <tests.suggestions.test_generators.TestParameterSuggestionGenerator object at 0x000002078AA5DA90>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AFF6990>

    def test_parameter_missing(self, generator: Any) -> None:
        """Test adding missing parameter documentation."""
        function = create_test_function(params=["username", "password", "remember_me"])

        issue = create_test_issue(
            issue_type="parameter_missing",
            description="Parameter 'remember_me' is not documented",
            details={"missing_param": "remember_me", "type_annotation": "bool"},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                params={"username": "User's username", "password": "User's password"}
            ),
            project_style="google",
        )

        suggestion = generator.generate(context)

        assert "remember_me" in suggestion.suggested_text
>       assert "bool" in suggestion.suggested_text
E       assert 'bool' in '"""\nTest function.\n\nArgs:\n    username (str): User\'s username\n    password (str): User\'s password\n    remember_me (int): Description for remember_me (int)\n"""'
E        +  where '"""\nTest function.\n\nArgs:\n    username (str): User\'s username\n    password (str): User\'s password\n    remember_me (int): Description for remember_me (int)\n"""' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text="Test function.\n\nArgs:\n    username: User's username\n    password: User's password", suggested_text='"""\nTest function.\n\nArgs:\n    username (str): User\'s username\n    password (str): User\'s password\n    remember_me (int): Description for remember_me (int)\n"""', confidence=0.9, diff=SuggestionDiff(original_lines=['Test function.', '', 'Args:', "    username: User's username", "    password: User's password"], suggested_lines=['"""', 'Test function.', '', 'Args:', "    username (str): User's username", "    password (str): User's password", '    remember_me (int): Description for remember_me (int)', '"""'], start_line=10, end_line=15), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ParameterSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:99: AssertionError
________ TestParameterSuggestionGenerator.test_parameter_type_mismatch ________

self = <tests.suggestions.test_generators.TestParameterSuggestionGenerator object at 0x000002078AA35350>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AFF7230>

    def test_parameter_type_mismatch(self, generator: Any) -> None:
        """Test fixing parameter type mismatch."""
        function = create_test_function(params=["count", "name"])

        issue = create_test_issue(
            issue_type="parameter_type_mismatch",
            description="Parameter 'count' type mismatch",
            details={
                "param_name": "count",
                "expected_type": "int",
                "documented_type": "str",
            },
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                params={"count": "Number of items", "name": "Item name"}
            ),
            project_style="google",
        )

        suggestion = generator.generate(context)

>       assert "count (int)" in suggestion.suggested_text
E       assert 'count (int)' in '"""\nTest function.\n\nArgs:\n    count (str): Number of items\n    name (int): Item name\n"""'
E        +  where '"""\nTest function.\n\nArgs:\n    count (str): Number of items\n    name (int): Item name\n"""' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='Test function.\n\nArgs:\n    count: Number of items\n    name: Item name', suggested_text='"""\nTest function.\n\nArgs:\n    count (str): Number of items\n    name (int): Item name\n"""', confidence=0.85, diff=SuggestionDiff(original_lines=['Test function.', '', 'Args:', '    count: Number of items', '    name: Item name'], suggested_lines=['"""', 'Test function.', '', 'Args:', '    count (str): Number of items', '    name (int): Item name', '"""'], start_line=10, end_line=15), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ParameterSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:127: AssertionError
________ TestParameterSuggestionGenerator.test_preserves_descriptions _________

self = <tests.suggestions.test_generators.TestParameterSuggestionGenerator object at 0x000002078AA35480>
generator = <codedocsync.suggestions.generators.parameter_generator.ParameterSuggestionGenerator object at 0x000002078AFF7650>

    def test_preserves_descriptions(self, generator: Any) -> None:
        """Test that existing descriptions are preserved."""
        function = create_test_function(params=["data", "config"])

        issue = create_test_issue(
            issue_type="parameter_name_mismatch",
            details={"expected": "config", "found": "settings"},
        )

        detailed_desc = (
            "Configuration object with multiple settings\n"
            "        that control the behavior of the function.\n"
            "        Can be None for default settings."
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                params={"data": "Input data to process", "settings": detailed_desc}
            ),
            project_style="google",
        )

        suggestion = generator.generate(context)

        # Should preserve the detailed description
        assert (
            "Configuration object with multiple settings" in suggestion.suggested_text
        )
>       assert "config" in suggestion.suggested_text
E       AssertionError: assert 'config' in 'Test function.\n\nArgs:\n    data: Input data to process\n    settings: Configuration object with multiple settings\n        that control the behavior of the function.\n        Can be None for default settings.'
E        +  where 'Test function.\n\nArgs:\n    data: Input data to process\n    settings: Configuration object with multiple settings\n        that control the behavior of the function.\n        Can be None for default settings.' = Suggestion(suggestion_type=<SuggestionType.PARAMETER_UPDATE: 'parameter_update'>, original_text='Test function.\n\nArgs:\n    data: Input data to process\n    settings: Configuration object with multiple settings\n        that control the behavior of the function.\n        Can be None for default settings.', suggested_text='Test function.\n\nArgs:\n    data: Input data to process\n    settings: Configuration object with multiple settings\n        that control the behavior of the function.\n        Can be None for default settings.', confidence=0.1, diff=SuggestionDiff(original_lines=['Test function.', '', 'Args:', '    data: Input data to process', '    settings: Configuration object with multiple settings', '        that control the behavior of the function.', '        Can be None for default settings.'], suggested_lines=['Test function.', '', 'Args:', '    data: Input data to process', '    settings: Configuration object with multiple settings', '        that control the behavior of the function.', '        Can be None for default settings.'], start_line=10, end_line=17), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ParameterSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:160: AssertionError
___________ TestReturnSuggestionGenerator.test_return_type_mismatch ___________

self = <tests.suggestions.test_generators.TestReturnSuggestionGenerator object at 0x000002078AA5DBD0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x00000209BC162F30>

    def test_return_type_mismatch(self, generator: Any) -> None:
        """Test fixing return type mismatch."""
        function = create_test_function(
            name="calculate_total",
            return_type="float",
            docstring="Calculate total.\n\nReturns:\n    int: The total",
        )

        issue = create_test_issue(
            issue_type="return_type_mismatch",
            description="Return type mismatch",
            details={"expected_type": "float", "documented_type": "int"},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(returns="The total"),
            project_style="google",
        )

        suggestion = generator.generate(context)

>       assert "float" in suggestion.suggested_text
E       assert 'float' in '"""\nTest function.\n\nReturns:\n    None: None\n"""'
E        +  where '"""\nTest function.\n\nReturns:\n    None: None\n"""' = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Test function.\n\nReturns:\n    The total', suggested_text='"""\nTest function.\n\nReturns:\n    None: None\n"""', confidence=0.85, diff=SuggestionDiff(original_lines=['Test function.', '', 'Returns:', '    The total'], suggested_lines=['"""', 'Test function.', '', 'Returns:', '    None: None', '"""'], start_line=10, end_line=14), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ReturnSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:196: AssertionError
_______ TestReturnSuggestionGenerator.test_missing_return_documentation _______

self = <tests.suggestions.test_generators.TestReturnSuggestionGenerator object at 0x000002078AA5DD10>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AF2CC30>

    def test_missing_return_documentation(self, generator: Any) -> None:
        """Test adding missing return documentation."""
        function = create_test_function(
            name="process_data", return_type="Dict[str, Any]"
        )

        issue = create_test_issue(
            issue_type="missing_returns",
            description="Missing return documentation",
            details={"return_type": "Dict[str, Any]"},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(summary="Process data."),
            project_style="google",
        )

        suggestion = generator.generate(context)

>       assert "Returns:" in suggestion.suggested_text
E       AssertionError: assert 'Returns:' in 'Process data.'
E        +  where 'Process data.' = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Process data.', suggested_text='Process data.', confidence=0.1, diff=SuggestionDiff(original_lines=['Process data.'], suggested_lines=['Process data.'], start_line=10, end_line=11), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ReturnSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:220: AssertionError
________ TestReturnSuggestionGenerator.test_generator_function_return _________

self = <tests.suggestions.test_generators.TestReturnSuggestionGenerator object at 0x000002078AA356E0>
generator = <codedocsync.suggestions.generators.return_generator.ReturnSuggestionGenerator object at 0x000002078AE37F50>

    def test_generator_function_return(self, generator: Any) -> None:
        """Test documenting generator functions."""
        function = create_test_function(
            name="iterate_items", return_type="Generator[int, None, None]"
        )

        issue = create_test_issue(
            issue_type="return_type_mismatch",
            details={"is_generator": True, "yield_type": "int"},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(returns="Items"),
            project_style="google",
        )

        suggestion = generator.generate(context)

>       assert (
            "Yields:" in suggestion.suggested_text
            or "Generator" in suggestion.suggested_text
        )
E       assert ('Yields:' in '"""\nTest function.\n\nReturns:\n    None: None\n"""' or 'Generator' in '"""\nTest function.\n\nReturns:\n    None: None\n"""')
E        +  where '"""\nTest function.\n\nReturns:\n    None: None\n"""' = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Test function.\n\nReturns:\n    Items', suggested_text='"""\nTest function.\n\nReturns:\n    None: None\n"""', confidence=0.85, diff=SuggestionDiff(original_lines=['Test function.', '', 'Returns:', '    Items'], suggested_lines=['"""', 'Test function.', '', 'Returns:', '    None: None', '"""'], start_line=10, end_line=14), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ReturnSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text
E        +  and   '"""\nTest function.\n\nReturns:\n    None: None\n"""' = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Test function.\n\nReturns:\n    Items', suggested_text='"""\nTest function.\n\nReturns:\n    None: None\n"""', confidence=0.85, diff=SuggestionDiff(original_lines=['Test function.', '', 'Returns:', '    Items'], suggested_lines=['"""', 'Test function.', '', 'Returns:', '    None: None', '"""'], start_line=10, end_line=14), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ReturnSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:243: AssertionError
_____ TestRaisesSuggestionGenerator.test_updates_existing_raises_section ______

self = <tests.suggestions.test_generators.TestRaisesSuggestionGenerator object at 0x000002078AA5DF90>
generator = <codedocsync.suggestions.generators.raises_generator.RaisesSuggestionGenerator object at 0x000002078A6B0890>

    def test_updates_existing_raises_section(self, generator: Any) -> None:
        """Test updating existing raises section."""
        function = create_test_function(name="process")

        issue = create_test_issue(
            issue_type="missing_raises",
            details={"missing_exceptions": [{"type": "RuntimeError"}]},
        )

        context = SuggestionContext(
            issue=issue,
            function=function,
            docstring=create_parsed_docstring(
                raises={"ValueError": "If value is invalid"}
            ),
            project_style="google",
        )

        suggestion = generator.generate(context)

        # Should preserve existing and add new
        assert "ValueError: If value is invalid" in suggestion.suggested_text
>       assert "RuntimeError" in suggestion.suggested_text
E       AssertionError: assert 'RuntimeError' in 'Test function.\n\nRaises:\n    ValueError: If value is invalid'
E        +  where 'Test function.\n\nRaises:\n    ValueError: If value is invalid' = Suggestion(suggestion_type=<SuggestionType.RAISES_UPDATE: 'raises_update'>, original_text='Test function.\n\nRaises:\n    ValueError: If value is invalid', suggested_text='Test function.\n\nRaises:\n    ValueError: If value is invalid', confidence=0.1, diff=SuggestionDiff(original_lines=['Test function.', '', 'Raises:', '    ValueError: If value is invalid'], suggested_lines=['Test function.', '', 'Raises:', '    ValueError: If value is invalid'], start_line=10, end_line=14), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='RaisesSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).suggested_text

tests\suggestions\test_generators.py:316: AssertionError
_______ TestBehaviorSuggestionGenerator.test_enhance_vague_description ________

self = <tests.suggestions.test_generators.TestBehaviorSuggestionGenerator object at 0x000002078AA5E0D0>
generator = <codedocsync.suggestions.generators.behavior_generator.BehaviorSuggestionGenerator object at 0x000002078ABEA8D0>

        def test_enhance_vague_description(self, generator: Any) -> None:
            """Test enhancing vague descriptions."""
            function = create_test_function(
                name="process_data",
                source_code="""def process_data(items):
        result = []
        for item in items:
            if item > 0:
                result.append(item * 2)
        return result
    """,
            )

>           issue = create_test_issue(
                issue_type="description_vague",
                description="Description is too vague",
                severity="medium",
            )

tests\suggestions\test_generators.py:341:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_vague', severity='medium', description='Description is too vague', suggestion='Fix description_vague', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_vague'

codedocsync\analyzer\models.py:63: ValueError
_________ TestBehaviorSuggestionGenerator.test_identify_side_effects __________

self = <tests.suggestions.test_generators.TestBehaviorSuggestionGenerator object at 0x000002078AA5E210>
generator = <codedocsync.suggestions.generators.behavior_generator.BehaviorSuggestionGenerator object at 0x000002078AF9B1D0>

        def test_identify_side_effects(self, generator: Any) -> None:
            """Test identifying and documenting side effects."""
            function = create_test_function(
                name="save_to_file",
                source_code="""def save_to_file(data, filename):
        with open(filename, 'w') as f:
            json.dump(data, f)
        logging.info(f"Saved data to {filename}")
    """,
            )

>           issue = create_test_issue(
                issue_type="description_incomplete", severity="medium"
            )

tests\suggestions\test_generators.py:371:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='description_incomplete', severity='medium', description='Test issue of type description_incomplete', suggestion='Fix description_incomplete', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'description_incomplete'

codedocsync\analyzer\models.py:63: ValueError
_________ TestExampleSuggestionGenerator.test_generate_basic_example __________

self = <tests.suggestions.test_generators.TestExampleSuggestionGenerator object at 0x000002078AA5E350>
generator = <codedocsync.suggestions.generators.example_generator.ExampleSuggestionGenerator object at 0x000002078AC835B0>

    def test_generate_basic_example(self, generator: Any) -> None:
        """Test generating basic usage example."""
        function = create_test_function(
            name="add_numbers", params=["a", "b"], return_type="int"
        )

>       issue = create_test_issue(
            issue_type="missing_examples",
            description="No usage examples provided",
            severity="low",
        )

tests\suggestions\test_generators.py:403:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='missing_examples', severity='low', description='No usage examples provided', suggestion='Fix missing_examples', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'missing_examples'

codedocsync\analyzer\models.py:63: ValueError
_____ TestEdgeCaseSuggestionGenerator.test_property_method_documentation ______

self = <tests.suggestions.test_generators.TestEdgeCaseSuggestionGenerator object at 0x000002078AA5E5D0>
generator = <codedocsync.suggestions.generators.edge_case_handlers.EdgeCaseSuggestionGenerator object at 0x000002078ABB6470>

    def test_property_method_documentation(self, generator: Any) -> None:
        """Test documenting property methods."""
        function = create_test_function(name="temperature")
        function.signature.decorators = ["property"]

>       issue = create_test_issue(
            issue_type="property_documentation",
            description="Property lacks proper documentation",
        )

tests\suggestions\test_generators.py:465:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='property_documentation', severity='critical', description='Property lacks proper documentation', suggestion='Fix property_documentation', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'property_documentation'

codedocsync\analyzer\models.py:63: ValueError
_______ TestEdgeCaseSuggestionGenerator.test_classmethod_documentation ________

self = <tests.suggestions.test_generators.TestEdgeCaseSuggestionGenerator object at 0x000002078AA5E710>
generator = <codedocsync.suggestions.generators.edge_case_handlers.EdgeCaseSuggestionGenerator object at 0x000002078AB19A50>

    def test_classmethod_documentation(self, generator: Any) -> None:
        """Test documenting class methods."""
        function = create_test_function(
            name="from_dict", params=["cls", "data"], return_type="MyClass"
        )
        function.signature.decorators = ["classmethod"]

>       issue = create_test_issue(
            issue_type="classmethod_documentation",
            description="Class method documentation includes 'cls' parameter",
        )

tests\suggestions\test_generators.py:492:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='classmethod_documentation', severity='critical', description="Class method documentation includes 'cls' parameter", suggestion='Fix classmethod_documentation', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'classmethod_documentation'

codedocsync\analyzer\models.py:63: ValueError
_______ TestEdgeCaseSuggestionGenerator.test_magic_method_documentation _______

self = <tests.suggestions.test_generators.TestEdgeCaseSuggestionGenerator object at 0x000002078AA35810>
generator = <codedocsync.suggestions.generators.edge_case_handlers.EdgeCaseSuggestionGenerator object at 0x000002078AB1AC50>

    def test_magic_method_documentation(self, generator: Any) -> None:
        """Test documenting magic methods."""
        function = create_test_function(
            name="__init__", params=["self", "name", "value"]
        )

>       issue = create_test_issue(
            issue_type="magic_method_documentation",
            description="Magic method needs appropriate documentation",
        )

tests\suggestions\test_generators.py:518:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\fixtures.py:152: in create_test_issue
    return InconsistencyIssue(
<string>:10: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = InconsistencyIssue(issue_type='magic_method_documentation', severity='critical', description='Magic method needs appropriate documentation', suggestion='Fix magic_method_documentation', line_number=10, confidence=0.95, details={})

    def __post_init__(self) -> None:
        """Validate issue fields."""
        # Validate issue_type
        if self.issue_type not in ISSUE_TYPES:
>           raise ValueError(
                f"issue_type must be one of {list(ISSUE_TYPES.keys())}, "
                f"got '{self.issue_type}'"
            )
E           ValueError: issue_type must be one of ['parameter_name_mismatch', 'parameter_missing', 'parameter_type_mismatch', 'return_type_mismatch', 'missing_raises', 'parameter_order_different', 'description_outdated', 'example_invalid', 'missing_params', 'missing_returns', 'undocumented_kwargs', 'type_mismatches', 'default_mismatches', 'parameter_count_mismatch'], got 'magic_method_documentation'

codedocsync\analyzer\models.py:63: ValueError
_________ TestGeneratorIntegration.test_multiple_issues_same_function _________

self = <tests.suggestions.test_generators.TestGeneratorIntegration object at 0x000002078AA5E850>

    def test_multiple_issues_same_function(self) -> None:
        """Test handling multiple issues for the same function."""
        config = SuggestionConfig(default_style="google")

        # Create function with multiple issues
        function = create_test_function(
            name="process_data",
            params=["data", "options"],
            return_type="Dict[str, Any]",
        )

        # Issue 1: Missing parameter
        param_gen = ParameterSuggestionGenerator(config)
        param_issue = create_test_issue(
            issue_type="parameter_missing", details={"missing_param": "options"}
        )

        # Issue 2: Missing return
        return_gen = ReturnSuggestionGenerator(config)
        return_issue = create_test_issue(
            issue_type="missing_returns", details={"return_type": "Dict[str, Any]"}
        )

        # Generate suggestions
        docstring = create_parsed_docstring(params={"data": "Input data"})

        param_suggestion = param_gen.generate(
            SuggestionContext(param_issue, function, docstring, "google")
        )
        return_suggestion = return_gen.generate(
            SuggestionContext(return_issue, function, docstring, "google")
        )

        # Both should be valid
        assert param_suggestion.confidence >= 0.8
>       assert return_suggestion.confidence >= 0.8
E       AssertionError: assert 0.1 >= 0.8
E        +  where 0.1 = Suggestion(suggestion_type=<SuggestionType.RETURN_UPDATE: 'return_update'>, original_text='Test function.\n\nArgs:\n    data: Input data', suggested_text='Test function.\n\nArgs:\n    data: Input data', confidence=0.1, diff=SuggestionDiff(original_lines=['Test function.', '', 'Args:', '    data: Input data'], suggested_lines=['Test function.', '', 'Args:', '    data: Input data'], start_line=10, end_line=14), style='google', copy_paste_ready=True, is_actionable=True, validation_passed=True, metadata=SuggestionMetadata(generator_type='ReturnSuggestionGenerator', generator_version='1.0.0', template_used=None, style_detected=None, rule_triggers=[], llm_used=False, generation_time_ms=0.0, token_usage=None), affected_sections=[], line_range=(1, 1)).confidence

tests\suggestions\test_generators.py:577: AssertionError
____ TestDocstringMerger.test_smart_parameter_merge_preserve_descriptions _____

self = <tests.suggestions.test_merging.TestDocstringMerger object at 0x000002078AABA7B0>
merger = <codedocsync.suggestions.merging.DocstringMerger object at 0x000002078AC74D60>

    def test_smart_parameter_merge_preserve_descriptions(self, merger: Any) -> None:
        """Test intelligent parameter merging with description preservation."""
        original_params = [
            DocstringParameter(
                name="param1",
                type_str="str",
                description="Detailed description that should be preserved",
            ),
            DocstringParameter(
                name="param2",
                type_str="int",
                description="Another detailed description",
            ),
        ]

        new_params = [
            DocstringParameter(
                name="param1",
                type_str="Optional[str]",  # Type updated
                description="Generic description",  # Generic description
            ),
            DocstringParameter(
                name="param3",  # New parameter
                type_str="bool",
                description="New parameter description",
            ),
        ]

        merged = merger.smart_parameter_merge(
            original_params, new_params, preserve_descriptions=True
        )

        assert len(merged) == 2

        # First parameter should have new type but preserved description
        param1 = next(p for p in merged if p.name == "param1")
        assert param1.type_str == "Optional[str]"
>       assert param1.description == "Detailed description that should be preserved"
E       AssertionError: assert 'Generic description' == 'Detailed des... be preserved'
E
E         - Detailed description that should be preserved
E         + Generic description

tests\suggestions\test_merging.py:174: AssertionError
_______ TestDocstringMerger.test_parse_section_boundaries_google_style ________

self = <tests.suggestions.test_merging.TestDocstringMerger object at 0x000002078AA65BF0>
merger = <codedocsync.suggestions.merging.DocstringMerger object at 0x000002078ACFD7B0>

    def test_parse_section_boundaries_google_style(self, merger: Any) -> None:
        """Test parsing section boundaries for Google style."""
        lines = [
            '"""Function summary.',
            "",
            "Detailed description.",
            "",
            "Args:",
            "    param1: First parameter",
            "    param2: Second parameter",
            "",
            "Returns:",
            "    Return value",
            "",
            "Raises:",
            "    ValueError: When something is wrong",
            "",
            "Examples:",
            "    >>> example()",
            "    True",
            '"""',
        ]

        boundaries = merger._parse_section_boundaries(lines)

>       assert SectionType.SUMMARY in boundaries
E       AssertionError: assert <SectionType.SUMMARY: 'summary'> in {<SectionType.PARAMETERS: 'parameters'>: SectionBoundary(section_type=<SectionType.PARAMETERS: 'parameters'>, start_line=4, end_line=7, header_line=None, content_lines=[4, 5, 6, 7]), <SectionType.RETURNS: 'returns'>: SectionBoundary(section_type=<SectionType.RETURNS: 'returns'>, start_line=8, end_line=10, header_line=None, content_lines=[8, 9, 10]), <SectionType.RAISES: 'raises'>: SectionBoundary(section_type=<SectionType.RAISES: 'raises'>, start_line=11, end_line=13, header_line=None, content_lines=[11, 12, 13]), <SectionType.EXAMPLES: 'examples'>: SectionBoundary(section_type=<SectionType.EXAMPLES: 'examples'>, start_line=14, end_line=17, header_line=None, content_lines=[14, 15, 16, 17])}
E        +  where <SectionType.SUMMARY: 'summary'> = SectionType.SUMMARY

tests\suggestions\test_merging.py:220: AssertionError
_______________ TestDocstringMerger.test_validate_merge_result ________________

self = <tests.suggestions.test_merging.TestDocstringMerger object at 0x000002078A9B7110>
merger = <codedocsync.suggestions.merging.DocstringMerger object at 0x000002078AB7EF30>

    def test_validate_merge_result(self, merger: Any) -> None:
        """Test validation of merge results."""
        # Valid docstring
        valid_docstring = '''"""
        Valid docstring.

        Args:
            param: Parameter description

        Returns:
            Return value
        """'''

        is_valid, errors = merger.validate_merge_result(valid_docstring)
        assert is_valid
        assert len(errors) == 0

        # Invalid docstring - unbalanced quotes
        invalid_docstring = '''"""
        Invalid docstring.

        Args:
            param: Parameter description
        """'''

        is_valid, errors = merger.validate_merge_result(invalid_docstring)
>       assert not is_valid
E       assert not True

tests\suggestions\test_merging.py:316: AssertionError
________ TestSuggestionPerformance.test_single_suggestion_performance _________

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000002078AACA5D0>

    def test_single_suggestion_performance(self) -> None:
        """Test that single suggestion generation is under 100ms."""
>       func = self.create_test_function(num_params=10)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:55:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_________ TestSuggestionPerformance.test_batch_suggestion_performance _________

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000002078AACA350>

    def test_batch_suggestion_performance(self) -> None:
        """Test performance with multiple analysis results."""
        results = []
        # Create 20 analysis results
        for _ in range(20):
>           func = self.create_test_function(num_params=5)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:111:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_________ TestSuggestionPerformance.test_generator_direct_performance _________

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000002078AA37950>

    def test_generator_direct_performance(self) -> None:
        """Test direct generator performance without integration layer."""
>       func = self.create_test_function(num_params=15)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:159:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_________ TestSuggestionPerformance.test_complex_function_performance _________

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000002078AA37A80>

    def test_complex_function_performance(self) -> None:
        """Test performance with complex function signatures."""
        # Create complex function with many parameters and complex types
        params = [
            FunctionParameter(
                name="data",
                type_annotation="Dict[str, List[Tuple[int, str]]]",
                is_required=True,
            ),
            FunctionParameter(
                name="processor",
                type_annotation="Callable[[Any], Tuple[bool, Dict[str, Any]]]",
                is_required=True,
            ),
            FunctionParameter(
                name="options",
                type_annotation="Dict[str, Union[str, int, float, List[str]]]",
                default_value="None",
                is_required=False,
            ),
            FunctionParameter(name="*args", type_annotation="Any", is_required=False),
            FunctionParameter(
                name="**kwargs", type_annotation="Any", is_required=False
            ),
        ]
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="complex_processor",
                parameters=params,
                return_type="Generator[Dict[str, Any], None, None]",
                is_async=True,
            ),
            docstring=RawDocstring(raw_text='""""""'),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_performance.py:207:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='complex_processor', parameters=[FunctionParameter(name='data', type_a...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestSuggestionPerformance.test_style_generation_performance[google] _____

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000002078AB29910>
style = 'google'

    @pytest.mark.parametrize("style", ["google", "numpy", "sphinx"])
    def test_style_generation_performance(self, style: Any) -> None:
        """Test performance across different docstring styles."""
>       func = self.create_test_function(num_params=8)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:284:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestSuggestionPerformance.test_style_generation_performance[numpy] ______

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000002078AA669C0>
style = 'numpy'

    @pytest.mark.parametrize("style", ["google", "numpy", "sphinx"])
    def test_style_generation_performance(self, style: Any) -> None:
        """Test performance across different docstring styles."""
>       func = self.create_test_function(num_params=8)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:284:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestSuggestionPerformance.test_style_generation_performance[sphinx] _____

self = <tests.suggestions.test_performance.TestSuggestionPerformance object at 0x000002078AA66AD0>
style = 'sphinx'

    @pytest.mark.parametrize("style", ["google", "numpy", "sphinx"])
    def test_style_generation_performance(self, style: Any) -> None:
        """Test performance across different docstring styles."""
>       func = self.create_test_function(num_params=8)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests\suggestions\test_performance.py:284:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
tests\suggestions\test_performance.py:44: in create_test_function
    return ParsedFunction(
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_function', parameters=[FunctionParameter(name='param0', type_ann...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
________________ TestSuggestionRanker.test_rank_by_confidence _________________

self = <tests.suggestions.test_ranking.TestSuggestionRanker object at 0x000002078AA37CE0>
critical_issue = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description='Critical parameter mismatch', su...rameter', line_number=10, confidence=0.95, details={}, rich_suggestion=None, formatted_output=None, ranking_score=29.5)
low_confidence_issue = EnhancedIssue(issue_type='description_outdated', severity='medium', description='Outdated description', suggestion='Up...cription', line_number=50, confidence=0.3, details={}, rich_suggestion=None, formatted_output=None, ranking_score=None)

    def test_rank_by_confidence(
        self, critical_issue: Any, low_confidence_issue: Any
    ) -> None:
        """Test ranking considers confidence."""
        config = RankingConfig(strategy=RankingStrategy.CONFIDENCE_FIRST)
        ranker = SuggestionRanker(config)

        issues = [low_confidence_issue, critical_issue]
        ranked = ranker.rank_suggestions(issues)

        # Higher confidence should rank higher
>       assert ranked[0].confidence > ranked[1].confidence
                                      ^^^^^^^^^
E       IndexError: list index out of range

tests\suggestions\test_ranking.py:226: IndexError
____________ TestRankingStrategies.test_confidence_first_strategy _____________

self = <tests.suggestions.test_ranking.TestRankingStrategies object at 0x000002078AACBB10>
critical_issue = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description='Critical parameter mismatch', su...arameter', line_number=10, confidence=0.6, details={}, rich_suggestion=None, formatted_output=None, ranking_score=26.0)
medium_issue = EnhancedIssue(issue_type='missing_raises', severity='medium', description='Missing exception documentation', suggestio...ion docs', line_number=30, confidence=0.9, details={}, rich_suggestion=None, formatted_output=None, ranking_score=19.0)

    def test_confidence_first_strategy(
        self, critical_issue: Any, medium_issue: Any
    ) -> None:
        """Test confidence-first ranking strategy."""
        config = RankingConfig(strategy=RankingStrategy.CONFIDENCE_FIRST)
        ranker = SuggestionRanker(config)

        # Set different confidences
        critical_issue.confidence = 0.6
        medium_issue.confidence = 0.9

        issues = [critical_issue, medium_issue]
        ranked = ranker.rank_suggestions(issues)

        # Medium issue should rank higher due to confidence boost
>       assert ranked[0].confidence > ranked[1].confidence
E       AssertionError: assert 0.6 > 0.9
E        +  where 0.6 = EnhancedIssue(issue_type='parameter_name_mismatch', severity='critical', description='Critical parameter mismatch', suggestion='Fix critical parameter', line_number=10, confidence=0.6, details={}, rich_suggestion=None, formatted_output=None, ranking_score=26.0).confidence
E        +  and   0.9 = EnhancedIssue(issue_type='missing_raises', severity='medium', description='Missing exception documentation', suggestion='Add exception docs', line_number=30, confidence=0.9, details={}, rich_suggestion=None, formatted_output=None, ranking_score=19.0).confidence

tests\suggestions\test_ranking.py:506: AssertionError
___________ TestSpecificIssueFixes.test_fix_parameter_name_mismatch ___________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000002078AB6C410>

    def test_fix_parameter_name_mismatch(self) -> None:
        """Test fixing parameter name mismatches."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="calculate_area",
                parameters=[
                    FunctionParameter(
                        name="width", type_annotation="float", is_required=True
                    ),
                    FunctionParameter(
                        name="height", type_annotation="float", is_required=True
                    ),
                ],
                return_type="float",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Calculate area of rectangle.
                    Args:
                        w (float): Width of rectangle.
                        h (float): Height of rectangle.
                    Returns:
                        float: Area value.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:39:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='calculate_area', parameters=[FunctionParameter(name='width', type_ann...:\n    float: Area value.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestSpecificIssueFixes.test_fix_return_type_mismatch _____________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000002078AB6C550>

    def test_fix_return_type_mismatch(self) -> None:
        """Test fixing return type documentation mismatches."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="get_config",
                return_type="Optional[Dict[str, Any]]",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Get configuration settings.
                    Returns:
                        dict: Configuration dictionary.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:94:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='get_config', parameters=[], return_type='Optional[Dict[str, Any]]', i...Configuration dictionary.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
___________ TestSpecificIssueFixes.test_fix_missing_raises_complex ____________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000002078AB50770>

    def test_fix_missing_raises_complex(self) -> None:
        """Test fixing missing exception documentation with multiple exceptions."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="parse_json_file",
                parameters=[
                    FunctionParameter(
                        name="filepath", type_annotation="str", is_required=True
                    ),
                ],
                return_type="Dict[str, Any]",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Parse JSON file and return contents.
                    Args:
                        filepath (str): Path to JSON file.
                    Returns:
                        Dict[str, Any]: Parsed JSON data.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:138:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='parse_json_file', parameters=[FunctionParameter(name='filepath', type..., Any]: Parsed JSON data.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
__________ TestSpecificIssueFixes.test_fix_parameter_order_different __________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000002078AB508A0>

    def test_fix_parameter_order_different(self) -> None:
        """Test fixing when parameter order in docs doesn't match code."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="create_connection",
                parameters=[
                    FunctionParameter(
                        name="host", type_annotation="str", is_required=True
                    ),
                    FunctionParameter(
                        name="port", type_annotation="int", is_required=True
                    ),
                    FunctionParameter(
                        name="timeout",
                        type_annotation="float",
                        default_value="30.0",
                        is_required=False,
                    ),
                ],
                return_type="Connection",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Create network connection.
                    Args:
                        port (int): Port number.
                        timeout (float): Timeout in seconds.
                        host (str): Host address.
                    Returns:
                        Connection: Active connection object.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:193:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='create_connection', parameters=[FunctionParameter(name='host', type_a...Active connection object.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
______ TestSpecificIssueFixes.test_fix_missing_params_with_complex_types ______

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000002078AB656D0>

    def test_fix_missing_params_with_complex_types(self) -> None:
        """Test fixing missing parameters with complex type annotations."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="process_data",
                parameters=[
                    FunctionParameter(
                        name="data", type_annotation="pd.DataFrame", is_required=True
                    ),
                    FunctionParameter(
                        name="columns",
                        type_annotation="Optional[List[str]]",
                        default_value="None",
                        is_required=False,
                    ),
                    FunctionParameter(
                        name="callback",
                        type_annotation="Callable[[int], None]",
                        default_value="None",
                        is_required=False,
                    ),
                ],
                return_type="pd.DataFrame",
            ),
            docstring=RawDocstring(raw_text='""""""'),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:254:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='process_data', parameters=[FunctionParameter(name='data', type_annota...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_______________ TestSpecificIssueFixes.test_fix_example_invalid _______________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000002078AA66F10>

    def test_fix_example_invalid(self) -> None:
        """Test fixing invalid examples in docstring."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="square",
                parameters=[
                    FunctionParameter(
                        name="x", type_annotation="float", is_required=True
                    ),
                ],
                return_type="float",
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Calculate square of a number.
                    Args:
                        x (float): Number to square.
                    Returns:
                        float: Square of x.
                    Examples:
                        >>> square(2)
                        5
                        >>> square(-3)
                        -9
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:302:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='square', parameters=[FunctionParameter(name='x', type_annotation='flo...   >>> square(-3)\n    -9\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestSpecificIssueFixes.test_fix_description_outdated _____________

self = <tests.suggestions.test_specific_issues.TestSpecificIssueFixes object at 0x000002078AA67460>

    def test_fix_description_outdated(self) -> None:
        """Test fixing outdated function descriptions."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="save_data",
                parameters=[
                    FunctionParameter(
                        name="data", type_annotation="Dict[str, Any]", is_required=True
                    ),
                    FunctionParameter(
                        name="filepath", type_annotation="Path", is_required=True
                    ),
                    FunctionParameter(
                        name="compress",
                        type_annotation="bool",
                        default_value="False",
                        is_required=False,
                    ),
                ],
                return_type="None",
                is_async=True,
            ),
            docstring=RawDocstring(
                raw_text=dedent(
                    '''
                    """
                    Save data to CSV file.
                    Args:
                        data (dict): Data to save.
                        filepath (str): Output file path.
                    Returns:
                        bool: True if successful.
                    """
                '''
                ).strip(),
                line_number=1,
            ),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_specific_issues.py:360:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='save_data', parameters=[FunctionParameter(name='data', type_annotatio...bool: True if successful.\n"""', line_number=1), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
______ TestDocstringStyleGeneration.test_generate_google_style_docstring ______

self = <tests.suggestions.test_suggestion_generator.TestDocstringStyleGeneration object at 0x000002078AB6D590>

    def test_generate_google_style_docstring(self) -> None:
        """Test Google style docstring generation."""
        template = GoogleStyleTemplate()

        # Create proper docstring components
        parameters = [
            DocstringParameter(
                name="numbers",
                type_str="List[float]",
                description="List of numbers to average",
                is_optional=False,
            ),
            DocstringParameter(
                name="weights",
                type_str="Optional[List[float]]",
                description="Optional weights for each number",
                is_optional=True,
            ),
        ]

        returns = DocstringReturns(
            type_str="float",
            description="The weighted average",
        )

        raises = [
            DocstringRaises(
                exception_type="ValueError",
                description="If lists have different lengths",
            )
        ]

        # Generate full docstring
        docstring = template.render_complete_docstring(
            summary="Calculate weighted average of numbers.",
            parameters=parameters,
            returns=returns,
            raises=raises,
        )

        # Verify structure
        assert "Calculate weighted average of numbers." in docstring
        assert "Args:" in docstring
        assert "numbers (List[float]): List of numbers to average" in docstring
>       assert (
            "weights (Optional[List[float]]): Optional weights for each number"
            in docstring
        )
E       assert 'weights (Optional[List[float]]): Optional weights for each number' in '"""\nCalculate weighted average of numbers.\n\nArgs:\n    numbers (List[float]): List of numbers to average\n    weights (List[float], optional): Optional weights for each number\n\nReturns:\n    float: The weighted average\n\nRaises:\n    ValueError: If lists have different lengths\n"""'

tests\suggestions\test_suggestion_generator.py:121: AssertionError
______ TestDocstringStyleGeneration.test_generate_numpy_style_docstring _______

self = <tests.suggestions.test_suggestion_generator.TestDocstringStyleGeneration object at 0x000002078AB6D6D0>

    def test_generate_numpy_style_docstring(self) -> None:
        """Test NumPy style docstring generation."""
        template = NumpyStyleTemplate()

        # Create proper docstring components
        parameters = [
            DocstringParameter(
                name="numbers",
                type_str="List[float]",
                description="List of numbers to average",
                is_optional=False,
            ),
            DocstringParameter(
                name="weights",
                type_str="Optional[List[float]]",
                description="Optional weights for each number",
                is_optional=True,
            ),
        ]

        returns = DocstringReturns(
            type_str="float",
            description="The weighted average",
        )

        raises = [
            DocstringRaises(
                exception_type="ValueError",
                description="If lists have different lengths",
            )
        ]

        # Generate full docstring
        docstring = template.render_complete_docstring(
            summary="Calculate weighted average of numbers.",
            parameters=parameters,
            returns=returns,
            raises=raises,
        )

        # Verify structure
        assert "Calculate weighted average of numbers." in docstring
        assert "Parameters" in docstring
        assert "----------" in docstring
>       assert "numbers : List[float]" in docstring
E       assert 'numbers : List[float]' in '"""\nCalculate weighted average of numbers.\n\nParameters\n----------\nnumbers : list of float\n    List of numbers to average\n\nweights : list of float, optional\n    Optional weights for each number\n\nReturns\n-------\nresult : float\n    The weighted average\n\nRaises\n------\nValueError\n    If lists have different lengths\n"""'

tests\suggestions\test_suggestion_generator.py:181: AssertionError
______ TestDocstringStyleGeneration.test_generate_sphinx_style_docstring ______

self = <tests.suggestions.test_suggestion_generator.TestDocstringStyleGeneration object at 0x000002078AB516E0>

    def test_generate_sphinx_style_docstring(self) -> None:
        """Test Sphinx style docstring generation."""
        template = SphinxStyleTemplate()

        # Create proper docstring components
        parameters = [
            DocstringParameter(
                name="numbers",
                type_str="List[float]",
                description="List of numbers to average",
                is_optional=False,
            ),
            DocstringParameter(
                name="weights",
                type_str="Optional[List[float]]",
                description="Optional weights for each number",
                is_optional=True,
            ),
        ]

        returns = DocstringReturns(
            type_str="float",
            description="The weighted average",
        )

        raises = [
            DocstringRaises(
                exception_type="ValueError",
                description="If lists have different lengths",
            )
        ]

        # Generate full docstring
        docstring = template.render_complete_docstring(
            summary="Calculate weighted average of numbers.",
            parameters=parameters,
            returns=returns,
            raises=raises,
        )

        # Verify structure
        assert "Calculate weighted average of numbers." in docstring
        assert ":param numbers:" in docstring
        assert "List of numbers to average" in docstring
>       assert ":type numbers: List[float]" in docstring
E       assert ':type numbers: List[float]' in '"""\nCalculate weighted average of numbers.\n\n:param numbers: List of numbers to average\n:type numbers: list of float\n:param weights: Optional weights for each number\n:type weights: list of float\n:returns: The weighted average\n:rtype: float\n:raises ValueError: If lists have different lengths\n"""'

tests\suggestions\test_suggestion_generator.py:242: AssertionError
_______________ TestSmartUpdates.test_preserve_existing_content _______________

self = <tests.suggestions.test_suggestion_generator.TestSmartUpdates object at 0x000002078AB6D810>

    def test_preserve_existing_content(self) -> None:
        """Test that existing docstring content is preserved during updates."""
>       function = ParsedFunction(
            signature=FunctionSignature(
                name="process_data",
                parameters=[
                    FunctionParameter(
                        name="data",
                        type_annotation="Dict[str, Any]",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="Dict[str, Any]",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=20,
        )

tests\suggestions\test_suggestion_generator.py:263:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='process_data', parameters=[FunctionParameter(name='data', type_annota...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=20, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (20)

codedocsync\parser\ast_parser.py:159: ValidationError
_________________ TestSmartUpdates.test_merge_partial_updates _________________

self = <tests.suggestions.test_suggestion_generator.TestSmartUpdates object at 0x000002078AB6D950>

    def test_merge_partial_updates(self) -> None:
        """Test merging partial docstring updates."""
>       function = ParsedFunction(
            signature=FunctionSignature(
                name="validate_input",
                parameters=[
                    FunctionParameter(
                        name="value",
                        type_annotation="str",
                        default_value=None,
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="strict",
                        type_annotation="bool",
                        default_value="False",
                        is_required=False,
                    ),
                ],
                return_type="bool",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=30,
        )

tests\suggestions\test_suggestion_generator.py:351:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='validate_input', parameters=[FunctionParameter(name='value', type_ann...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=30, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (30)

codedocsync\parser\ast_parser.py:159: ValidationError
__________________ TestSmartUpdates.test_fix_specific_issues __________________

self = <tests.suggestions.test_suggestion_generator.TestSmartUpdates object at 0x000002078AB51940>

    def test_fix_specific_issues(self) -> None:
        """Test fixing specific issues: parameter, return, and raises."""
>       function = ParsedFunction(
            signature=FunctionSignature(
                name="divide",
                parameters=[
                    FunctionParameter(
                        name="a",
                        type_annotation="float",
                        default_value=None,
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="b",
                        type_annotation="float",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="float",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=40,
        )

tests\suggestions\test_suggestion_generator.py:468:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='divide', parameters=[FunctionParameter(name='a', type_annotation='flo...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=40, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (40)

codedocsync\parser\ast_parser.py:159: ValidationError
______ TestPerformanceBenchmarks.test_suggestion_generation_performance _______

self = <tests.suggestions.test_suggestion_generator.TestPerformanceBenchmarks object at 0x000002078AB6DA90>

    def test_suggestion_generation_performance(self) -> None:
        """Test that suggestion generation is < 100ms."""
>       function = ParsedFunction(
            signature=FunctionSignature(
                name="test_func",
                parameters=[
                    FunctionParameter(
                        name="param1",
                        type_annotation="str",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="str",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=50,
        )

tests\suggestions\test_suggestion_generator.py:574:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_func', parameters=[FunctionParameter(name='param1', type_annotat...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=50, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (50)

codedocsync\parser\ast_parser.py:159: ValidationError
______________ TestPerformanceBenchmarks.test_template_accuracy _______________

self = <tests.suggestions.test_suggestion_generator.TestPerformanceBenchmarks object at 0x000002078AB6DBD0>

    def test_template_accuracy(self) -> None:
        """Test that all templates produce 100% valid syntax."""
        templates = [
            GoogleStyleTemplate(),
            NumpyStyleTemplate(),
            SphinxStyleTemplate(),
        ]

        parsers = {
            "google": GoogleParser(),
            "numpy": NumpydocParser(),
            "sphinx": parse,  # Sphinx uses general parser
        }

>       ParsedFunction(
            signature=FunctionSignature(
                name="complex_function",
                parameters=[
                    FunctionParameter(
                        name="required_param",
                        type_annotation="str",
                        default_value=None,
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="optional_param",
                        type_annotation="int",
                        default_value="0",
                        is_required=False,
                    ),
                ],
                return_type="Tuple[str, int]",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=60,
        )

tests\suggestions\test_suggestion_generator.py:635:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='complex_function', parameters=[FunctionParameter(name='required_param...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=60, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (60)

codedocsync\parser\ast_parser.py:159: ValidationError
_____ TestEdgeCasesAndRobustness.test_empty_function_docstring_generation _____

self = <tests.suggestions.test_suggestion_generator.TestEdgeCasesAndRobustness object at 0x000002078AB6DD10>

    def test_empty_function_docstring_generation(self) -> None:
        """Test generating docstring for function with no parameters or return."""
>       ParsedFunction(
            signature=FunctionSignature(
                name="do_nothing",
                parameters=[],
                return_type="None",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=70,
        )

tests\suggestions\test_suggestion_generator.py:741:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='do_nothing', parameters=[], return_type='None', is_async=False, is_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=70, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (70)

codedocsync\parser\ast_parser.py:159: ValidationError
__________ TestEdgeCasesAndRobustness.test_complex_type_annotations ___________

self = <tests.suggestions.test_suggestion_generator.TestEdgeCasesAndRobustness object at 0x000002078AB6DE50>

    def test_complex_type_annotations(self) -> None:
        """Test handling of complex type annotations."""
>       ParsedFunction(
            signature=FunctionSignature(
                name="process_complex_types",
                parameters=[
                    FunctionParameter(
                        name="data",
                        type_annotation="Dict[str, List[Tuple[int, str]]]",
                        default_value=None,
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="callback",
                        type_annotation="Callable[[str], Awaitable[None]]",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="AsyncIterator[Dict[str, Any]]",
                decorators=[],
                is_async=True,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=80,
        )

tests\suggestions\test_suggestion_generator.py:771:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='process_complex_types', parameters=[FunctionParameter(name='data', ty...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=80, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (80)

codedocsync\parser\ast_parser.py:159: ValidationError
___________ TestEdgeCasesAndRobustness.test_multiline_descriptions ____________

self = <tests.suggestions.test_suggestion_generator.TestEdgeCasesAndRobustness object at 0x000002078AB51A70>

    def test_multiline_descriptions(self) -> None:
        """Test handling of multiline descriptions."""
>       ParsedFunction(
            signature=FunctionSignature(
                name="complex_algorithm",
                parameters=[
                    FunctionParameter(
                        name="input_data",
                        type_annotation="np.ndarray",
                        default_value=None,
                        is_required=True,
                    ),
                ],
                return_type="np.ndarray",
                decorators=[],
                is_async=False,
                is_method=False,
            ),
            docstring=None,
            file_path="test.py",
            line_number=90,
        )

tests\suggestions\test_suggestion_generator.py:833:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='complex_algorithm', parameters=[FunctionParameter(name='input_data', ...s_method=False, decorators=[]), docstring=None, file_path='test.py', line_number=90, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (90)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestTypeAnnotationFormatter.test_format_complex_types ____________

self = <tests.suggestions.test_type_formatter.TestTypeAnnotationFormatter object at 0x000002078AB19750>
google_formatter = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x00000209BC113350>

    def test_format_complex_types(self, google_formatter: Any) -> None:
        """Test formatting of complex types."""
        # Callable should be simplified
>       assert (
            google_formatter.format_for_docstring("Callable[[int, str], bool]")
            == "callable"
        )
E       AssertionError: assert 'Callable[[int, str], bool]' == 'callable'
E
E         - callable
E         + Callable[[int, str], bool]

tests\suggestions\test_type_formatter.py:102: AssertionError
_____________ TestTypeAnnotationFormatter.test_assess_complexity ______________

self = <tests.suggestions.test_type_formatter.TestTypeAnnotationFormatter object at 0x000002078AB7CD70>
google_formatter = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x00000209BC0B2CF0>

    def test_assess_complexity(self, google_formatter: Any) -> None:
        """Test complexity assessment."""
        # Simple types
        assert google_formatter._assess_complexity("str") == TypeComplexity.SIMPLE
        assert google_formatter._assess_complexity("int") == TypeComplexity.SIMPLE

        # Generic types
        assert (
            google_formatter._assess_complexity("List[str]") == TypeComplexity.GENERIC
        )
        assert (
            google_formatter._assess_complexity("Dict[str, Any]")
            == TypeComplexity.GENERIC
        )

        # Union types
        assert (
            google_formatter._assess_complexity("Union[str, int]")
            == TypeComplexity.UNION
        )
        assert (
            google_formatter._assess_complexity("Optional[str]") == TypeComplexity.UNION
        )

        # Complex types
>       assert (
            google_formatter._assess_complexity("Callable[[int], str]")
            == TypeComplexity.COMPLEX
        )
E       AssertionError: assert <TypeComplexity.GENERIC: 'generic'> == <TypeComplexity.COMPLEX: 'complex'>
E        +  where <TypeComplexity.GENERIC: 'generic'> = _assess_complexity('Callable[[int], str]')
E        +    where _assess_complexity = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x00000209BC0B2CF0>._assess_complexity
E        +  and   <TypeComplexity.COMPLEX: 'complex'> = TypeComplexity.COMPLEX

tests\suggestions\test_type_formatter.py:152: AssertionError
___________ TestTypeAnnotationFormatter.test_new_style_union_syntax ___________

self = <tests.suggestions.test_type_formatter.TestTypeAnnotationFormatter object at 0x000002078ABC7A50>
google_formatter = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x00000209BC0B32F0>

    def test_new_style_union_syntax(self, google_formatter: Any) -> None:
        """Test Python 3.10+ union syntax (Union[A, B])."""
        result = google_formatter.format_for_docstring("Union[str, int]")
        assert result == "str or int"

        result = google_formatter.format_for_docstring("Union[str, int] | float")
>       assert result == "str or int or float"
E       AssertionError: assert 'str or int' == 'str or int or float'
E
E         - str or int or float
E         + str or int

tests\suggestions\test_type_formatter.py:265: AssertionError
__________ TestComplexTypeScenarios.test_very_long_type_annotations ___________

self = <tests.suggestions.test_type_formatter.TestComplexTypeScenarios object at 0x000002078AB6E490>
formatter = <codedocsync.suggestions.type_formatter.TypeAnnotationFormatter object at 0x00000209BC0B30B0>

    def test_very_long_type_annotations(self, formatter: Any) -> None:
        """Test very long type annotations."""
        long_type = "Callable[[Dict[str, List[Tuple[int, str]]], Union[List[Dict[str, Any]], None]]"
        result = formatter.format_for_docstring(long_type)
        # Should be simplified to "callable"
>       assert result == "callable"
E       AssertionError: assert 'Callable[[Di...Any]], None]]' == 'callable'
E
E         - callable
E         + Callable[[Dict[str, List[Tuple[int, str]]], Union[List[Dict[str, Any]], None]]

tests\suggestions\test_type_formatter.py:289: AssertionError
_______ TestTemplateSyntaxValidation.test_return_documentation_validity _______

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000002078AB528B0>

    def test_return_documentation_validity(self) -> None:
        """Test return documentation produces valid syntax."""
        generator = ReturnSuggestionGenerator()
        test_returns = [
            {"type": "int", "description": "Count of items"},
            {"type": "List[str]", "description": "List of names"},
            {"type": "Optional[Dict[str, Any]]", "description": "Data or None"},
            {"type": "Generator[int, None, None]", "description": "Number generator"},
        ]
        for style in ["google", "numpy", "sphinx"]:
            for ret in test_returns:
>               func = ParsedFunction(
                    signature=FunctionSignature(
                        name="test_func", return_type=ret["type"]
                    ),
                    docstring=RawDocstring(raw_text='""""""'),
                    file_path="test.py",
                    line_number=1,
                )

tests\suggestions\test_validation.py:213:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_func', parameters=[], return_type='int', is_async=False, is_meth...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
_______ TestTemplateSyntaxValidation.test_raises_documentation_validity _______

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000002078ABA0170>

    def test_raises_documentation_validity(self) -> None:
        """Test exception documentation produces valid syntax."""
        generator = RaisesSuggestionGenerator()
        exceptions = [
            ["ValueError", "TypeError"],
            ["FileNotFoundError", "PermissionError", "OSError"],
            ["CustomError"],
        ]
        for style in ["google", "numpy", "sphinx"]:
            for exc_list in exceptions:
>               func = ParsedFunction(
                    signature=FunctionSignature(name="test_func"),
                    docstring=RawDocstring(raw_text='""""""'),
                    file_path="test.py",
                    line_number=1,
                )

tests\suggestions\test_validation.py:246:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='test_func', parameters=[], return_type=None, is_async=False, is_metho...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
________ TestTemplateSyntaxValidation.test_complete_docstring_validity ________

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000002078ABB48D0>

    def test_complete_docstring_validity(self) -> None:
        """Test complete docstrings with all sections are valid."""
        # Create a complex function
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="process_data",
                parameters=[
                    FunctionParameter(
                        name="data",
                        type_annotation="List[Dict[str, Any]]",
                        is_required=True,
                    ),
                    FunctionParameter(
                        name="validate",
                        type_annotation="bool",
                        default_value="True",
                        is_required=False,
                    ),
                ],
                return_type="ProcessedResult",
            ),
            docstring=RawDocstring(raw_text='""""""'),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_validation.py:270:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='process_data', parameters=[FunctionParameter(name='data', type_annota...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
____________ TestTemplateSyntaxValidation.test_edge_case_validity _____________

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000002078ABB49E0>

    def test_edge_case_validity(self) -> None:
        """Test edge cases produce valid syntax."""
        edge_cases: list[dict[str, Any]] = [
            # Empty parameter list
            {
                "params": [],
                "returns": None,
                "raises": [],
            },
            # Very long type annotations
            {
                "params": [
                    {
                        "name": "complex_param",
                        "type": "Dict[str, List[Tuple[int, str, Dict[str, Any]]]]",
                        "description": "Very complex nested type",
                    }
                ],
                "returns": "Tuple[bool, Dict[str, List[int]], Optional[str]]",
                "raises": ["Exception"],
            },
            # Special characters in descriptions
            {
                "params": [
                    {
                        "name": "pattern",
                        "type": "str",
                        "description": "Pattern with special chars: \"quotes\", 'single', \\backslash",
                    }
                ],
                "returns": "bool",
                "raises": [],
            },
        ]
        for style in ["google", "numpy", "sphinx"]:
            for case in edge_cases:
                # Build a complete docstring
                if style == "google":
                    docstring = '"""Test function.\n\n'
                    if case["params"]:
                        docstring += "Args:\n"
                        for p in case["params"]:
                            docstring += (
                                f"    {p['name']} ({p['type']}): {p['description']}\n"
                            )
                    if case["returns"]:
                        docstring += f"\nReturns:\n    {case['returns']}: Result.\n"
                    if case["raises"]:
                        docstring += "\nRaises:\n"
                        for exc in case["raises"]:
                            docstring += f"    {exc}: Error.\n"
                    docstring += '"""'
>                   assert self.validate_python_syntax(docstring)
E                   assert False
E                    +  where False = validate_python_syntax('"""Test function.\n\n"""')
E                    +    where validate_python_syntax = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000002078ABB49E0>.validate_python_syntax

tests\suggestions\test_validation.py:390: AssertionError
______ TestTemplateSyntaxValidation.test_multiline_descriptions_validity ______

self = <tests.suggestions.test_validation.TestTemplateSyntaxValidation object at 0x000002078AB19950>

    def test_multiline_descriptions_validity(self) -> None:
        """Test multiline descriptions produce valid syntax."""
>       func = ParsedFunction(
            signature=FunctionSignature(
                name="complex_function",
                parameters=[
                    FunctionParameter(
                        name="config",
                        type_annotation="Dict[str, Any]",
                        is_required=True,
                    ),
                ],
            ),
            docstring=RawDocstring(raw_text='""""""'),
            file_path="test.py",
            line_number=1,
        )

tests\suggestions\test_validation.py:394:
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
<string>:9: in __init__
    ???
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = ParsedFunction(signature=FunctionSignature(name='complex_function', parameters=[FunctionParameter(name='config', type_...=RawDocstring(raw_text='""""""', line_number=0), file_path='test.py', line_number=1, end_line_number=0, source_code='')

    def __post_init__(self) -> None:
        """Validate parsed function data."""
        if self.line_number < 0:
            raise ValidationError(
                f"Invalid line number: {self.line_number}",
                recovery_hint="Line numbers must be positive integers",
            )

        if self.end_line_number < self.line_number:
>           raise ValidationError(
                f"End line ({self.end_line_number}) before start line ({self.line_number})",
                recovery_hint="End line number must be >= start line number",
            )
E           codedocsync.utils.errors.ValidationError: End line (0) before start line (1)

codedocsync\parser\ast_parser.py:159: ValidationError
=========================== short test summary info ===========================
FAILED tests/suggestions/formatters/test_json_formatter.py::TestSuggestionFormatting::test_format_suggestion_with_metadata
FAILED tests/suggestions/formatters/test_json_formatter.py::TestAnalysisResultFormatting::test_format_analysis_result
FAILED tests/suggestions/formatters/test_json_formatter.py::TestAnalysisResultFormatting::test_format_result_without_documentation
FAILED tests/suggestions/formatters/test_json_formatter.py::TestBatchFormatting::test_format_suggestion_batch
FAILED tests/suggestions/formatters/test_json_formatter.py::TestFunctionInformationExtraction::test_format_function_info_minimal
FAILED tests/suggestions/formatters/test_json_formatter.py::TestConvenienceFunctions::test_analysis_result_to_json
FAILED tests/suggestions/formatters/test_json_formatter.py::TestConvenienceFunctions::test_batch_results_to_json
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestSuggestionFormatting::test_format_basic_suggestion_plain
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestSuggestionFormatting::test_format_suggestion_rich
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestEnhancedIssueFormatting::test_format_issue_with_suggestion_plain
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestBatchSummaryFormatting::test_format_batch_summary_plain
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestBatchSummaryFormatting::test_format_batch_summary_minimal
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestBatchSummaryFormatting::test_format_empty_batch
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestEdgeCases::test_suggestion_without_diff
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestEdgeCases::test_issue_with_zero_line_number
FAILED tests/suggestions/formatters/test_terminal_formatter.py::TestEdgeCases::test_function_without_signature
FAILED tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_data_operations
FAILED tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_error_handling
FAILED tests/suggestions/generators/test_behavior_generator.py::TestBehaviorAnalyzer::test_analyze_performance_characteristics
FAILED tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_unknown_issue_type
FAILED tests/suggestions/generators/test_behavior_generator.py::TestBehaviorGeneratorIntegration::test_complete_workflow_data_processing
FAILED tests/suggestions/generators/test_behavior_generator.py::TestBehaviorGeneratorIntegration::test_complete_workflow_file_operations
FAILED tests/suggestions/generators/test_behavior_generator.py::TestBehaviorGeneratorIntegration::test_performance_pattern_detection
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestSpecialConstructAnalyzer::test_analyze_property_getter
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestSpecialConstructAnalyzer::test_analyze_classmethod
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestSpecialConstructAnalyzer::test_analyze_magic_method
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestSpecialConstructAnalyzer::test_analyze_async_function
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestPropertyMethodHandler::test_property_setter_detection
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestPropertyMethodHandler::test_property_deleter_detection
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestClassMethodHandler::test_staticmethod_handling
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestEdgeCaseSuggestionGenerator::test_async_function_suggestion
FAILED tests/suggestions/generators/test_edge_case_handlers.py::TestEdgeCaseSuggestionGenerator::test_magic_method_suggestion
FAILED tests/suggestions/generators/test_example_generator.py::TestParameterValueGenerator::test_generate_value_by_name
FAILED tests/suggestions/generators/test_example_generator.py::TestParameterValueGenerator::test_generate_value_optional_with_default
FAILED tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_async_function
FAILED tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_generator_function
FAILED tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_side_effects
FAILED tests/suggestions/generators/test_example_generator.py::TestExamplePatternAnalyzer::test_analyze_domain_detection
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_async_example
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_property_example
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_edge_case_values
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_expected_output
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleGenerator::test_generate_multiple_examples
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_unknown_issue_type
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleGeneratorIntegration::test_complete_workflow_mathematical_function
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleGeneratorIntegration::test_complete_workflow_file_processing_function
FAILED tests/suggestions/generators/test_example_generator.py::TestExampleGeneratorIntegration::test_async_function_example_generation
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_fix_parameter_order
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_add_kwargs_documentation
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_filter_special_parameters
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_normalize_type
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_detect_style_from_docstring
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_fallback_suggestion
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_generic_parameter_fix
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterGeneratorEdgeCases::test_empty_function_parameters
FAILED tests/suggestions/generators/test_parameter_generator.py::TestParameterGeneratorEdgeCases::test_classmethod_detection
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_add_missing_raises_documentation
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_fix_raises_type_mismatch
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_improve_raises_description
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_is_vague_description
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_no_source_code_fallback
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_no_significant_exceptions
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesSuggestionGenerator::test_unknown_issue_type
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesGeneratorIntegration::test_complete_workflow_file_operations
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesGeneratorIntegration::test_complete_workflow_mismatch_correction
FAILED tests/suggestions/generators/test_raises_generator.py::TestRaisesGeneratorIntegration::test_edge_case_no_exceptions_detected
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnStatementAnalyzer::test_analyze_generator_function
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_fix_return_type_mismatch
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_add_missing_return_documentation
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_improve_return_description
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_fix_generator_return
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_determine_best_return_type_single
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_determine_best_return_type_multiple
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_no_source_code_fallback
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnSuggestionGenerator::test_unknown_issue_type
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnGeneratorIntegration::test_complete_workflow_missing_returns
FAILED tests/suggestions/generators/test_return_generator.py::TestReturnGeneratorIntegration::test_complete_workflow_generator_function
FAILED tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_render_parameters_simple
FAILED tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_match_parameter_line
FAILED tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_extract_section_boundaries
FAILED tests/suggestions/templates/test_google_template.py::TestGoogleStyleTemplate::test_template_with_max_line_length
FAILED tests/suggestions/templates/test_google_template.py::TestTemplateRegistry::test_invalid_style_raises_error
FAILED tests/suggestions/templates/test_google_template.py::TestTemplateIntegration::test_realistic_function_docstring
FAILED tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_render_raises_without_type
FAILED tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_match_parameter_line
FAILED tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_format_type_annotation_array_types
FAILED tests/suggestions/templates/test_numpy_template.py::TestNumpyStyleTemplate::test_long_line_wrapping
FAILED tests/suggestions/templates/test_sphinx_template.py::TestSphinxStyleTemplate::test_render_examples
FAILED tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_unicode_in_sphinx_fields
FAILED tests/suggestions/templates/test_sphinx_template.py::TestSphinxTemplateEdgeCases::test_very_long_field_names
FAILED tests/suggestions/test_config.py::TestConfigIntegration::test_config_with_yaml_file_and_overrides
FAILED tests/suggestions/test_converter.py::TestSpecialCases::test_convert_with_unicode_content
FAILED tests/suggestions/test_e2e_integration.py::TestFullPipeline::test_parse_analyze_suggest_workflow
FAILED tests/suggestions/test_e2e_integration.py::TestFullPipeline::test_batch_processing
FAILED tests/suggestions/test_e2e_integration.py::TestCLIIntegration::test_suggest_command_with_file
FAILED tests/suggestions/test_e2e_integration.py::TestCLIIntegration::test_suggest_command_dry_run
FAILED tests/suggestions/test_e2e_integration.py::TestPerformanceMonitoring::test_performance_recommendations
FAILED tests/suggestions/test_e2e_integration.py::TestProductionScenarios::test_large_codebase_simulation
FAILED tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_name_mismatch_simple
FAILED tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_missing
FAILED tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_parameter_type_mismatch
FAILED tests/suggestions/test_generators.py::TestParameterSuggestionGenerator::test_preserves_descriptions
FAILED tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_return_type_mismatch
FAILED tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_missing_return_documentation
FAILED tests/suggestions/test_generators.py::TestReturnSuggestionGenerator::test_generator_function_return
FAILED tests/suggestions/test_generators.py::TestRaisesSuggestionGenerator::test_updates_existing_raises_section
FAILED tests/suggestions/test_generators.py::TestBehaviorSuggestionGenerator::test_enhance_vague_description
FAILED tests/suggestions/test_generators.py::TestBehaviorSuggestionGenerator::test_identify_side_effects
FAILED tests/suggestions/test_generators.py::TestExampleSuggestionGenerator::test_generate_basic_example
FAILED tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_property_method_documentation
FAILED tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_classmethod_documentation
FAILED tests/suggestions/test_generators.py::TestEdgeCaseSuggestionGenerator::test_magic_method_documentation
FAILED tests/suggestions/test_generators.py::TestGeneratorIntegration::test_multiple_issues_same_function
FAILED tests/suggestions/test_merging.py::TestDocstringMerger::test_smart_parameter_merge_preserve_descriptions
FAILED tests/suggestions/test_merging.py::TestDocstringMerger::test_parse_section_boundaries_google_style
FAILED tests/suggestions/test_merging.py::TestDocstringMerger::test_validate_merge_result
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_single_suggestion_performance
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_batch_suggestion_performance
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_generator_direct_performance
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_complex_function_performance
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[google]
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[numpy]
FAILED tests/suggestions/test_performance.py::TestSuggestionPerformance::test_style_generation_performance[sphinx]
FAILED tests/suggestions/test_ranking.py::TestSuggestionRanker::test_rank_by_confidence
FAILED tests/suggestions/test_ranking.py::TestRankingStrategies::test_confidence_first_strategy
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_parameter_name_mismatch
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_return_type_mismatch
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_missing_raises_complex
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_parameter_order_different
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_missing_params_with_complex_types
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_example_invalid
FAILED tests/suggestions/test_specific_issues.py::TestSpecificIssueFixes::test_fix_description_outdated
FAILED tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_google_style_docstring
FAILED tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_numpy_style_docstring
FAILED tests/suggestions/test_suggestion_generator.py::TestDocstringStyleGeneration::test_generate_sphinx_style_docstring
FAILED tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_preserve_existing_content
FAILED tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_merge_partial_updates
FAILED tests/suggestions/test_suggestion_generator.py::TestSmartUpdates::test_fix_specific_issues
FAILED tests/suggestions/test_suggestion_generator.py::TestPerformanceBenchmarks::test_suggestion_generation_performance
FAILED tests/suggestions/test_suggestion_generator.py::TestPerformanceBenchmarks::test_template_accuracy
FAILED tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_empty_function_docstring_generation
FAILED tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_complex_type_annotations
FAILED tests/suggestions/test_suggestion_generator.py::TestEdgeCasesAndRobustness::test_multiline_descriptions
FAILED tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_format_complex_types
FAILED tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_assess_complexity
FAILED tests/suggestions/test_type_formatter.py::TestTypeAnnotationFormatter::test_new_style_union_syntax
FAILED tests/suggestions/test_type_formatter.py::TestComplexTypeScenarios::test_very_long_type_annotations
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_return_documentation_validity
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_raises_documentation_validity
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_complete_docstring_validity
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_edge_case_validity
FAILED tests/suggestions/test_validation.py::TestTemplateSyntaxValidation::test_multiline_descriptions_validity
ERROR tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_improve_vague_description
ERROR tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_improve_outdated_description
ERROR tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_add_behavior_description
ERROR tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_add_side_effects_documentation
ERROR tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_no_source_code_fallback
ERROR tests/suggestions/generators/test_behavior_generator.py::TestBehaviorSuggestionGenerator::test_no_patterns_detected
ERROR tests/suggestions/generators/test_edge_case_handlers.py::TestPropertyMethodHandler::test_generate_property_getter_docstring
ERROR tests/suggestions/generators/test_edge_case_handlers.py::TestClassMethodHandler::test_generate_classmethod_docstring
ERROR tests/suggestions/generators/test_edge_case_handlers.py::TestEdgeCaseSuggestionGenerator::test_generate_suggestion_delegates_to_handlers
ERROR tests/suggestions/generators/test_edge_case_handlers.py::TestEdgeCaseSuggestionGenerator::test_generate_suggestion_no_handler
ERROR tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_add_missing_examples
ERROR tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_fix_invalid_example
ERROR tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_update_outdated_example
ERROR tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_complete_example
ERROR tests/suggestions/generators/test_example_generator.py::TestExampleSuggestionGenerator::test_no_examples_generated_fallback
ERROR tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_fix_parameter_name_mismatch
ERROR tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_add_missing_parameter
ERROR tests/suggestions/generators/test_parameter_generator.py::TestParameterSuggestionGenerator::test_fix_parameter_type_mismatch
================= 152 failed, 470 passed, 18 errors in 51.39s =================
